{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset import get_twit_company_dataloaders, get_twit_sentiment_dataloaders, get_twit_company_sentiment_dataloaders\n",
    "from model import LSTMTwitClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# text, label = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ignored due to unreadability: http://t.co/48emAEID \n",
      "Tweet ignored due to unreadability: http://t.co/Izh7KaiU \n",
      "Tweet ignored due to unreadability: http://t.co/e5ClGzsI \n",
      "Tweet ignored due to unreadability: http://t.co/18xg3ivo! \n",
      "Tweet ignored due to unreadability: Поиск от \n",
      "Tweet ignored due to unreadability: サムスン電子のスマートフォン新機種「ギャラクシー・ネクサス」、グーグルの基本ソフト（ＯＳ）「アンドロイド」最新版を搭載。「クラウド」活用、音声認識やカメラの機能も向上させた戦略モデル \n",
      "Tweet ignored due to unreadability: Новите \n",
      "Tweet ignored due to unreadability: اعرف الكثير عن نظام ايسكريم ساندويتش http://t.co/Fzjd2Zx1 \n",
      "Tweet ignored due to unreadability: 看見 \n",
      "Tweet ignored due to unreadability: نظام جديد .. و جهاز جديد شكراً جزيلاً \n",
      "Tweet ignored due to unreadability: ايسكريم ساندويش، عسل، زنجبيل .. مشكلة من كثر المسميات احسهم مسوين مقادير مب انظمة !! 😝  \n",
      "Tweet ignored due to unreadability: الجهاز الجديد عجيب   \n",
      "Tweet ignored due to unreadability: Я немного потрясен :) \n",
      "Tweet ignored due to unreadability: 今日発表だった＾ﾛ＾　 \n",
      "Tweet ignored due to unreadability: يبدو ان طفرة الاجهزة الالكترونية القادمة ستكون بقيادة موتورولا ،، لاسيم بعد استحواذ قوقل عليها.   \n",
      "Tweet ignored due to unreadability: 顔認識ロック解除失敗してる・・・デモで失敗しちゃっていいのか？ \n",
      "Tweet ignored due to unreadability: Με συγχισες \n",
      "Tweet ignored due to unreadability: デフォでデータ通信制御？　\n",
      "Tweet ignored due to unreadability: http://t.co/gAPEyL5N \n",
      "Tweet ignored due to unreadability: http://t.co/J3p3KYHf \n",
      "Tweet ignored due to unreadability: http://t.co/h1IH7FN6 مايكروسوفت تقوم بتطوير تقنية تمكنك من استخدام يدك كهاتف  \n",
      "Tweet ignored due to unreadability: http://t.co/ONI0JX8B \n",
      "Tweet ignored due to unreadability: http://t.co/JVidt6U4 \n",
      "Tweet ignored due to unreadability: На сайте \n",
      "Tweet ignored due to unreadability: ☼ \n",
      "Tweet ignored due to unreadability: Настоящий твиттерянин как только попадает в толпу стремиться тут же как можно быстрее попасть в \n",
      "Tweet ignored due to unreadability: Доброе утро \n",
      "Tweet ignored due to unreadability: 【\n",
      "Tweet ignored due to unreadability: なにやらフォロー制限に引っ掛かったようです…もっとフォロアーを増やさなくちゃ♪　\n",
      "Tweet ignored due to unreadability: ツイッターを利用して感謝の気持ちとともに約２０００円が振り込まれ続ける方法→ｺｺ→ http://t.co/TyjUGsnQ ←ｺｺ← :) \n",
      "Tweet ignored due to unreadability: رقم الفلو والفلورز والتويتات  للبيع لاعلى سعر \n",
      "Tweet ignored due to unreadability: قال الرئيس التنفيذي لشركة \n",
      "Tweet ignored due to unreadability: Улучшим продукты компании \n",
      "Tweet ignored due to unreadability: نفسي يوم يعدي علي تويتر من غير مشاكل فنية \n",
      "Tweet ignored due to unreadability: ツイッター検索 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "wandb: Currently logged in as: ars860 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">electric-smoke-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/ars860/text2sentiment_twit_classification\" target=\"_blank\">https://wandb.ai/ars860/text2sentiment_twit_classification</a><br/>\n                Run page: <a href=\"https://wandb.ai/ars860/text2sentiment_twit_classification/runs/3dq0a2rt\" target=\"_blank\">https://wandb.ai/ars860/text2sentiment_twit_classification/runs/3dq0a2rt</a><br/>\n                Run data is saved locally in <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_213327-3dq0a2rt</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, iter: 100/3382, mean loss: 0.42261880833655596\n",
      "Epoch 1/50, iter: 200/3382, mean loss: 0.023846450009150432\n",
      "Epoch 1/50, iter: 300/3382, mean loss: 0.010459279580500152\n",
      "Epoch 1/50, iter: 400/3382, mean loss: 0.008468175009966217\n",
      "Epoch 1/50, iter: 500/3382, mean loss: 0.021027950721418165\n",
      "Epoch 1/50, iter: 600/3382, mean loss: 0.003911573119510194\n",
      "Epoch 1/50, iter: 700/3382, mean loss: 0.005205889387016213\n",
      "Epoch 1/50, iter: 800/3382, mean loss: 0.0016406561168128065\n",
      "Epoch 1/50, iter: 900/3382, mean loss: 0.00439424554352513\n",
      "Epoch 1/50, iter: 1000/3382, mean loss: 0.5940594247990703\n",
      "Epoch 1/50, iter: 1100/3382, mean loss: 0.33317440437152984\n",
      "Epoch 1/50, iter: 1200/3382, mean loss: 0.07702367916877847\n",
      "Epoch 1/50, iter: 1300/3382, mean loss: 0.03264839368152025\n",
      "Epoch 1/50, iter: 1400/3382, mean loss: 0.02000695823757269\n",
      "Epoch 1/50, iter: 1500/3382, mean loss: 0.023298537346854574\n",
      "Epoch 1/50, iter: 1600/3382, mean loss: 0.04022621084817729\n",
      "Epoch 1/50, iter: 1700/3382, mean loss: 0.017431088487510352\n",
      "Epoch 1/50, iter: 1800/3382, mean loss: 0.9260841075305325\n",
      "Epoch 1/50, iter: 1900/3382, mean loss: 0.15282164822798222\n",
      "Epoch 1/50, iter: 2000/3382, mean loss: 0.0790184875097475\n",
      "Epoch 1/50, iter: 2100/3382, mean loss: 0.04528981564282731\n",
      "Epoch 1/50, iter: 2200/3382, mean loss: 0.053676615023214254\n",
      "Epoch 1/50, iter: 2300/3382, mean loss: 0.020213703218360024\n",
      "Epoch 1/50, iter: 2400/3382, mean loss: 0.024684533542822466\n",
      "Epoch 1/50, iter: 2500/3382, mean loss: 0.04244675081982223\n",
      "Epoch 1/50, iter: 2600/3382, mean loss: 0.9894714490702335\n",
      "Epoch 1/50, iter: 2700/3382, mean loss: 0.1685079692886211\n",
      "Epoch 1/50, iter: 2800/3382, mean loss: 0.06046551663952414\n",
      "Epoch 1/50, iter: 2900/3382, mean loss: 0.05413455879039247\n",
      "Epoch 1/50, iter: 3000/3382, mean loss: 0.04816974304434552\n",
      "Epoch 1/50, iter: 3100/3382, mean loss: 0.038086319937192456\n",
      "Epoch 1/50, iter: 3200/3382, mean loss: 0.02416254511288571\n",
      "Epoch 1/50, iter: 3300/3382, mean loss: 0.03368450917479095\n",
      "Epoch 2/50, iter: 100/3382, mean loss: 0.9559112191013992\n",
      "Epoch 2/50, iter: 200/3382, mean loss: 0.05150283170049079\n",
      "Epoch 2/50, iter: 300/3382, mean loss: 0.016450900986674243\n",
      "Epoch 2/50, iter: 400/3382, mean loss: 0.018381337017635814\n",
      "Epoch 2/50, iter: 500/3382, mean loss: 0.038054923907475315\n",
      "Epoch 2/50, iter: 600/3382, mean loss: 0.008605056723317829\n",
      "Epoch 2/50, iter: 700/3382, mean loss: 0.008907725008175476\n",
      "Epoch 2/50, iter: 800/3382, mean loss: 0.006292322749604864\n",
      "Epoch 2/50, iter: 900/3382, mean loss: 0.0022245229432155613\n",
      "Epoch 2/50, iter: 1000/3382, mean loss: 0.46850448394652633\n",
      "Epoch 2/50, iter: 1100/3382, mean loss: 0.4916018223389983\n",
      "Epoch 2/50, iter: 1200/3382, mean loss: 0.10733487773337401\n",
      "Epoch 2/50, iter: 1300/3382, mean loss: 0.0507271497065085\n",
      "Epoch 2/50, iter: 1400/3382, mean loss: 0.04924415840403526\n",
      "Epoch 2/50, iter: 1500/3382, mean loss: 0.035172790291617274\n",
      "Epoch 2/50, iter: 1600/3382, mean loss: 0.0541983558805623\n",
      "Epoch 2/50, iter: 1700/3382, mean loss: 0.021913102140915727\n",
      "Epoch 2/50, iter: 1800/3382, mean loss: 0.8516927562825731\n",
      "Epoch 2/50, iter: 1900/3382, mean loss: 0.25200531461043285\n",
      "Epoch 2/50, iter: 2000/3382, mean loss: 0.08981809883844108\n",
      "Epoch 2/50, iter: 2100/3382, mean loss: 0.052416899406234736\n",
      "Epoch 2/50, iter: 2200/3382, mean loss: 0.0626727439660317\n",
      "Epoch 2/50, iter: 2300/3382, mean loss: 0.02630329340985554\n",
      "Epoch 2/50, iter: 2400/3382, mean loss: 0.02393268288813488\n",
      "Epoch 2/50, iter: 2500/3382, mean loss: 0.041561014102799165\n",
      "Epoch 2/50, iter: 2600/3382, mean loss: 1.0043518438356795\n",
      "Epoch 2/50, iter: 2700/3382, mean loss: 0.16563518276438116\n",
      "Epoch 2/50, iter: 2800/3382, mean loss: 0.06417185278303805\n",
      "Epoch 2/50, iter: 2900/3382, mean loss: 0.047335430360817554\n",
      "Epoch 2/50, iter: 3000/3382, mean loss: 0.043975020870529985\n",
      "Epoch 2/50, iter: 3100/3382, mean loss: 0.027092208392368776\n",
      "Epoch 2/50, iter: 3200/3382, mean loss: 0.018161082072892895\n",
      "Epoch 2/50, iter: 3300/3382, mean loss: 0.024288867620207384\n",
      "Epoch 3/50, iter: 100/3382, mean loss: 0.8443562415940687\n",
      "Epoch 3/50, iter: 200/3382, mean loss: 0.04524585665145423\n",
      "Epoch 3/50, iter: 300/3382, mean loss: 0.01853972342752968\n",
      "Epoch 3/50, iter: 400/3382, mean loss: 0.011656671404052759\n",
      "Epoch 3/50, iter: 500/3382, mean loss: 0.026775266366894358\n",
      "Epoch 3/50, iter: 600/3382, mean loss: 0.00540192043325078\n",
      "Epoch 3/50, iter: 700/3382, mean loss: 0.008407714469249185\n",
      "Epoch 3/50, iter: 800/3382, mean loss: 0.008880330702777429\n",
      "Epoch 3/50, iter: 900/3382, mean loss: 0.00456143530409463\n",
      "Epoch 3/50, iter: 1000/3382, mean loss: 0.4830193328601035\n",
      "Epoch 3/50, iter: 1100/3382, mean loss: 0.43127878399332986\n",
      "Epoch 3/50, iter: 1200/3382, mean loss: 0.12355698078230488\n",
      "Epoch 3/50, iter: 1300/3382, mean loss: 0.0646906829677755\n",
      "Epoch 3/50, iter: 1400/3382, mean loss: 0.05728146052089869\n",
      "Epoch 3/50, iter: 1500/3382, mean loss: 0.03806172183001763\n",
      "Epoch 3/50, iter: 1600/3382, mean loss: 0.05182770389770667\n",
      "Epoch 3/50, iter: 1700/3382, mean loss: 0.021938584505496694\n",
      "Epoch 3/50, iter: 1800/3382, mean loss: 0.8101798690535543\n",
      "Epoch 3/50, iter: 1900/3382, mean loss: 0.3135860464628786\n",
      "Epoch 3/50, iter: 2000/3382, mean loss: 0.0927823008800624\n",
      "Epoch 3/50, iter: 2100/3382, mean loss: 0.05535759478865657\n",
      "Epoch 3/50, iter: 2200/3382, mean loss: 0.061559550181991655\n",
      "Epoch 3/50, iter: 2300/3382, mean loss: 0.025930950438014407\n",
      "Epoch 3/50, iter: 2400/3382, mean loss: 0.023341927935944112\n",
      "Epoch 3/50, iter: 2500/3382, mean loss: 0.03642290722742473\n",
      "Epoch 3/50, iter: 2600/3382, mean loss: 0.9369217192119504\n",
      "Epoch 3/50, iter: 2700/3382, mean loss: 0.1571969748940319\n",
      "Epoch 3/50, iter: 2800/3382, mean loss: 0.05905667044629809\n",
      "Epoch 3/50, iter: 2900/3382, mean loss: 0.044496029283327514\n",
      "Epoch 3/50, iter: 3000/3382, mean loss: 0.03708355290000327\n",
      "Epoch 3/50, iter: 3100/3382, mean loss: 0.02867033151087526\n",
      "Epoch 3/50, iter: 3200/3382, mean loss: 0.015506864318722365\n",
      "Epoch 3/50, iter: 3300/3382, mean loss: 0.02177972419636717\n",
      "Epoch 4/50, iter: 100/3382, mean loss: 0.725574150562752\n",
      "Epoch 4/50, iter: 200/3382, mean loss: 0.03919189319567522\n",
      "Epoch 4/50, iter: 300/3382, mean loss: 0.010621062611753586\n",
      "Epoch 4/50, iter: 400/3382, mean loss: 0.005926395336355199\n",
      "Epoch 4/50, iter: 500/3382, mean loss: 0.03019403229994168\n",
      "Epoch 4/50, iter: 600/3382, mean loss: 0.012601322823502414\n",
      "Epoch 4/50, iter: 700/3382, mean loss: 0.00710847827127509\n",
      "Epoch 4/50, iter: 800/3382, mean loss: 0.003091345494781308\n",
      "Epoch 4/50, iter: 900/3382, mean loss: 0.002007117260332052\n",
      "Epoch 4/50, iter: 1000/3382, mean loss: 0.47949945707319785\n",
      "Epoch 4/50, iter: 1100/3382, mean loss: 0.40564261248800904\n",
      "Epoch 4/50, iter: 1200/3382, mean loss: 0.0857623344453168\n",
      "Epoch 4/50, iter: 1300/3382, mean loss: 0.04142891086856253\n",
      "Epoch 4/50, iter: 1400/3382, mean loss: 0.025033599619891902\n",
      "Epoch 4/50, iter: 1500/3382, mean loss: 0.02829049409381696\n",
      "Epoch 4/50, iter: 1600/3382, mean loss: 0.04474157099077274\n",
      "Epoch 4/50, iter: 1700/3382, mean loss: 0.020971251485680114\n",
      "Epoch 4/50, iter: 1800/3382, mean loss: 0.7824629281036141\n",
      "Epoch 4/50, iter: 1900/3382, mean loss: 0.34390459921211003\n",
      "Epoch 4/50, iter: 2000/3382, mean loss: 0.09464771800092421\n",
      "Epoch 4/50, iter: 2100/3382, mean loss: 0.05609381278452929\n",
      "Epoch 4/50, iter: 2200/3382, mean loss: 0.049625641261591226\n",
      "Epoch 4/50, iter: 2300/3382, mean loss: 0.025214346103821297\n",
      "Epoch 4/50, iter: 2400/3382, mean loss: 0.02038326248552039\n",
      "Epoch 4/50, iter: 2500/3382, mean loss: 0.03073441068543616\n",
      "Epoch 4/50, iter: 2600/3382, mean loss: 0.8978453432233254\n",
      "Epoch 4/50, iter: 2700/3382, mean loss: 0.15268219771736768\n",
      "Epoch 4/50, iter: 2800/3382, mean loss: 0.06130773461423814\n",
      "Epoch 4/50, iter: 2900/3382, mean loss: 0.03786295636404247\n",
      "Epoch 4/50, iter: 3000/3382, mean loss: 0.03989634202553134\n",
      "Epoch 4/50, iter: 3100/3382, mean loss: 0.02203400518618764\n",
      "Epoch 4/50, iter: 3200/3382, mean loss: 0.02175772534513044\n",
      "Epoch 4/50, iter: 3300/3382, mean loss: 0.018704040946458916\n",
      "Epoch 5/50, iter: 100/3382, mean loss: 0.9020778089598752\n",
      "Epoch 5/50, iter: 200/3382, mean loss: 0.03814700448245276\n",
      "Epoch 5/50, iter: 300/3382, mean loss: 0.01225393764776527\n",
      "Epoch 5/50, iter: 400/3382, mean loss: 0.007248015417590068\n",
      "Epoch 5/50, iter: 500/3382, mean loss: 0.019443374549373404\n",
      "Epoch 5/50, iter: 600/3382, mean loss: 0.004374286492420652\n",
      "Epoch 5/50, iter: 700/3382, mean loss: 0.006154977530559336\n",
      "Epoch 5/50, iter: 800/3382, mean loss: 0.005558791214625671\n",
      "Epoch 5/50, iter: 900/3382, mean loss: 0.003496339792991421\n",
      "Epoch 5/50, iter: 1000/3382, mean loss: 0.4045156412790584\n",
      "Epoch 5/50, iter: 1100/3382, mean loss: 0.42559392856433986\n",
      "Epoch 5/50, iter: 1200/3382, mean loss: 0.0937219037633622\n",
      "Epoch 5/50, iter: 1300/3382, mean loss: 0.03430094698211178\n",
      "Epoch 5/50, iter: 1400/3382, mean loss: 0.02757947587113449\n",
      "Epoch 5/50, iter: 1500/3382, mean loss: 0.023561798471346266\n",
      "Epoch 5/50, iter: 1600/3382, mean loss: 0.037517475957201896\n",
      "Epoch 5/50, iter: 1700/3382, mean loss: 0.020105443498282513\n",
      "Epoch 5/50, iter: 1800/3382, mean loss: 0.7278467876749392\n",
      "Epoch 5/50, iter: 1900/3382, mean loss: 0.3199039133824408\n",
      "Epoch 5/50, iter: 2000/3382, mean loss: 0.08961507262225496\n",
      "Epoch 5/50, iter: 2100/3382, mean loss: 0.04449994741968112\n",
      "Epoch 5/50, iter: 2200/3382, mean loss: 0.05373338521801998\n",
      "Epoch 5/50, iter: 2300/3382, mean loss: 0.0244549577545331\n",
      "Epoch 5/50, iter: 2400/3382, mean loss: 0.024503724251794666\n",
      "Epoch 5/50, iter: 2500/3382, mean loss: 0.028122118044371404\n",
      "Epoch 5/50, iter: 2600/3382, mean loss: 0.7891757594003956\n",
      "Epoch 5/50, iter: 2700/3382, mean loss: 0.18495291340281256\n",
      "Epoch 5/50, iter: 2800/3382, mean loss: 0.05554818021657411\n",
      "Epoch 5/50, iter: 2900/3382, mean loss: 0.03247744943968428\n",
      "Epoch 5/50, iter: 3000/3382, mean loss: 0.044582968303202505\n",
      "Epoch 5/50, iter: 3100/3382, mean loss: 0.027529824487619408\n",
      "Epoch 5/50, iter: 3200/3382, mean loss: 0.015827284086144575\n",
      "Epoch 5/50, iter: 3300/3382, mean loss: 0.014543275036319301\n",
      "Epoch 6/50, iter: 100/3382, mean loss: 0.8380521848378703\n",
      "Epoch 6/50, iter: 200/3382, mean loss: 0.06177627083612606\n",
      "Epoch 6/50, iter: 300/3382, mean loss: 0.015382956389075844\n",
      "Epoch 6/50, iter: 400/3382, mean loss: 0.007378184016488376\n",
      "Epoch 6/50, iter: 500/3382, mean loss: 0.027885680027102355\n",
      "Epoch 6/50, iter: 600/3382, mean loss: 0.009022229463935218\n",
      "Epoch 6/50, iter: 700/3382, mean loss: 0.00613034206519842\n",
      "Epoch 6/50, iter: 800/3382, mean loss: 0.0061345878351630745\n",
      "Epoch 6/50, iter: 900/3382, mean loss: 0.00394670393978231\n",
      "Epoch 6/50, iter: 1000/3382, mean loss: 0.3725582811264826\n",
      "Epoch 6/50, iter: 1100/3382, mean loss: 0.47410158220678567\n",
      "Epoch 6/50, iter: 1200/3382, mean loss: 0.13109000379277858\n",
      "Epoch 6/50, iter: 1300/3382, mean loss: 0.04799638629199762\n",
      "Epoch 6/50, iter: 1400/3382, mean loss: 0.02983304774050339\n",
      "Epoch 6/50, iter: 1500/3382, mean loss: 0.024991708599445703\n",
      "Epoch 6/50, iter: 1600/3382, mean loss: 0.042596035130327434\n",
      "Epoch 6/50, iter: 1700/3382, mean loss: 0.017116823616415786\n",
      "Epoch 6/50, iter: 1800/3382, mean loss: 0.6303112690786702\n",
      "Epoch 6/50, iter: 1900/3382, mean loss: 0.3734536761417985\n",
      "Epoch 6/50, iter: 2000/3382, mean loss: 0.10636546170921064\n",
      "Epoch 6/50, iter: 2100/3382, mean loss: 0.06154259413611726\n",
      "Epoch 6/50, iter: 2200/3382, mean loss: 0.053045440048299496\n",
      "Epoch 6/50, iter: 2300/3382, mean loss: 0.023819069367382328\n",
      "Epoch 6/50, iter: 2400/3382, mean loss: 0.0220749531994079\n",
      "Epoch 6/50, iter: 2500/3382, mean loss: 0.02886245416399106\n",
      "Epoch 6/50, iter: 2600/3382, mean loss: 0.8177745109504212\n",
      "Epoch 6/50, iter: 2700/3382, mean loss: 0.20883389269700273\n",
      "Epoch 6/50, iter: 2800/3382, mean loss: 0.0856075349466846\n",
      "Epoch 6/50, iter: 2900/3382, mean loss: 0.05024834616378939\n",
      "Epoch 6/50, iter: 3000/3382, mean loss: 0.05762795445190932\n",
      "Epoch 6/50, iter: 3100/3382, mean loss: 0.028730126835780537\n",
      "Epoch 6/50, iter: 3200/3382, mean loss: 0.018049988351713182\n",
      "Epoch 6/50, iter: 3300/3382, mean loss: 0.02140623527473281\n",
      "Epoch 7/50, iter: 100/3382, mean loss: 0.8202042756252922\n",
      "Epoch 7/50, iter: 200/3382, mean loss: 0.11086561090429313\n",
      "Epoch 7/50, iter: 300/3382, mean loss: 0.01496800204833562\n",
      "Epoch 7/50, iter: 400/3382, mean loss: 0.010987417212040782\n",
      "Epoch 7/50, iter: 500/3382, mean loss: 0.028728336472704542\n",
      "Epoch 7/50, iter: 600/3382, mean loss: 0.010675653011594477\n",
      "Epoch 7/50, iter: 700/3382, mean loss: 0.004486506809258799\n",
      "Epoch 7/50, iter: 800/3382, mean loss: 0.006733851626004253\n",
      "Epoch 7/50, iter: 900/3382, mean loss: 0.005721917087530528\n",
      "Epoch 7/50, iter: 1000/3382, mean loss: 0.35585344379347816\n",
      "Epoch 7/50, iter: 1100/3382, mean loss: 0.43621350817382337\n",
      "Epoch 7/50, iter: 1200/3382, mean loss: 0.1675058021233417\n",
      "Epoch 7/50, iter: 1300/3382, mean loss: 0.06249284588731825\n",
      "Epoch 7/50, iter: 1400/3382, mean loss: 0.03520829852361203\n",
      "Epoch 7/50, iter: 1500/3382, mean loss: 0.02601992770054494\n",
      "Epoch 7/50, iter: 1600/3382, mean loss: 0.03290505543642666\n",
      "Epoch 7/50, iter: 1700/3382, mean loss: 0.022506407815972126\n",
      "Epoch 7/50, iter: 1800/3382, mean loss: 0.5813870653326012\n",
      "Epoch 7/50, iter: 1900/3382, mean loss: 0.4395470490120351\n",
      "Epoch 7/50, iter: 2000/3382, mean loss: 0.1395938532240689\n",
      "Epoch 7/50, iter: 2100/3382, mean loss: 0.0688774206439848\n",
      "Epoch 7/50, iter: 2200/3382, mean loss: 0.05003886580285325\n",
      "Epoch 7/50, iter: 2300/3382, mean loss: 0.02768545328101027\n",
      "Epoch 7/50, iter: 2400/3382, mean loss: 0.025753350207869518\n",
      "Epoch 7/50, iter: 2500/3382, mean loss: 0.03167310642501661\n",
      "Epoch 7/50, iter: 2600/3382, mean loss: 0.8009833608524058\n",
      "Epoch 7/50, iter: 2700/3382, mean loss: 0.2614131148997694\n",
      "Epoch 7/50, iter: 2800/3382, mean loss: 0.0992028361975099\n",
      "Epoch 7/50, iter: 2900/3382, mean loss: 0.04097596369007078\n",
      "Epoch 7/50, iter: 3000/3382, mean loss: 0.04362682901002699\n",
      "Epoch 7/50, iter: 3100/3382, mean loss: 0.024007482502202037\n",
      "Epoch 7/50, iter: 3200/3382, mean loss: 0.014579431199640567\n",
      "Epoch 7/50, iter: 3300/3382, mean loss: 0.022996370603786998\n",
      "Epoch 8/50, iter: 100/3382, mean loss: 0.6511590416653781\n",
      "Epoch 8/50, iter: 200/3382, mean loss: 0.07656102004839341\n",
      "Epoch 8/50, iter: 300/3382, mean loss: 0.01597351466974942\n",
      "Epoch 8/50, iter: 400/3382, mean loss: 0.008398049837524013\n",
      "Epoch 8/50, iter: 500/3382, mean loss: 0.03292742921992613\n",
      "Epoch 8/50, iter: 600/3382, mean loss: 0.018606121850330056\n",
      "Epoch 8/50, iter: 700/3382, mean loss: 0.006090901623974787\n",
      "Epoch 8/50, iter: 800/3382, mean loss: 0.008911201250598424\n",
      "Epoch 8/50, iter: 900/3382, mean loss: 0.013935019652408301\n",
      "Epoch 8/50, iter: 1000/3382, mean loss: 0.3408070553018433\n",
      "Epoch 8/50, iter: 1100/3382, mean loss: 0.41795405006501823\n",
      "Epoch 8/50, iter: 1200/3382, mean loss: 0.16571694132871925\n",
      "Epoch 8/50, iter: 1300/3382, mean loss: 0.0630766005665646\n",
      "Epoch 8/50, iter: 1400/3382, mean loss: 0.04020753273156515\n",
      "Epoch 8/50, iter: 1500/3382, mean loss: 0.02987050438667211\n",
      "Epoch 8/50, iter: 1600/3382, mean loss: 0.030312010513273435\n",
      "Epoch 8/50, iter: 1700/3382, mean loss: 0.021068226137485907\n",
      "Epoch 8/50, iter: 1800/3382, mean loss: 0.5454108952967135\n",
      "Epoch 8/50, iter: 1900/3382, mean loss: 0.4181285494565964\n",
      "Epoch 8/50, iter: 2000/3382, mean loss: 0.1590910860861186\n",
      "Epoch 8/50, iter: 2100/3382, mean loss: 0.0646950454088801\n",
      "Epoch 8/50, iter: 2200/3382, mean loss: 0.050762713811564025\n",
      "Epoch 8/50, iter: 2300/3382, mean loss: 0.03751560807326314\n",
      "Epoch 8/50, iter: 2400/3382, mean loss: 0.020976898834487657\n",
      "Epoch 8/50, iter: 2500/3382, mean loss: 0.02705244181695889\n",
      "Epoch 8/50, iter: 2600/3382, mean loss: 0.7011910704670299\n",
      "Epoch 8/50, iter: 2700/3382, mean loss: 0.29443959271768105\n",
      "Epoch 8/50, iter: 2800/3382, mean loss: 0.1387355885945726\n",
      "Epoch 8/50, iter: 2900/3382, mean loss: 0.05888625219784444\n",
      "Epoch 8/50, iter: 3000/3382, mean loss: 0.05056948625096993\n",
      "Epoch 8/50, iter: 3100/3382, mean loss: 0.02499742166000942\n",
      "Epoch 8/50, iter: 3200/3382, mean loss: 0.017773838377520404\n",
      "Epoch 8/50, iter: 3300/3382, mean loss: 0.02385966161884653\n",
      "Epoch 9/50, iter: 100/3382, mean loss: 0.6893100169487297\n",
      "Epoch 9/50, iter: 200/3382, mean loss: 0.11024992931401358\n",
      "Epoch 9/50, iter: 300/3382, mean loss: 0.01411022239986778\n",
      "Epoch 9/50, iter: 400/3382, mean loss: 0.009253714667866007\n",
      "Epoch 9/50, iter: 500/3382, mean loss: 0.033915541946098526\n",
      "Epoch 9/50, iter: 600/3382, mean loss: 0.014484576527465834\n",
      "Epoch 9/50, iter: 700/3382, mean loss: 0.010529844877619326\n",
      "Epoch 9/50, iter: 800/3382, mean loss: 0.00614870308988543\n",
      "Epoch 9/50, iter: 900/3382, mean loss: 0.006276910499027508\n",
      "Epoch 9/50, iter: 1000/3382, mean loss: 0.2489520704464121\n",
      "Epoch 9/50, iter: 1100/3382, mean loss: 0.38213564404984934\n",
      "Epoch 9/50, iter: 1200/3382, mean loss: 0.19297228157171048\n",
      "Epoch 9/50, iter: 1300/3382, mean loss: 0.139312619523771\n",
      "Epoch 9/50, iter: 1400/3382, mean loss: 0.04710841519122596\n",
      "Epoch 9/50, iter: 1500/3382, mean loss: 0.03734404355197512\n",
      "Epoch 9/50, iter: 1600/3382, mean loss: 0.04787796512229761\n",
      "Epoch 9/50, iter: 1700/3382, mean loss: 0.02361076027994386\n",
      "Epoch 9/50, iter: 1800/3382, mean loss: 0.5884295688999372\n",
      "Epoch 9/50, iter: 1900/3382, mean loss: 0.5280754577368498\n",
      "Epoch 9/50, iter: 2000/3382, mean loss: 0.32636050197295846\n",
      "Epoch 9/50, iter: 2100/3382, mean loss: 0.11454806626192295\n",
      "Epoch 9/50, iter: 2200/3382, mean loss: 0.07178645031235646\n",
      "Epoch 9/50, iter: 2300/3382, mean loss: 0.04183226470544468\n",
      "Epoch 9/50, iter: 2400/3382, mean loss: 0.045693967962433815\n",
      "Epoch 9/50, iter: 2500/3382, mean loss: 0.029342830557288833\n",
      "Epoch 9/50, iter: 2600/3382, mean loss: 0.666304833014874\n",
      "Epoch 9/50, iter: 2700/3382, mean loss: 0.32253880936652424\n",
      "Epoch 9/50, iter: 2800/3382, mean loss: 0.22044045981951058\n",
      "Epoch 9/50, iter: 2900/3382, mean loss: 0.11324246446485631\n",
      "Epoch 9/50, iter: 3000/3382, mean loss: 0.06824439880685532\n",
      "Epoch 9/50, iter: 3100/3382, mean loss: 0.04066787715522878\n",
      "Epoch 9/50, iter: 3200/3382, mean loss: 0.02382829259011487\n",
      "Epoch 9/50, iter: 3300/3382, mean loss: 0.04599180684572275\n",
      "Epoch 10/50, iter: 100/3382, mean loss: 0.6120662991222343\n",
      "Epoch 10/50, iter: 200/3382, mean loss: 0.08726878558547468\n",
      "Epoch 10/50, iter: 300/3382, mean loss: 0.018418583479797235\n",
      "Epoch 10/50, iter: 400/3382, mean loss: 0.017230784680068608\n",
      "Epoch 10/50, iter: 500/3382, mean loss: 0.03495063916501749\n",
      "Epoch 10/50, iter: 600/3382, mean loss: 0.01517706519188323\n",
      "Epoch 10/50, iter: 700/3382, mean loss: 0.006166181501321262\n",
      "Epoch 10/50, iter: 800/3382, mean loss: 0.024308487781263467\n",
      "Epoch 10/50, iter: 900/3382, mean loss: 0.01616791976076911\n",
      "Epoch 10/50, iter: 1000/3382, mean loss: 0.24592297828982737\n",
      "Epoch 10/50, iter: 1100/3382, mean loss: 0.3362640043115243\n",
      "Epoch 10/50, iter: 1200/3382, mean loss: 0.17687025331222686\n",
      "Epoch 10/50, iter: 1300/3382, mean loss: 0.0906710486902739\n",
      "Epoch 10/50, iter: 1400/3382, mean loss: 0.08231638932535133\n",
      "Epoch 10/50, iter: 1500/3382, mean loss: 0.03822624125021776\n",
      "Epoch 10/50, iter: 1600/3382, mean loss: 0.04452429494070259\n",
      "Epoch 10/50, iter: 1700/3382, mean loss: 0.023736285658060297\n",
      "Epoch 10/50, iter: 1800/3382, mean loss: 0.5134121538455907\n",
      "Epoch 10/50, iter: 1900/3382, mean loss: 0.3971739028953016\n",
      "Epoch 10/50, iter: 2000/3382, mean loss: 0.24582123138941825\n",
      "Epoch 10/50, iter: 2100/3382, mean loss: 0.10112644559529144\n",
      "Epoch 10/50, iter: 2200/3382, mean loss: 0.0732102377541014\n",
      "Epoch 10/50, iter: 2300/3382, mean loss: 0.04740768312646651\n",
      "Epoch 10/50, iter: 2400/3382, mean loss: 0.030443525674454578\n",
      "Epoch 10/50, iter: 2500/3382, mean loss: 0.03897322268385324\n",
      "Epoch 10/50, iter: 2600/3382, mean loss: 0.5578820837146486\n",
      "Epoch 10/50, iter: 2700/3382, mean loss: 0.298808822814899\n",
      "Epoch 10/50, iter: 2800/3382, mean loss: 0.16270563831785695\n",
      "Epoch 10/50, iter: 2900/3382, mean loss: 0.10904291916347575\n",
      "Epoch 10/50, iter: 3000/3382, mean loss: 0.10642508989640191\n",
      "Epoch 10/50, iter: 3100/3382, mean loss: 0.052273154514550696\n",
      "Epoch 10/50, iter: 3200/3382, mean loss: 0.024005769866107585\n",
      "Epoch 10/50, iter: 3300/3382, mean loss: 0.028561617343102627\n",
      "Epoch 11/50, iter: 100/3382, mean loss: 0.6627811310300603\n",
      "Epoch 11/50, iter: 200/3382, mean loss: 0.1279894328676164\n",
      "Epoch 11/50, iter: 300/3382, mean loss: 0.021610699808170465\n",
      "Epoch 11/50, iter: 400/3382, mean loss: 0.033935431330291976\n",
      "Epoch 11/50, iter: 500/3382, mean loss: 0.028769718681523955\n",
      "Epoch 11/50, iter: 600/3382, mean loss: 0.020809928527396552\n",
      "Epoch 11/50, iter: 700/3382, mean loss: 0.0071234428988964284\n",
      "Epoch 11/50, iter: 800/3382, mean loss: 0.00760276786065333\n",
      "Epoch 11/50, iter: 900/3382, mean loss: 0.011395761779446047\n",
      "Epoch 11/50, iter: 1000/3382, mean loss: 0.18098069774674058\n",
      "Epoch 11/50, iter: 1100/3382, mean loss: 0.31564313546172346\n",
      "Epoch 11/50, iter: 1200/3382, mean loss: 0.2311962918296922\n",
      "Epoch 11/50, iter: 1300/3382, mean loss: 0.09776711454280303\n",
      "Epoch 11/50, iter: 1400/3382, mean loss: 0.0641661771901272\n",
      "Epoch 11/50, iter: 1500/3382, mean loss: 0.044857785416272694\n",
      "Epoch 11/50, iter: 1600/3382, mean loss: 0.05539863526519184\n",
      "Epoch 11/50, iter: 1700/3382, mean loss: 0.026154211277954573\n",
      "Epoch 11/50, iter: 1800/3382, mean loss: 0.48132732909078185\n",
      "Epoch 11/50, iter: 1900/3382, mean loss: 0.3950350584089756\n",
      "Epoch 11/50, iter: 2000/3382, mean loss: 0.2752365874964744\n",
      "Epoch 11/50, iter: 2100/3382, mean loss: 0.14758079232065938\n",
      "Epoch 11/50, iter: 2200/3382, mean loss: 0.10329601705598179\n",
      "Epoch 11/50, iter: 2300/3382, mean loss: 0.05705751370507642\n",
      "Epoch 11/50, iter: 2400/3382, mean loss: 0.04748748750222148\n",
      "Epoch 11/50, iter: 2500/3382, mean loss: 0.023134587241365807\n",
      "Epoch 11/50, iter: 2600/3382, mean loss: 0.5388151027615277\n",
      "Epoch 11/50, iter: 2700/3382, mean loss: 0.2514107269454689\n",
      "Epoch 11/50, iter: 2800/3382, mean loss: 0.12462562722852454\n",
      "Epoch 11/50, iter: 2900/3382, mean loss: 0.12077688679681159\n",
      "Epoch 11/50, iter: 3000/3382, mean loss: 0.11558653146377765\n",
      "Epoch 11/50, iter: 3100/3382, mean loss: 0.06544126683253125\n",
      "Epoch 11/50, iter: 3200/3382, mean loss: 0.02782560279534664\n",
      "Epoch 11/50, iter: 3300/3382, mean loss: 0.03239503134560437\n",
      "Epoch 12/50, iter: 100/3382, mean loss: 0.47637258971808477\n",
      "Epoch 12/50, iter: 200/3382, mean loss: 0.08636478147120215\n",
      "Epoch 12/50, iter: 300/3382, mean loss: 0.032065739266618036\n",
      "Epoch 12/50, iter: 400/3382, mean loss: 0.01414965623098169\n",
      "Epoch 12/50, iter: 500/3382, mean loss: 0.04835788615534056\n",
      "Epoch 12/50, iter: 600/3382, mean loss: 0.020498463582175646\n",
      "Epoch 12/50, iter: 700/3382, mean loss: 0.008269786246853528\n",
      "Epoch 12/50, iter: 800/3382, mean loss: 0.018461973871632155\n",
      "Epoch 12/50, iter: 900/3382, mean loss: 0.02523469799000509\n",
      "Epoch 12/50, iter: 1000/3382, mean loss: 0.1674218319123682\n",
      "Epoch 12/50, iter: 1100/3382, mean loss: 0.31633972518378867\n",
      "Epoch 12/50, iter: 1200/3382, mean loss: 0.2564514324814081\n",
      "Epoch 12/50, iter: 1300/3382, mean loss: 0.1535062574336189\n",
      "Epoch 12/50, iter: 1400/3382, mean loss: 0.08128429833212067\n",
      "Epoch 12/50, iter: 1500/3382, mean loss: 0.06092649126815559\n",
      "Epoch 12/50, iter: 1600/3382, mean loss: 0.043322686912609924\n",
      "Epoch 12/50, iter: 1700/3382, mean loss: 0.033595122907399855\n",
      "Epoch 12/50, iter: 1800/3382, mean loss: 0.34091133068205637\n",
      "Epoch 12/50, iter: 1900/3382, mean loss: 0.32595170514425265\n",
      "Epoch 12/50, iter: 2000/3382, mean loss: 0.19781622274254915\n",
      "Epoch 12/50, iter: 2100/3382, mean loss: 0.1338241072226083\n",
      "Epoch 12/50, iter: 2200/3382, mean loss: 0.08976665710193629\n",
      "Epoch 12/50, iter: 2300/3382, mean loss: 0.051572626393972316\n",
      "Epoch 12/50, iter: 2400/3382, mean loss: 0.03285545867965993\n",
      "Epoch 12/50, iter: 2500/3382, mean loss: 0.0374507531424706\n",
      "Epoch 12/50, iter: 2600/3382, mean loss: 0.39841977989965927\n",
      "Epoch 12/50, iter: 2700/3382, mean loss: 0.25622240466647783\n",
      "Epoch 12/50, iter: 2800/3382, mean loss: 0.1797762954677455\n",
      "Epoch 12/50, iter: 2900/3382, mean loss: 0.11524451146695355\n",
      "Epoch 12/50, iter: 3000/3382, mean loss: 0.14864981922175502\n",
      "Epoch 12/50, iter: 3100/3382, mean loss: 0.07080775242917298\n",
      "Epoch 12/50, iter: 3200/3382, mean loss: 0.0513207628501641\n",
      "Epoch 12/50, iter: 3300/3382, mean loss: 0.026941971599626413\n",
      "Epoch 13/50, iter: 100/3382, mean loss: 0.36058384329429827\n",
      "Epoch 13/50, iter: 200/3382, mean loss: 0.04487968911980715\n",
      "Epoch 13/50, iter: 300/3382, mean loss: 0.029992414991102122\n",
      "Epoch 13/50, iter: 400/3382, mean loss: 0.023030881449835762\n",
      "Epoch 13/50, iter: 500/3382, mean loss: 0.05304701686914882\n",
      "Epoch 13/50, iter: 600/3382, mean loss: 0.03604901213305766\n",
      "Epoch 13/50, iter: 700/3382, mean loss: 0.010598082516444833\n",
      "Epoch 13/50, iter: 800/3382, mean loss: 0.029740193640138843\n",
      "Epoch 13/50, iter: 900/3382, mean loss: 0.015524008316594973\n",
      "Epoch 13/50, iter: 1000/3382, mean loss: 0.12244436239441597\n",
      "Epoch 13/50, iter: 1100/3382, mean loss: 0.2839084431726951\n",
      "Epoch 13/50, iter: 1200/3382, mean loss: 0.2336635375651531\n",
      "Epoch 13/50, iter: 1300/3382, mean loss: 0.1422369277842381\n",
      "Epoch 13/50, iter: 1400/3382, mean loss: 0.09173517220591293\n",
      "Epoch 13/50, iter: 1500/3382, mean loss: 0.0770752400325216\n",
      "Epoch 13/50, iter: 1600/3382, mean loss: 0.07862419207011499\n",
      "Epoch 13/50, iter: 1700/3382, mean loss: 0.027094627604379865\n",
      "Epoch 13/50, iter: 1800/3382, mean loss: 0.293634479838056\n",
      "Epoch 13/50, iter: 1900/3382, mean loss: 0.251231160487514\n",
      "Epoch 13/50, iter: 2000/3382, mean loss: 0.22859356246539392\n",
      "Epoch 13/50, iter: 2100/3382, mean loss: 0.11235732325611025\n",
      "Epoch 13/50, iter: 2200/3382, mean loss: 0.07584832135564284\n",
      "Epoch 13/50, iter: 2300/3382, mean loss: 0.05525676981764263\n",
      "Epoch 13/50, iter: 2400/3382, mean loss: 0.04526367972270464\n",
      "Epoch 13/50, iter: 2500/3382, mean loss: 0.03154494643999442\n",
      "Epoch 13/50, iter: 2600/3382, mean loss: 0.36779740030436187\n",
      "Epoch 13/50, iter: 2700/3382, mean loss: 0.20072170026949607\n",
      "Epoch 13/50, iter: 2800/3382, mean loss: 0.1620744601840852\n",
      "Epoch 13/50, iter: 2900/3382, mean loss: 0.13001368649798678\n",
      "Epoch 13/50, iter: 3000/3382, mean loss: 0.16927294355558842\n",
      "Epoch 13/50, iter: 3100/3382, mean loss: 0.06873786959735298\n",
      "Epoch 13/50, iter: 3200/3382, mean loss: 0.033115243320453375\n",
      "Epoch 13/50, iter: 3300/3382, mean loss: 0.03344537414415754\n",
      "Epoch 14/50, iter: 100/3382, mean loss: 0.23581866118096514\n",
      "Epoch 14/50, iter: 200/3382, mean loss: 0.10095032112014451\n",
      "Epoch 14/50, iter: 300/3382, mean loss: 0.02496898897162737\n",
      "Epoch 14/50, iter: 400/3382, mean loss: 0.02321398939931214\n",
      "Epoch 14/50, iter: 500/3382, mean loss: 0.05190979649488327\n",
      "Epoch 14/50, iter: 600/3382, mean loss: 0.029078294666763895\n",
      "Epoch 14/50, iter: 700/3382, mean loss: 0.005828861794362865\n",
      "Epoch 14/50, iter: 800/3382, mean loss: 0.023807638557887038\n",
      "Epoch 14/50, iter: 900/3382, mean loss: 0.03458383652474325\n",
      "Epoch 14/50, iter: 1000/3382, mean loss: 0.1298832659209188\n",
      "Epoch 14/50, iter: 1100/3382, mean loss: 0.30801393145287875\n",
      "Epoch 14/50, iter: 1200/3382, mean loss: 0.20889620736896178\n",
      "Epoch 14/50, iter: 1300/3382, mean loss: 0.15674598060570133\n",
      "Epoch 14/50, iter: 1400/3382, mean loss: 0.1396816756228327\n",
      "Epoch 14/50, iter: 1500/3382, mean loss: 0.07597272131774503\n",
      "Epoch 14/50, iter: 1600/3382, mean loss: 0.07404880757969749\n",
      "Epoch 14/50, iter: 1700/3382, mean loss: 0.04134476358711026\n",
      "Epoch 14/50, iter: 1800/3382, mean loss: 0.2616402796074306\n",
      "Epoch 14/50, iter: 1900/3382, mean loss: 0.2820610539359041\n",
      "Epoch 14/50, iter: 2000/3382, mean loss: 0.17492811475676717\n",
      "Epoch 14/50, iter: 2100/3382, mean loss: 0.11755617368449749\n",
      "Epoch 14/50, iter: 2200/3382, mean loss: 0.08908364916023856\n",
      "Epoch 14/50, iter: 2300/3382, mean loss: 0.06244126140896697\n",
      "Epoch 14/50, iter: 2400/3382, mean loss: 0.059182704048746475\n",
      "Epoch 14/50, iter: 2500/3382, mean loss: 0.03545535172190057\n",
      "Epoch 14/50, iter: 2600/3382, mean loss: 0.28053257980250806\n",
      "Epoch 14/50, iter: 2700/3382, mean loss: 0.15241309438366443\n",
      "Epoch 14/50, iter: 2800/3382, mean loss: 0.1178085437315167\n",
      "Epoch 14/50, iter: 2900/3382, mean loss: 0.1399666892242385\n",
      "Epoch 14/50, iter: 3000/3382, mean loss: 0.14524002068181288\n",
      "Epoch 14/50, iter: 3100/3382, mean loss: 0.10352796328446857\n",
      "Epoch 14/50, iter: 3200/3382, mean loss: 0.07140372105079223\n",
      "Epoch 14/50, iter: 3300/3382, mean loss: 0.03500092622891316\n",
      "Epoch 15/50, iter: 100/3382, mean loss: 0.14857275043148546\n",
      "Epoch 15/50, iter: 200/3382, mean loss: 0.054338036535291394\n",
      "Epoch 15/50, iter: 300/3382, mean loss: 0.01752695056694847\n",
      "Epoch 15/50, iter: 400/3382, mean loss: 0.027695929806327513\n",
      "Epoch 15/50, iter: 500/3382, mean loss: 0.06348797917241775\n",
      "Epoch 15/50, iter: 600/3382, mean loss: 0.014304856761362998\n",
      "Epoch 15/50, iter: 700/3382, mean loss: 0.007840938249546453\n",
      "Epoch 15/50, iter: 800/3382, mean loss: 0.01585853490641128\n",
      "Epoch 15/50, iter: 900/3382, mean loss: 0.01698834972388255\n",
      "Epoch 15/50, iter: 1000/3382, mean loss: 0.0967853731126258\n",
      "Epoch 15/50, iter: 1100/3382, mean loss: 0.18036138034873148\n",
      "Epoch 15/50, iter: 1200/3382, mean loss: 0.14879140657815015\n",
      "Epoch 15/50, iter: 1300/3382, mean loss: 0.12507086032549977\n",
      "Epoch 15/50, iter: 1400/3382, mean loss: 0.069100997203318\n",
      "Epoch 15/50, iter: 1500/3382, mean loss: 0.07728049006272243\n",
      "Epoch 15/50, iter: 1600/3382, mean loss: 0.05938389006786252\n",
      "Epoch 15/50, iter: 1700/3382, mean loss: 0.019929594756675897\n",
      "Epoch 15/50, iter: 1800/3382, mean loss: 0.20941868096449412\n",
      "Epoch 15/50, iter: 1900/3382, mean loss: 0.20164603447483387\n",
      "Epoch 15/50, iter: 2000/3382, mean loss: 0.17407577164922258\n",
      "Epoch 15/50, iter: 2100/3382, mean loss: 0.14797459901179535\n",
      "Epoch 15/50, iter: 2200/3382, mean loss: 0.08815684980672814\n",
      "Epoch 15/50, iter: 2300/3382, mean loss: 0.0717001342677122\n",
      "Epoch 15/50, iter: 2400/3382, mean loss: 0.07874638465068529\n",
      "Epoch 15/50, iter: 2500/3382, mean loss: 0.02818818555745139\n",
      "Epoch 15/50, iter: 2600/3382, mean loss: 0.2582844076499879\n",
      "Epoch 15/50, iter: 2700/3382, mean loss: 0.13892530986573548\n",
      "Epoch 15/50, iter: 2800/3382, mean loss: 0.11537664287840016\n",
      "Epoch 15/50, iter: 2900/3382, mean loss: 0.13031920681562043\n",
      "Epoch 15/50, iter: 3000/3382, mean loss: 0.14814970907653333\n",
      "Epoch 15/50, iter: 3100/3382, mean loss: 0.1160556893500052\n",
      "Epoch 15/50, iter: 3200/3382, mean loss: 0.08265927141857446\n",
      "Epoch 15/50, iter: 3300/3382, mean loss: 0.0244520491655976\n",
      "Epoch 16/50, iter: 100/3382, mean loss: 0.14580774548947376\n",
      "Epoch 16/50, iter: 200/3382, mean loss: 0.04201307828550369\n",
      "Epoch 16/50, iter: 300/3382, mean loss: 0.024849061056107756\n",
      "Epoch 16/50, iter: 400/3382, mean loss: 0.021708075000130406\n",
      "Epoch 16/50, iter: 500/3382, mean loss: 0.045754034080415805\n",
      "Epoch 16/50, iter: 600/3382, mean loss: 0.006542253114351553\n",
      "Epoch 16/50, iter: 700/3382, mean loss: 0.0324846200274608\n",
      "Epoch 16/50, iter: 800/3382, mean loss: 0.016647060426481772\n",
      "Epoch 16/50, iter: 900/3382, mean loss: 0.022676378590880546\n",
      "Epoch 16/50, iter: 1000/3382, mean loss: 0.14612964372937343\n",
      "Epoch 16/50, iter: 1100/3382, mean loss: 0.142880749773758\n",
      "Epoch 16/50, iter: 1200/3382, mean loss: 0.11640643426001589\n",
      "Epoch 16/50, iter: 1300/3382, mean loss: 0.11858575933734755\n",
      "Epoch 16/50, iter: 1400/3382, mean loss: 0.08347447905373429\n",
      "Epoch 16/50, iter: 1500/3382, mean loss: 0.04740142812236115\n",
      "Epoch 16/50, iter: 1600/3382, mean loss: 0.054746635113590826\n",
      "Epoch 16/50, iter: 1700/3382, mean loss: 0.03697315298723197\n",
      "Epoch 16/50, iter: 1800/3382, mean loss: 0.1748886458736044\n",
      "Epoch 16/50, iter: 1900/3382, mean loss: 0.17601041959751457\n",
      "Epoch 16/50, iter: 2000/3382, mean loss: 0.12536934760079022\n",
      "Epoch 16/50, iter: 2100/3382, mean loss: 0.11591678076045354\n",
      "Epoch 16/50, iter: 2200/3382, mean loss: 0.08200805859666616\n",
      "Epoch 16/50, iter: 2300/3382, mean loss: 0.07574773871780507\n",
      "Epoch 16/50, iter: 2400/3382, mean loss: 0.05155956706913798\n",
      "Epoch 16/50, iter: 2500/3382, mean loss: 0.06844967195993888\n",
      "Epoch 16/50, iter: 2600/3382, mean loss: 0.2341979109852855\n",
      "Epoch 16/50, iter: 2700/3382, mean loss: 0.09736741145941778\n",
      "Epoch 16/50, iter: 2800/3382, mean loss: 0.11430683997925371\n",
      "Epoch 16/50, iter: 2900/3382, mean loss: 0.09189882502618275\n",
      "Epoch 16/50, iter: 3000/3382, mean loss: 0.09148083085420694\n",
      "Epoch 16/50, iter: 3100/3382, mean loss: 0.13334967976851658\n",
      "Epoch 16/50, iter: 3200/3382, mean loss: 0.07241026506359191\n",
      "Epoch 16/50, iter: 3300/3382, mean loss: 0.028124166717263963\n",
      "Epoch 17/50, iter: 100/3382, mean loss: 0.07940611840173915\n",
      "Epoch 17/50, iter: 200/3382, mean loss: 0.05024111495283051\n",
      "Epoch 17/50, iter: 300/3382, mean loss: 0.021686662824805865\n",
      "Epoch 17/50, iter: 400/3382, mean loss: 0.021303339612579037\n",
      "Epoch 17/50, iter: 500/3382, mean loss: 0.054085716576174364\n",
      "Epoch 17/50, iter: 600/3382, mean loss: 0.015372696303530872\n",
      "Epoch 17/50, iter: 700/3382, mean loss: 0.002454741088668513\n",
      "Epoch 17/50, iter: 800/3382, mean loss: 0.016558567897705316\n",
      "Epoch 17/50, iter: 900/3382, mean loss: 0.030076562661469915\n",
      "Epoch 17/50, iter: 1000/3382, mean loss: 0.08074723158541416\n",
      "Epoch 17/50, iter: 1100/3382, mean loss: 0.13956445382871607\n",
      "Epoch 17/50, iter: 1200/3382, mean loss: 0.15642840615603518\n",
      "Epoch 17/50, iter: 1300/3382, mean loss: 0.10271655226655639\n",
      "Epoch 17/50, iter: 1400/3382, mean loss: 0.0952479026896777\n",
      "Epoch 17/50, iter: 1500/3382, mean loss: 0.08594107307042066\n",
      "Epoch 17/50, iter: 1600/3382, mean loss: 0.046518239177302405\n",
      "Epoch 17/50, iter: 1700/3382, mean loss: 0.05584817218707073\n",
      "Epoch 17/50, iter: 1800/3382, mean loss: 0.16379244622419747\n",
      "Epoch 17/50, iter: 1900/3382, mean loss: 0.2398350100425887\n",
      "Epoch 17/50, iter: 2000/3382, mean loss: 0.15531161620718195\n",
      "Epoch 17/50, iter: 2100/3382, mean loss: 0.17511537484300788\n",
      "Epoch 17/50, iter: 2200/3382, mean loss: 0.14398648859667446\n",
      "Epoch 17/50, iter: 2300/3382, mean loss: 0.07739778169649071\n",
      "Epoch 17/50, iter: 2400/3382, mean loss: 0.0959205505187174\n",
      "Epoch 17/50, iter: 2500/3382, mean loss: 0.04723062469608351\n",
      "Epoch 17/50, iter: 2600/3382, mean loss: 0.1298757537005008\n",
      "Epoch 17/50, iter: 2700/3382, mean loss: 0.14097565139414656\n",
      "Epoch 17/50, iter: 2800/3382, mean loss: 0.12404644823342097\n",
      "Epoch 17/50, iter: 2900/3382, mean loss: 0.13176871922962163\n",
      "Epoch 17/50, iter: 3000/3382, mean loss: 0.1591781742996318\n",
      "Epoch 17/50, iter: 3100/3382, mean loss: 0.06893286655364136\n",
      "Epoch 17/50, iter: 3200/3382, mean loss: 0.06253921286401265\n",
      "Epoch 17/50, iter: 3300/3382, mean loss: 0.03779353480188661\n",
      "Epoch 18/50, iter: 100/3382, mean loss: 0.07993814868210393\n",
      "Epoch 18/50, iter: 200/3382, mean loss: 0.029756244948314397\n",
      "Epoch 18/50, iter: 300/3382, mean loss: 0.022147283033903876\n",
      "Epoch 18/50, iter: 400/3382, mean loss: 0.015449659077906795\n",
      "Epoch 18/50, iter: 500/3382, mean loss: 0.026484750864446162\n",
      "Epoch 18/50, iter: 600/3382, mean loss: 0.013907524704047915\n",
      "Epoch 18/50, iter: 700/3382, mean loss: 0.02555477161893869\n",
      "Epoch 18/50, iter: 800/3382, mean loss: 0.0034014015416574494\n",
      "Epoch 18/50, iter: 900/3382, mean loss: 0.011999175158468134\n",
      "Epoch 18/50, iter: 1000/3382, mean loss: 0.05146752438190916\n",
      "Epoch 18/50, iter: 1100/3382, mean loss: 0.08465741961409322\n",
      "Epoch 18/50, iter: 1200/3382, mean loss: 0.17810614367388553\n",
      "Epoch 18/50, iter: 1300/3382, mean loss: 0.05706555675545019\n",
      "Epoch 18/50, iter: 1400/3382, mean loss: 0.07385047056319607\n",
      "Epoch 18/50, iter: 1500/3382, mean loss: 0.05040558452490195\n",
      "Epoch 18/50, iter: 1600/3382, mean loss: 0.09316431449621866\n",
      "Epoch 18/50, iter: 1700/3382, mean loss: 0.04263004461709045\n",
      "Epoch 18/50, iter: 1800/3382, mean loss: 0.1519518790028548\n",
      "Epoch 18/50, iter: 1900/3382, mean loss: 0.11890377361945866\n",
      "Epoch 18/50, iter: 2000/3382, mean loss: 0.08835941727134923\n",
      "Epoch 18/50, iter: 2100/3382, mean loss: 0.074064412004833\n",
      "Epoch 18/50, iter: 2200/3382, mean loss: 0.08666654068620573\n",
      "Epoch 18/50, iter: 2300/3382, mean loss: 0.05634397513825661\n",
      "Epoch 18/50, iter: 2400/3382, mean loss: 0.028647645121873212\n",
      "Epoch 18/50, iter: 2500/3382, mean loss: 0.029704710686494877\n",
      "Epoch 18/50, iter: 2600/3382, mean loss: 0.17683141412797226\n",
      "Epoch 18/50, iter: 2700/3382, mean loss: 0.055632780237706354\n",
      "Epoch 18/50, iter: 2800/3382, mean loss: 0.054676083059239315\n",
      "Epoch 18/50, iter: 2900/3382, mean loss: 0.03963148554852523\n",
      "Epoch 18/50, iter: 3000/3382, mean loss: 0.08637508306595464\n",
      "Epoch 18/50, iter: 3100/3382, mean loss: 0.06068841389274894\n",
      "Epoch 18/50, iter: 3200/3382, mean loss: 0.08095001650741153\n",
      "Epoch 18/50, iter: 3300/3382, mean loss: 0.01705694241247329\n",
      "Epoch 19/50, iter: 100/3382, mean loss: 0.0667788926874232\n",
      "Epoch 19/50, iter: 200/3382, mean loss: 0.026591571722286746\n",
      "Epoch 19/50, iter: 300/3382, mean loss: 0.01570166538687701\n",
      "Epoch 19/50, iter: 400/3382, mean loss: 0.006645507995689073\n",
      "Epoch 19/50, iter: 500/3382, mean loss: 0.039393377371364974\n",
      "Epoch 19/50, iter: 600/3382, mean loss: 0.022247817459207866\n",
      "Epoch 19/50, iter: 700/3382, mean loss: 0.012123873663595503\n",
      "Epoch 19/50, iter: 800/3382, mean loss: 0.01588790103979804\n",
      "Epoch 19/50, iter: 900/3382, mean loss: 0.0066973313631930155\n",
      "Epoch 19/50, iter: 1000/3382, mean loss: 0.04966772717962204\n",
      "Epoch 19/50, iter: 1100/3382, mean loss: 0.08314270435638094\n",
      "Epoch 19/50, iter: 1200/3382, mean loss: 0.14746279822794123\n",
      "Epoch 19/50, iter: 1300/3382, mean loss: 0.0990937355798951\n",
      "Epoch 19/50, iter: 1400/3382, mean loss: 0.05522141459201521\n",
      "Epoch 19/50, iter: 1500/3382, mean loss: 0.06179356433685683\n",
      "Epoch 19/50, iter: 1600/3382, mean loss: 0.0449763785310941\n",
      "Epoch 19/50, iter: 1700/3382, mean loss: 0.035353362825795785\n",
      "Epoch 19/50, iter: 1800/3382, mean loss: 0.11538319809071439\n",
      "Epoch 19/50, iter: 1900/3382, mean loss: 0.1470280704844845\n",
      "Epoch 19/50, iter: 2000/3382, mean loss: 0.08745112395983597\n",
      "Epoch 19/50, iter: 2100/3382, mean loss: 0.1095950638821887\n",
      "Epoch 19/50, iter: 2200/3382, mean loss: 0.047772955345607215\n",
      "Epoch 19/50, iter: 2300/3382, mean loss: 0.04802721773841086\n",
      "Epoch 19/50, iter: 2400/3382, mean loss: 0.03918065303169556\n",
      "Epoch 19/50, iter: 2500/3382, mean loss: 0.023865418201249326\n",
      "Epoch 19/50, iter: 2600/3382, mean loss: 0.14494995603806757\n",
      "Epoch 19/50, iter: 2700/3382, mean loss: 0.06985712559895035\n",
      "Epoch 19/50, iter: 2800/3382, mean loss: 0.09805980031182117\n",
      "Epoch 19/50, iter: 2900/3382, mean loss: 0.029113683556925025\n",
      "Epoch 19/50, iter: 3000/3382, mean loss: 0.12332123970001248\n",
      "Epoch 19/50, iter: 3100/3382, mean loss: 0.044105405561438146\n",
      "Epoch 19/50, iter: 3200/3382, mean loss: 0.07417795292902618\n",
      "Epoch 19/50, iter: 3300/3382, mean loss: 0.028463632573277806\n",
      "Epoch 20/50, iter: 100/3382, mean loss: 0.06347795451517868\n",
      "Epoch 20/50, iter: 200/3382, mean loss: 0.05248382057498617\n",
      "Epoch 20/50, iter: 300/3382, mean loss: 0.01627664378763086\n",
      "Epoch 20/50, iter: 400/3382, mean loss: 0.02012304328192833\n",
      "Epoch 20/50, iter: 500/3382, mean loss: 0.03551084985122276\n",
      "Epoch 20/50, iter: 600/3382, mean loss: 0.017846195131043744\n",
      "Epoch 20/50, iter: 700/3382, mean loss: 0.007799218576094447\n",
      "Epoch 20/50, iter: 800/3382, mean loss: 0.006977080451745543\n",
      "Epoch 20/50, iter: 900/3382, mean loss: 0.0072300394247488955\n",
      "Epoch 20/50, iter: 1000/3382, mean loss: 0.03417083619502151\n",
      "Epoch 20/50, iter: 1100/3382, mean loss: 0.05882858623840889\n",
      "Epoch 20/50, iter: 1200/3382, mean loss: 0.12561495058431807\n",
      "Epoch 20/50, iter: 1300/3382, mean loss: 0.080963880676901\n",
      "Epoch 20/50, iter: 1400/3382, mean loss: 0.04439913551838821\n",
      "Epoch 20/50, iter: 1500/3382, mean loss: 0.021581529538949838\n",
      "Epoch 20/50, iter: 1600/3382, mean loss: 0.04078246805747185\n",
      "Epoch 20/50, iter: 1700/3382, mean loss: 0.03489021628809752\n",
      "Epoch 20/50, iter: 1800/3382, mean loss: 0.08531579038526417\n",
      "Epoch 20/50, iter: 1900/3382, mean loss: 0.09581689099418327\n",
      "Epoch 20/50, iter: 2000/3382, mean loss: 0.0709749573262161\n",
      "Epoch 20/50, iter: 2100/3382, mean loss: 0.06010829576134711\n",
      "Epoch 20/50, iter: 2200/3382, mean loss: 0.051820177643878654\n",
      "Epoch 20/50, iter: 2300/3382, mean loss: 0.03907969075454829\n",
      "Epoch 20/50, iter: 2400/3382, mean loss: 0.04019533521169194\n",
      "Epoch 20/50, iter: 2500/3382, mean loss: 0.03380929919016587\n",
      "Epoch 20/50, iter: 2600/3382, mean loss: 0.10351070860393775\n",
      "Epoch 20/50, iter: 2700/3382, mean loss: 0.08971889705087734\n",
      "Epoch 20/50, iter: 2800/3382, mean loss: 0.0302382461164342\n",
      "Epoch 20/50, iter: 2900/3382, mean loss: 0.04066033626554031\n",
      "Epoch 20/50, iter: 3000/3382, mean loss: 0.07546096191370225\n",
      "Epoch 20/50, iter: 3100/3382, mean loss: 0.03823795023726177\n",
      "Epoch 20/50, iter: 3200/3382, mean loss: 0.051381266629408916\n",
      "Epoch 20/50, iter: 3300/3382, mean loss: 0.041696208268012354\n",
      "Epoch 21/50, iter: 100/3382, mean loss: 0.044831723269587655\n",
      "Epoch 21/50, iter: 200/3382, mean loss: 0.04802369773811115\n",
      "Epoch 21/50, iter: 300/3382, mean loss: 0.017625316850915597\n",
      "Epoch 21/50, iter: 400/3382, mean loss: 0.008445249774001412\n",
      "Epoch 21/50, iter: 500/3382, mean loss: 0.02640896758633392\n",
      "Epoch 21/50, iter: 600/3382, mean loss: 0.012169855318488807\n",
      "Epoch 21/50, iter: 700/3382, mean loss: 0.0028999880643960554\n",
      "Epoch 21/50, iter: 800/3382, mean loss: 0.0036176966180642366\n",
      "Epoch 21/50, iter: 900/3382, mean loss: 0.016150853588688285\n",
      "Epoch 21/50, iter: 1000/3382, mean loss: 0.04336024036251089\n",
      "Epoch 21/50, iter: 1100/3382, mean loss: 0.0627653041479408\n",
      "Epoch 21/50, iter: 1200/3382, mean loss: 0.12918691901057186\n",
      "Epoch 21/50, iter: 1300/3382, mean loss: 0.0427082066957405\n",
      "Epoch 21/50, iter: 1400/3382, mean loss: 0.055889850488135086\n",
      "Epoch 21/50, iter: 1500/3382, mean loss: 0.02547628890321647\n",
      "Epoch 21/50, iter: 1600/3382, mean loss: 0.048993136578884704\n",
      "Epoch 21/50, iter: 1700/3382, mean loss: 0.01285606367998632\n",
      "Epoch 21/50, iter: 1800/3382, mean loss: 0.07188607333058257\n",
      "Epoch 21/50, iter: 1900/3382, mean loss: 0.1450851001811111\n",
      "Epoch 21/50, iter: 2000/3382, mean loss: 0.1458277933613499\n",
      "Epoch 21/50, iter: 2100/3382, mean loss: 0.046111141812591544\n",
      "Epoch 21/50, iter: 2200/3382, mean loss: 0.04172611663857651\n",
      "Epoch 21/50, iter: 2300/3382, mean loss: 0.043465679421417464\n",
      "Epoch 21/50, iter: 2400/3382, mean loss: 0.019071452971362604\n",
      "Epoch 21/50, iter: 2500/3382, mean loss: 0.04893183170359528\n",
      "Epoch 21/50, iter: 2600/3382, mean loss: 0.10923777996974081\n",
      "Epoch 21/50, iter: 2700/3382, mean loss: 0.07618876809385966\n",
      "Epoch 21/50, iter: 2800/3382, mean loss: 0.053120223209534745\n",
      "Epoch 21/50, iter: 2900/3382, mean loss: 0.05515327876737274\n",
      "Epoch 21/50, iter: 3000/3382, mean loss: 0.0509150575231638\n",
      "Epoch 21/50, iter: 3100/3382, mean loss: 0.021373159466302277\n",
      "Epoch 21/50, iter: 3200/3382, mean loss: 0.05969800227779658\n",
      "Epoch 21/50, iter: 3300/3382, mean loss: 0.029522265727140534\n",
      "Epoch 22/50, iter: 100/3382, mean loss: 0.04528026640802182\n",
      "Epoch 22/50, iter: 200/3382, mean loss: 0.04366680720379193\n",
      "Epoch 22/50, iter: 300/3382, mean loss: 0.017393889467900686\n",
      "Epoch 22/50, iter: 400/3382, mean loss: 0.0020555596451007217\n",
      "Epoch 22/50, iter: 500/3382, mean loss: 0.023251779810998522\n",
      "Epoch 22/50, iter: 600/3382, mean loss: 0.00951300592212487\n",
      "Epoch 22/50, iter: 700/3382, mean loss: 0.00568468433066684\n",
      "Epoch 22/50, iter: 800/3382, mean loss: 0.00758171512897075\n",
      "Epoch 22/50, iter: 900/3382, mean loss: 0.0185090177737964\n",
      "Epoch 22/50, iter: 1000/3382, mean loss: 0.03496174640381185\n",
      "Epoch 22/50, iter: 1100/3382, mean loss: 0.061069243399304654\n",
      "Epoch 22/50, iter: 1200/3382, mean loss: 0.0592302215660732\n",
      "Epoch 22/50, iter: 1300/3382, mean loss: 0.0548882590716989\n",
      "Epoch 22/50, iter: 1400/3382, mean loss: 0.053720381375522736\n",
      "Epoch 22/50, iter: 1500/3382, mean loss: 0.023773687771134533\n",
      "Epoch 22/50, iter: 1600/3382, mean loss: 0.060209631159848766\n",
      "Epoch 22/50, iter: 1700/3382, mean loss: 0.03824530936688568\n",
      "Epoch 22/50, iter: 1800/3382, mean loss: 0.10590608190010257\n",
      "Epoch 22/50, iter: 1900/3382, mean loss: 0.11107261377525901\n",
      "Epoch 22/50, iter: 2000/3382, mean loss: 0.05472067811060242\n",
      "Epoch 22/50, iter: 2100/3382, mean loss: 0.11014239246158468\n",
      "Epoch 22/50, iter: 2200/3382, mean loss: 0.053936070266081514\n",
      "Epoch 22/50, iter: 2300/3382, mean loss: 0.08959862376832689\n",
      "Epoch 22/50, iter: 2400/3382, mean loss: 0.05261879466076493\n",
      "Epoch 22/50, iter: 2500/3382, mean loss: 0.05297955362836276\n",
      "Epoch 22/50, iter: 2600/3382, mean loss: 0.13592022318879707\n",
      "Epoch 22/50, iter: 2700/3382, mean loss: 0.061881549726583704\n",
      "Epoch 22/50, iter: 2800/3382, mean loss: 0.047040133326436834\n",
      "Epoch 22/50, iter: 2900/3382, mean loss: 0.07234603942927151\n",
      "Epoch 22/50, iter: 3000/3382, mean loss: 0.08055330082938497\n",
      "Epoch 22/50, iter: 3100/3382, mean loss: 0.044764327113457514\n",
      "Epoch 22/50, iter: 3200/3382, mean loss: 0.07958366984716221\n",
      "Epoch 22/50, iter: 3300/3382, mean loss: 0.05036146048909448\n",
      "Epoch 23/50, iter: 100/3382, mean loss: 0.05913839528309843\n",
      "Epoch 23/50, iter: 200/3382, mean loss: 0.05104527307644801\n",
      "Epoch 23/50, iter: 300/3382, mean loss: 0.023817444588377513\n",
      "Epoch 23/50, iter: 400/3382, mean loss: 0.0014196178194542596\n",
      "Epoch 23/50, iter: 500/3382, mean loss: 0.020924471225805447\n",
      "Epoch 23/50, iter: 600/3382, mean loss: 0.011374802057310696\n",
      "Epoch 23/50, iter: 700/3382, mean loss: 0.002920456795534676\n",
      "Epoch 23/50, iter: 800/3382, mean loss: 0.02537094966279753\n",
      "Epoch 23/50, iter: 900/3382, mean loss: 0.01134481789217059\n",
      "Epoch 23/50, iter: 1000/3382, mean loss: 0.020114729140007056\n",
      "Epoch 23/50, iter: 1100/3382, mean loss: 0.03954175967060053\n",
      "Epoch 23/50, iter: 1200/3382, mean loss: 0.046442707049692306\n",
      "Epoch 23/50, iter: 1300/3382, mean loss: 0.04952317142345713\n",
      "Epoch 23/50, iter: 1400/3382, mean loss: 0.024844408768284722\n",
      "Epoch 23/50, iter: 1500/3382, mean loss: 0.022187483333808444\n",
      "Epoch 23/50, iter: 1600/3382, mean loss: 0.04468092546468625\n",
      "Epoch 23/50, iter: 1700/3382, mean loss: 0.033500848105057844\n",
      "Epoch 23/50, iter: 1800/3382, mean loss: 0.06744208120852135\n",
      "Epoch 23/50, iter: 1900/3382, mean loss: 0.0941018031561822\n",
      "Epoch 23/50, iter: 2000/3382, mean loss: 0.04305937799759704\n",
      "Epoch 23/50, iter: 2100/3382, mean loss: 0.0789345667653788\n",
      "Epoch 23/50, iter: 2200/3382, mean loss: 0.057983275547612435\n",
      "Epoch 23/50, iter: 2300/3382, mean loss: 0.07668754050583658\n",
      "Epoch 23/50, iter: 2400/3382, mean loss: 0.02495334434931692\n",
      "Epoch 23/50, iter: 2500/3382, mean loss: 0.02440496979972643\n",
      "Epoch 23/50, iter: 2600/3382, mean loss: 0.07082818353251127\n",
      "Epoch 23/50, iter: 2700/3382, mean loss: 0.02635601013352513\n",
      "Epoch 23/50, iter: 2800/3382, mean loss: 0.039630931685103545\n",
      "Epoch 23/50, iter: 2900/3382, mean loss: 0.04284752150376334\n",
      "Epoch 23/50, iter: 3000/3382, mean loss: 0.07913880693819465\n",
      "Epoch 23/50, iter: 3100/3382, mean loss: 0.039220463630411366\n",
      "Epoch 23/50, iter: 3200/3382, mean loss: 0.03728576620144707\n",
      "Epoch 23/50, iter: 3300/3382, mean loss: 0.023693263110046985\n",
      "Epoch 24/50, iter: 100/3382, mean loss: 0.020126572047917932\n",
      "Epoch 24/50, iter: 200/3382, mean loss: 0.03589445595029865\n",
      "Epoch 24/50, iter: 300/3382, mean loss: 0.0021909555732011654\n",
      "Epoch 24/50, iter: 400/3382, mean loss: 0.009956208469076274\n",
      "Epoch 24/50, iter: 500/3382, mean loss: 0.009079442902043943\n",
      "Epoch 24/50, iter: 600/3382, mean loss: 0.008936749007741475\n",
      "Epoch 24/50, iter: 700/3382, mean loss: 0.006979572029919901\n",
      "Epoch 24/50, iter: 800/3382, mean loss: 0.002947663860592904\n",
      "Epoch 24/50, iter: 900/3382, mean loss: 0.0026518914723584787\n",
      "Epoch 24/50, iter: 1000/3382, mean loss: 0.011388288287084443\n",
      "Epoch 24/50, iter: 1100/3382, mean loss: 0.044024036737584996\n",
      "Epoch 24/50, iter: 1200/3382, mean loss: 0.03257810201815573\n",
      "Epoch 24/50, iter: 1300/3382, mean loss: 0.033896051397795335\n",
      "Epoch 24/50, iter: 1400/3382, mean loss: 0.04064958846228144\n",
      "Epoch 24/50, iter: 1500/3382, mean loss: 0.029992085489951918\n",
      "Epoch 24/50, iter: 1600/3382, mean loss: 0.02976912495212723\n",
      "Epoch 24/50, iter: 1700/3382, mean loss: 0.005462306125936216\n",
      "Epoch 24/50, iter: 1800/3382, mean loss: 0.06898380475960167\n",
      "Epoch 24/50, iter: 1900/3382, mean loss: 0.10427814716071908\n",
      "Epoch 24/50, iter: 2000/3382, mean loss: 0.03252860449730861\n",
      "Epoch 24/50, iter: 2100/3382, mean loss: 0.05927806735222248\n",
      "Epoch 24/50, iter: 2200/3382, mean loss: 0.06288388686993188\n",
      "Epoch 24/50, iter: 2300/3382, mean loss: 0.0302919241310191\n",
      "Epoch 24/50, iter: 2400/3382, mean loss: 0.024478375309063126\n",
      "Epoch 24/50, iter: 2500/3382, mean loss: 0.013493273450407415\n",
      "Epoch 24/50, iter: 2600/3382, mean loss: 0.05171405760294192\n",
      "Epoch 24/50, iter: 2700/3382, mean loss: 0.02819698531974609\n",
      "Epoch 24/50, iter: 2800/3382, mean loss: 0.030617746701550458\n",
      "Epoch 24/50, iter: 2900/3382, mean loss: 0.033176049226567556\n",
      "Epoch 24/50, iter: 3000/3382, mean loss: 0.0368399902602404\n",
      "Epoch 24/50, iter: 3100/3382, mean loss: 0.010129136601821109\n",
      "Epoch 24/50, iter: 3200/3382, mean loss: 0.02724084257940078\n",
      "Epoch 24/50, iter: 3300/3382, mean loss: 0.017194668262893308\n",
      "Epoch 25/50, iter: 100/3382, mean loss: 0.03007989677022046\n",
      "Epoch 25/50, iter: 200/3382, mean loss: 0.05298181164894622\n",
      "Epoch 25/50, iter: 300/3382, mean loss: 0.005625253992102124\n",
      "Epoch 25/50, iter: 400/3382, mean loss: 0.0018678225414698346\n",
      "Epoch 25/50, iter: 500/3382, mean loss: 0.014921111851837275\n",
      "Epoch 25/50, iter: 600/3382, mean loss: 0.024144081334306015\n",
      "Epoch 25/50, iter: 700/3382, mean loss: 0.0030597857085713897\n",
      "Epoch 25/50, iter: 800/3382, mean loss: 0.002989747884245162\n",
      "Epoch 25/50, iter: 900/3382, mean loss: 0.007265313198815911\n",
      "Epoch 25/50, iter: 1000/3382, mean loss: 0.02149735867958718\n",
      "Epoch 25/50, iter: 1100/3382, mean loss: 0.05194322890353174\n",
      "Epoch 25/50, iter: 1200/3382, mean loss: 0.12931525172501818\n",
      "Epoch 25/50, iter: 1300/3382, mean loss: 0.01842728280987352\n",
      "Epoch 25/50, iter: 1400/3382, mean loss: 0.031954583600990745\n",
      "Epoch 25/50, iter: 1500/3382, mean loss: 0.10072671835856312\n",
      "Epoch 25/50, iter: 1600/3382, mean loss: 0.06023199718386064\n",
      "Epoch 25/50, iter: 1700/3382, mean loss: 0.0556006774157526\n",
      "Epoch 25/50, iter: 1800/3382, mean loss: 0.06693724854278031\n",
      "Epoch 25/50, iter: 1900/3382, mean loss: 0.08166818093184702\n",
      "Epoch 25/50, iter: 2000/3382, mean loss: 0.09046915229008619\n",
      "Epoch 25/50, iter: 2100/3382, mean loss: 0.02783977249396912\n",
      "Epoch 25/50, iter: 2200/3382, mean loss: 0.0330585865738621\n",
      "Epoch 25/50, iter: 2300/3382, mean loss: 0.01817934011285985\n",
      "Epoch 25/50, iter: 2400/3382, mean loss: 0.024506504911712454\n",
      "Epoch 25/50, iter: 2500/3382, mean loss: 0.028964055601120826\n",
      "Epoch 25/50, iter: 2600/3382, mean loss: 0.07101296624199122\n",
      "Epoch 25/50, iter: 2700/3382, mean loss: 0.05378898021781879\n",
      "Epoch 25/50, iter: 2800/3382, mean loss: 0.0448434051163531\n",
      "Epoch 25/50, iter: 2900/3382, mean loss: 0.02425888678441993\n",
      "Epoch 25/50, iter: 3000/3382, mean loss: 0.03384384913430125\n",
      "Epoch 25/50, iter: 3100/3382, mean loss: 0.04340806734383591\n",
      "Epoch 25/50, iter: 3200/3382, mean loss: 0.0781533597566192\n",
      "Epoch 25/50, iter: 3300/3382, mean loss: 0.012677179400717513\n",
      "Epoch 26/50, iter: 100/3382, mean loss: 0.03978333779877964\n",
      "Epoch 26/50, iter: 200/3382, mean loss: 0.02186415061701677\n",
      "Epoch 26/50, iter: 300/3382, mean loss: 0.008224950577611523\n",
      "Epoch 26/50, iter: 400/3382, mean loss: 0.0006974953603792855\n",
      "Epoch 26/50, iter: 500/3382, mean loss: 0.02444411774687186\n",
      "Epoch 26/50, iter: 600/3382, mean loss: 0.005989620131160294\n",
      "Epoch 26/50, iter: 700/3382, mean loss: 0.0006357198746886538\n",
      "Epoch 26/50, iter: 800/3382, mean loss: 0.0003330189144520901\n",
      "Epoch 26/50, iter: 900/3382, mean loss: 0.002124539794391431\n",
      "Epoch 26/50, iter: 1000/3382, mean loss: 0.041161749239973774\n",
      "Epoch 26/50, iter: 1100/3382, mean loss: 0.04074157401360097\n",
      "Epoch 26/50, iter: 1200/3382, mean loss: 0.040053822423505386\n",
      "Epoch 26/50, iter: 1300/3382, mean loss: 0.05520072436644767\n",
      "Epoch 26/50, iter: 1400/3382, mean loss: 0.020579859837629683\n",
      "Epoch 26/50, iter: 1500/3382, mean loss: 0.019034674215842387\n",
      "Epoch 26/50, iter: 1600/3382, mean loss: 0.03441334050356985\n",
      "Epoch 26/50, iter: 1700/3382, mean loss: 0.03978991120423249\n",
      "Epoch 26/50, iter: 1800/3382, mean loss: 0.07297111494347433\n",
      "Epoch 26/50, iter: 1900/3382, mean loss: 0.07825275566257175\n",
      "Epoch 26/50, iter: 2000/3382, mean loss: 0.021911616746263008\n",
      "Epoch 26/50, iter: 2100/3382, mean loss: 0.07006760285113046\n",
      "Epoch 26/50, iter: 2200/3382, mean loss: 0.04545082208158917\n",
      "Epoch 26/50, iter: 2300/3382, mean loss: 0.03511269329157365\n",
      "Epoch 26/50, iter: 2400/3382, mean loss: 0.0460015239505033\n",
      "Epoch 26/50, iter: 2500/3382, mean loss: 0.02645427313170643\n",
      "Epoch 26/50, iter: 2600/3382, mean loss: 0.0843019472475391\n",
      "Epoch 26/50, iter: 2700/3382, mean loss: 0.03449734720064271\n",
      "Epoch 26/50, iter: 2800/3382, mean loss: 0.04350008127951696\n",
      "Epoch 26/50, iter: 2900/3382, mean loss: 0.0530738273355216\n",
      "Epoch 26/50, iter: 3000/3382, mean loss: 0.02281134278913811\n",
      "Epoch 26/50, iter: 3100/3382, mean loss: 0.027956891504933877\n",
      "Epoch 26/50, iter: 3200/3382, mean loss: 0.01717928286539305\n",
      "Epoch 26/50, iter: 3300/3382, mean loss: 0.01944601931361518\n",
      "Epoch 27/50, iter: 100/3382, mean loss: 0.05368995838718451\n",
      "Epoch 27/50, iter: 200/3382, mean loss: 0.04445648636936674\n",
      "Epoch 27/50, iter: 300/3382, mean loss: 0.008013800641615524\n",
      "Epoch 27/50, iter: 400/3382, mean loss: 0.003604214423898142\n",
      "Epoch 27/50, iter: 500/3382, mean loss: 0.0223217927536804\n",
      "Epoch 27/50, iter: 600/3382, mean loss: 0.010541638062666614\n",
      "Epoch 27/50, iter: 700/3382, mean loss: 0.0011407434393154504\n",
      "Epoch 27/50, iter: 800/3382, mean loss: 0.006879389017621627\n",
      "Epoch 27/50, iter: 900/3382, mean loss: 0.0012421589669703436\n",
      "Epoch 27/50, iter: 1000/3382, mean loss: 0.02133167640622908\n",
      "Epoch 27/50, iter: 1100/3382, mean loss: 0.04043138510043718\n",
      "Epoch 27/50, iter: 1200/3382, mean loss: 0.04580040001185935\n",
      "Epoch 27/50, iter: 1300/3382, mean loss: 0.053657655921815\n",
      "Epoch 27/50, iter: 1400/3382, mean loss: 0.03529969724697459\n",
      "Epoch 27/50, iter: 1500/3382, mean loss: 0.05154278449277555\n",
      "Epoch 27/50, iter: 1600/3382, mean loss: 0.02589193201567145\n",
      "Epoch 27/50, iter: 1700/3382, mean loss: 0.030024562187073726\n",
      "Epoch 27/50, iter: 1800/3382, mean loss: 0.06857405182249438\n",
      "Epoch 27/50, iter: 1900/3382, mean loss: 0.08600469911578731\n",
      "Epoch 27/50, iter: 2000/3382, mean loss: 0.030641090425101537\n",
      "Epoch 27/50, iter: 2100/3382, mean loss: 0.06514593868816931\n",
      "Epoch 27/50, iter: 2200/3382, mean loss: 0.032908331027399595\n",
      "Epoch 27/50, iter: 2300/3382, mean loss: 0.03379090834942147\n",
      "Epoch 27/50, iter: 2400/3382, mean loss: 0.013516874343251217\n",
      "Epoch 27/50, iter: 2500/3382, mean loss: 0.03065037370086863\n",
      "Epoch 27/50, iter: 2600/3382, mean loss: 0.07423859882479121\n",
      "Epoch 27/50, iter: 2700/3382, mean loss: 0.025735866552625167\n",
      "Epoch 27/50, iter: 2800/3382, mean loss: 0.026484331999076894\n",
      "Epoch 27/50, iter: 2900/3382, mean loss: 0.034203225321244875\n",
      "Epoch 27/50, iter: 3000/3382, mean loss: 0.06691575274317789\n",
      "Epoch 27/50, iter: 3100/3382, mean loss: 0.018398603069892303\n",
      "Epoch 27/50, iter: 3200/3382, mean loss: 0.01896374106096978\n",
      "Epoch 27/50, iter: 3300/3382, mean loss: 0.026381007516377862\n",
      "Epoch 28/50, iter: 100/3382, mean loss: 0.021867192276249198\n",
      "Epoch 28/50, iter: 200/3382, mean loss: 0.02122494155009502\n",
      "Epoch 28/50, iter: 300/3382, mean loss: 0.007349605445841832\n",
      "Epoch 28/50, iter: 400/3382, mean loss: 0.0024452080849666656\n",
      "Epoch 28/50, iter: 500/3382, mean loss: 0.007529659556412795\n",
      "Epoch 28/50, iter: 600/3382, mean loss: 0.022559981412278666\n",
      "Epoch 28/50, iter: 700/3382, mean loss: 0.0031636371337220126\n",
      "Epoch 28/50, iter: 800/3382, mean loss: 0.0007256111208157989\n",
      "Epoch 28/50, iter: 900/3382, mean loss: 0.005155617168835747\n",
      "Epoch 28/50, iter: 1000/3382, mean loss: 0.019334596686063285\n",
      "Epoch 28/50, iter: 1100/3382, mean loss: 0.04287330927353779\n",
      "Epoch 28/50, iter: 1200/3382, mean loss: 0.04533694320588033\n",
      "Epoch 28/50, iter: 1300/3382, mean loss: 0.03061635361391719\n",
      "Epoch 28/50, iter: 1400/3382, mean loss: 0.03977092564481378\n",
      "Epoch 28/50, iter: 1500/3382, mean loss: 0.013994735263191772\n",
      "Epoch 28/50, iter: 1600/3382, mean loss: 0.015690461823460213\n",
      "Epoch 28/50, iter: 1700/3382, mean loss: 0.03990288191121657\n",
      "Epoch 28/50, iter: 1800/3382, mean loss: 0.07341177612693034\n",
      "Epoch 28/50, iter: 1900/3382, mean loss: 0.06775061570248284\n",
      "Epoch 28/50, iter: 2000/3382, mean loss: 0.04792033317366759\n",
      "Epoch 28/50, iter: 2100/3382, mean loss: 0.030196069869986103\n",
      "Epoch 28/50, iter: 2200/3382, mean loss: 0.04236843735759578\n",
      "Epoch 28/50, iter: 2300/3382, mean loss: 0.041583039049150304\n",
      "Epoch 28/50, iter: 2400/3382, mean loss: 0.04387314370761757\n",
      "Epoch 28/50, iter: 2500/3382, mean loss: 0.018554704087975507\n",
      "Epoch 28/50, iter: 2600/3382, mean loss: 0.07136471315108764\n",
      "Epoch 28/50, iter: 2700/3382, mean loss: 0.025350831668154116\n",
      "Epoch 28/50, iter: 2800/3382, mean loss: 0.022269659322627717\n",
      "Epoch 28/50, iter: 2900/3382, mean loss: 0.027365812447540064\n",
      "Epoch 28/50, iter: 3000/3382, mean loss: 0.0482315549700688\n",
      "Epoch 28/50, iter: 3100/3382, mean loss: 0.0703870977406342\n",
      "Epoch 28/50, iter: 3200/3382, mean loss: 0.01812774616402706\n",
      "Epoch 28/50, iter: 3300/3382, mean loss: 0.029103475650527528\n",
      "Epoch 29/50, iter: 100/3382, mean loss: 0.023908544033549896\n",
      "Epoch 29/50, iter: 200/3382, mean loss: 0.02599980493100638\n",
      "Epoch 29/50, iter: 300/3382, mean loss: 0.005114541888581634\n",
      "Epoch 29/50, iter: 400/3382, mean loss: 0.0031947930597465302\n",
      "Epoch 29/50, iter: 500/3382, mean loss: 0.010522657464623214\n",
      "Epoch 29/50, iter: 600/3382, mean loss: 0.006838228560622106\n",
      "Epoch 29/50, iter: 700/3382, mean loss: 0.0076142154197989245\n",
      "Epoch 29/50, iter: 800/3382, mean loss: 0.0019104968739561557\n",
      "Epoch 29/50, iter: 900/3382, mean loss: 0.006314075894816042\n",
      "Epoch 29/50, iter: 1000/3382, mean loss: 0.02130279009909657\n",
      "Epoch 29/50, iter: 1100/3382, mean loss: 0.014744431279234789\n",
      "Epoch 29/50, iter: 1200/3382, mean loss: 0.03664028684530194\n",
      "Epoch 29/50, iter: 1300/3382, mean loss: 0.02753629068991387\n",
      "Epoch 29/50, iter: 1400/3382, mean loss: 0.020410790223462313\n",
      "Epoch 29/50, iter: 1500/3382, mean loss: 0.023494614528208935\n",
      "Epoch 29/50, iter: 1600/3382, mean loss: 0.021497391647755534\n",
      "Epoch 29/50, iter: 1700/3382, mean loss: 0.019007908516495354\n",
      "Epoch 29/50, iter: 1800/3382, mean loss: 0.03321175817408218\n",
      "Epoch 29/50, iter: 1900/3382, mean loss: 0.10115442381326148\n",
      "Epoch 29/50, iter: 2000/3382, mean loss: 0.02693581447332676\n",
      "Epoch 29/50, iter: 2100/3382, mean loss: 0.031716445840424115\n",
      "Epoch 29/50, iter: 2200/3382, mean loss: 0.04062347869403858\n",
      "Epoch 29/50, iter: 2300/3382, mean loss: 0.0202452399385146\n",
      "Epoch 29/50, iter: 2400/3382, mean loss: 0.07217914879122453\n",
      "Epoch 29/50, iter: 2500/3382, mean loss: 0.00842463406075872\n",
      "Epoch 29/50, iter: 2600/3382, mean loss: 0.09351939790822371\n",
      "Epoch 29/50, iter: 2700/3382, mean loss: 0.015986907821993697\n",
      "Epoch 29/50, iter: 2800/3382, mean loss: 0.01791861977045201\n",
      "Epoch 29/50, iter: 2900/3382, mean loss: 0.008370769133960643\n",
      "Epoch 29/50, iter: 3000/3382, mean loss: 0.03260765369735211\n",
      "Epoch 29/50, iter: 3100/3382, mean loss: 0.052896684660964116\n",
      "Epoch 29/50, iter: 3200/3382, mean loss: 0.031231108038207226\n",
      "Epoch 29/50, iter: 3300/3382, mean loss: 0.01269919587164857\n",
      "Epoch 30/50, iter: 100/3382, mean loss: 0.024254507052286555\n",
      "Epoch 30/50, iter: 200/3382, mean loss: 0.02195101187163427\n",
      "Epoch 30/50, iter: 300/3382, mean loss: 0.003809411879823372\n",
      "Epoch 30/50, iter: 400/3382, mean loss: 0.003999992821999499\n",
      "Epoch 30/50, iter: 500/3382, mean loss: 0.009005262950584054\n",
      "Epoch 30/50, iter: 600/3382, mean loss: 0.0012626667104749956\n",
      "Epoch 30/50, iter: 700/3382, mean loss: 0.00811360009419861\n",
      "Epoch 30/50, iter: 800/3382, mean loss: 0.0062264945607202905\n",
      "Epoch 30/50, iter: 900/3382, mean loss: 0.025694123649346673\n",
      "Epoch 30/50, iter: 1000/3382, mean loss: 0.013424781460478385\n",
      "Epoch 30/50, iter: 1100/3382, mean loss: 0.022278797044841845\n",
      "Epoch 30/50, iter: 1200/3382, mean loss: 0.03292016957054084\n",
      "Epoch 30/50, iter: 1300/3382, mean loss: 0.025500236053290593\n",
      "Epoch 30/50, iter: 1400/3382, mean loss: 0.012856223540817275\n",
      "Epoch 30/50, iter: 1500/3382, mean loss: 0.019574690737451234\n",
      "Epoch 30/50, iter: 1600/3382, mean loss: 0.022454183274034242\n",
      "Epoch 30/50, iter: 1700/3382, mean loss: 0.017490714874118574\n",
      "Epoch 30/50, iter: 1800/3382, mean loss: 0.039271257497136426\n",
      "Epoch 30/50, iter: 1900/3382, mean loss: 0.09245318789442933\n",
      "Epoch 30/50, iter: 2000/3382, mean loss: 0.044840414477271794\n",
      "Epoch 30/50, iter: 2100/3382, mean loss: 0.027566432084605737\n",
      "Epoch 30/50, iter: 2200/3382, mean loss: 0.05188209230615723\n",
      "Epoch 30/50, iter: 2300/3382, mean loss: 0.02361131612127906\n",
      "Epoch 30/50, iter: 2400/3382, mean loss: 0.05154372597758211\n",
      "Epoch 30/50, iter: 2500/3382, mean loss: 0.010517992646424367\n",
      "Epoch 30/50, iter: 2600/3382, mean loss: 0.057325289682407146\n",
      "Epoch 30/50, iter: 2700/3382, mean loss: 0.016543336537191068\n",
      "Epoch 30/50, iter: 2800/3382, mean loss: 0.016941249974769618\n",
      "Epoch 30/50, iter: 2900/3382, mean loss: 0.011327053794571497\n",
      "Epoch 30/50, iter: 3000/3382, mean loss: 0.008458342840335895\n",
      "Epoch 30/50, iter: 3100/3382, mean loss: 0.059483891517063334\n",
      "Epoch 30/50, iter: 3200/3382, mean loss: 0.01508656534323162\n",
      "Epoch 30/50, iter: 3300/3382, mean loss: 0.007617390000900777\n",
      "Epoch 31/50, iter: 100/3382, mean loss: 0.02503597357711307\n",
      "Epoch 31/50, iter: 200/3382, mean loss: 0.05009053672056922\n",
      "Epoch 31/50, iter: 300/3382, mean loss: 0.00018805870121195057\n",
      "Epoch 31/50, iter: 400/3382, mean loss: 0.0028531194393373125\n",
      "Epoch 31/50, iter: 500/3382, mean loss: 0.009953473821963002\n",
      "Epoch 31/50, iter: 600/3382, mean loss: 0.005981714907576112\n",
      "Epoch 31/50, iter: 700/3382, mean loss: 0.0063845246389460895\n",
      "Epoch 31/50, iter: 800/3382, mean loss: 0.0006312497809834384\n",
      "Epoch 31/50, iter: 900/3382, mean loss: 0.03630982424382665\n",
      "Epoch 31/50, iter: 1000/3382, mean loss: 0.01451088628591382\n",
      "Epoch 31/50, iter: 1100/3382, mean loss: 0.047046616239975234\n",
      "Epoch 31/50, iter: 1200/3382, mean loss: 0.03757552623948445\n",
      "Epoch 31/50, iter: 1300/3382, mean loss: 0.027452334575759813\n",
      "Epoch 31/50, iter: 1400/3382, mean loss: 0.023182637755846898\n",
      "Epoch 31/50, iter: 1500/3382, mean loss: 0.023921616531428356\n",
      "Epoch 31/50, iter: 1600/3382, mean loss: 0.029558746495804266\n",
      "Epoch 31/50, iter: 1700/3382, mean loss: 0.008002891019978869\n",
      "Epoch 31/50, iter: 1800/3382, mean loss: 0.041499446372536754\n",
      "Epoch 31/50, iter: 1900/3382, mean loss: 0.06610019591194145\n",
      "Epoch 31/50, iter: 2000/3382, mean loss: 0.028322432459920676\n",
      "Epoch 31/50, iter: 2100/3382, mean loss: 0.05788729826131309\n",
      "Epoch 31/50, iter: 2200/3382, mean loss: 0.04368888611651201\n",
      "Epoch 31/50, iter: 2300/3382, mean loss: 0.024606177375363244\n",
      "Epoch 31/50, iter: 2400/3382, mean loss: 0.017931033966444118\n",
      "Epoch 31/50, iter: 2500/3382, mean loss: 0.018732231902864598\n",
      "Epoch 31/50, iter: 2600/3382, mean loss: 0.05824819589766492\n",
      "Epoch 31/50, iter: 2700/3382, mean loss: 0.034078813300218266\n",
      "Epoch 31/50, iter: 2800/3382, mean loss: 0.016595372265256324\n",
      "Epoch 31/50, iter: 2900/3382, mean loss: 0.0390470293664589\n",
      "Epoch 31/50, iter: 3000/3382, mean loss: 0.03582040016334218\n",
      "Epoch 31/50, iter: 3100/3382, mean loss: 0.05039776604691685\n",
      "Epoch 31/50, iter: 3200/3382, mean loss: 0.010003795220704426\n",
      "Epoch 31/50, iter: 3300/3382, mean loss: 0.008356695752245286\n",
      "Epoch 32/50, iter: 100/3382, mean loss: 0.01723363786212456\n",
      "Epoch 32/50, iter: 200/3382, mean loss: 0.02403937111447771\n",
      "Epoch 32/50, iter: 300/3382, mean loss: 0.004326941380358953\n",
      "Epoch 32/50, iter: 400/3382, mean loss: 0.0010170236289733126\n",
      "Epoch 32/50, iter: 500/3382, mean loss: 0.009291354219529247\n",
      "Epoch 32/50, iter: 600/3382, mean loss: 0.0034114323570287298\n",
      "Epoch 32/50, iter: 700/3382, mean loss: 0.003718401628368717\n",
      "Epoch 32/50, iter: 800/3382, mean loss: 0.017992596910650784\n",
      "Epoch 32/50, iter: 900/3382, mean loss: 0.015417118954009474\n",
      "Epoch 32/50, iter: 1000/3382, mean loss: 0.00600220767952166\n",
      "Epoch 32/50, iter: 1100/3382, mean loss: 0.030051937802875735\n",
      "Epoch 32/50, iter: 1200/3382, mean loss: 0.04487142510257101\n",
      "Epoch 32/50, iter: 1300/3382, mean loss: 0.020530792968042277\n",
      "Epoch 32/50, iter: 1400/3382, mean loss: 0.015006025568588086\n",
      "Epoch 32/50, iter: 1500/3382, mean loss: 0.07285524567992599\n",
      "Epoch 32/50, iter: 1600/3382, mean loss: 0.018180206792067572\n",
      "Epoch 32/50, iter: 1700/3382, mean loss: 0.05346515645868141\n",
      "Epoch 32/50, iter: 1800/3382, mean loss: 0.05558682414745498\n",
      "Epoch 32/50, iter: 1900/3382, mean loss: 0.11333591477715124\n",
      "Epoch 32/50, iter: 2000/3382, mean loss: 0.0426117406734943\n",
      "Epoch 32/50, iter: 2100/3382, mean loss: 0.04696799081960648\n",
      "Epoch 32/50, iter: 2200/3382, mean loss: 0.046120427097974606\n",
      "Epoch 32/50, iter: 2300/3382, mean loss: 0.025442589949910683\n",
      "Epoch 32/50, iter: 2400/3382, mean loss: 0.05429497950082947\n",
      "Epoch 32/50, iter: 2500/3382, mean loss: 0.013606743262878354\n",
      "Epoch 32/50, iter: 2600/3382, mean loss: 0.03944323691126641\n",
      "Epoch 32/50, iter: 2700/3382, mean loss: 0.020678191392683978\n",
      "Epoch 32/50, iter: 2800/3382, mean loss: 0.04099876343314307\n",
      "Epoch 32/50, iter: 2900/3382, mean loss: 0.019807109321192867\n",
      "Epoch 32/50, iter: 3000/3382, mean loss: 0.04877257427989214\n",
      "Epoch 32/50, iter: 3100/3382, mean loss: 0.030392643058333987\n",
      "Epoch 32/50, iter: 3200/3382, mean loss: 0.016509032043700456\n",
      "Epoch 32/50, iter: 3300/3382, mean loss: 0.010013723647957775\n",
      "Epoch 33/50, iter: 100/3382, mean loss: 0.021691247260340028\n",
      "Epoch 33/50, iter: 200/3382, mean loss: 0.015877019543409608\n",
      "Epoch 33/50, iter: 300/3382, mean loss: 0.0013965944908722605\n",
      "Epoch 33/50, iter: 400/3382, mean loss: 0.0020014736768640164\n",
      "Epoch 33/50, iter: 500/3382, mean loss: 0.002239434832174112\n",
      "Epoch 33/50, iter: 600/3382, mean loss: 0.005814945892064749\n",
      "Epoch 33/50, iter: 700/3382, mean loss: 0.003427729957141672\n",
      "Epoch 33/50, iter: 800/3382, mean loss: 0.015614195369605852\n",
      "Epoch 33/50, iter: 900/3382, mean loss: 0.01364161704701786\n",
      "Epoch 33/50, iter: 1000/3382, mean loss: 0.006493721609176539\n",
      "Epoch 33/50, iter: 1100/3382, mean loss: 0.01885230059725206\n",
      "Epoch 33/50, iter: 1200/3382, mean loss: 0.036487823370059264\n",
      "Epoch 33/50, iter: 1300/3382, mean loss: 0.016448116620181957\n",
      "Epoch 33/50, iter: 1400/3382, mean loss: 0.02583411436894771\n",
      "Epoch 33/50, iter: 1500/3382, mean loss: 0.00840542981933094\n",
      "Epoch 33/50, iter: 1600/3382, mean loss: 0.019283223895862064\n",
      "Epoch 33/50, iter: 1700/3382, mean loss: 0.02482680392798283\n",
      "Epoch 33/50, iter: 1800/3382, mean loss: 0.04436554003956281\n",
      "Epoch 33/50, iter: 1900/3382, mean loss: 0.08737323260336155\n",
      "Epoch 33/50, iter: 2000/3382, mean loss: 0.03297489778621177\n",
      "Epoch 33/50, iter: 2100/3382, mean loss: 0.018153892948608395\n",
      "Epoch 33/50, iter: 2200/3382, mean loss: 0.04051724325235483\n",
      "Epoch 33/50, iter: 2300/3382, mean loss: 0.019811789831246145\n",
      "Epoch 33/50, iter: 2400/3382, mean loss: 0.02054237484952331\n",
      "Epoch 33/50, iter: 2500/3382, mean loss: 0.030866273797711372\n",
      "Epoch 33/50, iter: 2600/3382, mean loss: 0.061116734213208304\n",
      "Epoch 33/50, iter: 2700/3382, mean loss: 0.021919027445684948\n",
      "Epoch 33/50, iter: 2800/3382, mean loss: 0.030783916720046135\n",
      "Epoch 33/50, iter: 2900/3382, mean loss: 0.01664339395093066\n",
      "Epoch 33/50, iter: 3000/3382, mean loss: 0.028168854763980917\n",
      "Epoch 33/50, iter: 3100/3382, mean loss: 0.013461315722759331\n",
      "Epoch 33/50, iter: 3200/3382, mean loss: 0.012474881878055868\n",
      "Epoch 33/50, iter: 3300/3382, mean loss: 0.012623003980342417\n",
      "Epoch 34/50, iter: 100/3382, mean loss: 0.014907781343330413\n",
      "Epoch 34/50, iter: 200/3382, mean loss: 0.014207080476085779\n",
      "Epoch 34/50, iter: 300/3382, mean loss: 0.00030393992203180174\n",
      "Epoch 34/50, iter: 400/3382, mean loss: 0.0005117187158223046\n",
      "Epoch 34/50, iter: 500/3382, mean loss: 0.004354721025523212\n",
      "Epoch 34/50, iter: 600/3382, mean loss: 0.00472499896829035\n",
      "Epoch 34/50, iter: 700/3382, mean loss: 0.0012079848325915066\n",
      "Epoch 34/50, iter: 800/3382, mean loss: 0.0016043795907822655\n",
      "Epoch 34/50, iter: 900/3382, mean loss: 0.0014986089292389692\n",
      "Epoch 34/50, iter: 1000/3382, mean loss: 0.0066004057352549595\n",
      "Epoch 34/50, iter: 1100/3382, mean loss: 0.01755445405688519\n",
      "Epoch 34/50, iter: 1200/3382, mean loss: 0.031409369230323704\n",
      "Epoch 34/50, iter: 1300/3382, mean loss: 0.04781411364407066\n",
      "Epoch 34/50, iter: 1400/3382, mean loss: 0.046010200231755366\n",
      "Epoch 34/50, iter: 1500/3382, mean loss: 0.006829703483812856\n",
      "Epoch 34/50, iter: 1600/3382, mean loss: 0.010455881739906338\n",
      "Epoch 34/50, iter: 1700/3382, mean loss: 0.002146905571809583\n",
      "Epoch 34/50, iter: 1800/3382, mean loss: 0.03801825490387373\n",
      "Epoch 34/50, iter: 1900/3382, mean loss: 0.0816611097194919\n",
      "Epoch 34/50, iter: 2000/3382, mean loss: 0.011554687247335452\n",
      "Epoch 34/50, iter: 2100/3382, mean loss: 0.026485557807310867\n",
      "Epoch 34/50, iter: 2200/3382, mean loss: 0.014355494885932317\n",
      "Epoch 34/50, iter: 2300/3382, mean loss: 0.018436956304961498\n",
      "Epoch 34/50, iter: 2400/3382, mean loss: 0.012605494158806714\n",
      "Epoch 34/50, iter: 2500/3382, mean loss: 0.01474826482144035\n",
      "Epoch 34/50, iter: 2600/3382, mean loss: 0.08051091676257335\n",
      "Epoch 34/50, iter: 2700/3382, mean loss: 0.025885501719808062\n",
      "Epoch 34/50, iter: 2800/3382, mean loss: 0.02035668804258414\n",
      "Epoch 34/50, iter: 2900/3382, mean loss: 0.008343650144950913\n",
      "Epoch 34/50, iter: 3000/3382, mean loss: 0.06457843055438882\n",
      "Epoch 34/50, iter: 3100/3382, mean loss: 0.011150339448913797\n",
      "Epoch 34/50, iter: 3200/3382, mean loss: 0.012137643507939444\n",
      "Epoch 34/50, iter: 3300/3382, mean loss: 0.003215967700191662\n",
      "Epoch 35/50, iter: 100/3382, mean loss: 0.016305933665692187\n",
      "Epoch 35/50, iter: 200/3382, mean loss: 0.02300423654472926\n",
      "Epoch 35/50, iter: 300/3382, mean loss: 0.001139093975937655\n",
      "Epoch 35/50, iter: 400/3382, mean loss: 0.0011782561137997404\n",
      "Epoch 35/50, iter: 500/3382, mean loss: 0.001554430397183708\n",
      "Epoch 35/50, iter: 600/3382, mean loss: 0.002728981277773528\n",
      "Epoch 35/50, iter: 700/3382, mean loss: 0.011767933069410503\n",
      "Epoch 35/50, iter: 800/3382, mean loss: 0.0007648136482591638\n",
      "Epoch 35/50, iter: 900/3382, mean loss: 0.0020198118180164925\n",
      "Epoch 35/50, iter: 1000/3382, mean loss: 0.05800405395996073\n",
      "Epoch 35/50, iter: 1100/3382, mean loss: 0.018747224774211802\n",
      "Epoch 35/50, iter: 1200/3382, mean loss: 0.06351052278738344\n",
      "Epoch 35/50, iter: 1300/3382, mean loss: 0.031576079265626264\n",
      "Epoch 35/50, iter: 1400/3382, mean loss: 0.03578209501312671\n",
      "Epoch 35/50, iter: 1500/3382, mean loss: 0.024452873497484724\n",
      "Epoch 35/50, iter: 1600/3382, mean loss: 0.014335249472406986\n",
      "Epoch 35/50, iter: 1700/3382, mean loss: 0.002731633174007442\n",
      "Epoch 35/50, iter: 1800/3382, mean loss: 0.02155526317952841\n",
      "Epoch 35/50, iter: 1900/3382, mean loss: 0.05778515492496723\n",
      "Epoch 35/50, iter: 2000/3382, mean loss: 0.01428150955274475\n",
      "Epoch 35/50, iter: 2100/3382, mean loss: 0.02432954952090384\n",
      "Epoch 35/50, iter: 2200/3382, mean loss: 0.03780980551866343\n",
      "Epoch 35/50, iter: 2300/3382, mean loss: 0.02278585802892664\n",
      "Epoch 35/50, iter: 2400/3382, mean loss: 0.014591472593819788\n",
      "Epoch 35/50, iter: 2500/3382, mean loss: 0.009105344714024213\n",
      "Epoch 35/50, iter: 2600/3382, mean loss: 0.039869746237752926\n",
      "Epoch 35/50, iter: 2700/3382, mean loss: 0.00646640638925895\n",
      "Epoch 35/50, iter: 2800/3382, mean loss: 0.023215841392391745\n",
      "Epoch 35/50, iter: 2900/3382, mean loss: 0.02176681315528306\n",
      "Epoch 35/50, iter: 3000/3382, mean loss: 0.010856138619387928\n",
      "Epoch 35/50, iter: 3100/3382, mean loss: 0.02219593259404629\n",
      "Epoch 35/50, iter: 3200/3382, mean loss: 0.02294218557363159\n",
      "Epoch 35/50, iter: 3300/3382, mean loss: 0.005871026520138862\n",
      "Epoch 36/50, iter: 100/3382, mean loss: 0.014354397812640904\n",
      "Epoch 36/50, iter: 200/3382, mean loss: 0.012916230878108302\n",
      "Epoch 36/50, iter: 300/3382, mean loss: 0.0076644459349641285\n",
      "Epoch 36/50, iter: 400/3382, mean loss: 0.01795301629915574\n",
      "Epoch 36/50, iter: 500/3382, mean loss: 0.004789389889570934\n",
      "Epoch 36/50, iter: 600/3382, mean loss: 0.001557053496991756\n",
      "Epoch 36/50, iter: 700/3382, mean loss: 0.002021669607279435\n",
      "Epoch 36/50, iter: 800/3382, mean loss: 0.0006058755497057433\n",
      "Epoch 36/50, iter: 900/3382, mean loss: 0.0010846818497419264\n",
      "Epoch 36/50, iter: 1000/3382, mean loss: 0.006712494950992429\n",
      "Epoch 36/50, iter: 1100/3382, mean loss: 0.018714085175146878\n",
      "Epoch 36/50, iter: 1200/3382, mean loss: 0.032360452727963535\n",
      "Epoch 36/50, iter: 1300/3382, mean loss: 0.019953625559821404\n",
      "Epoch 36/50, iter: 1400/3382, mean loss: 0.019729677673289137\n",
      "Epoch 36/50, iter: 1500/3382, mean loss: 0.003539405053456619\n",
      "Epoch 36/50, iter: 1600/3382, mean loss: 0.021129834278175892\n",
      "Epoch 36/50, iter: 1700/3382, mean loss: 0.004178427042805914\n",
      "Epoch 36/50, iter: 1800/3382, mean loss: 0.04882613655997954\n",
      "Epoch 36/50, iter: 1900/3382, mean loss: 0.03388024961043492\n",
      "Epoch 36/50, iter: 2000/3382, mean loss: 0.010288790187882278\n",
      "Epoch 36/50, iter: 2100/3382, mean loss: 0.03718113171927406\n",
      "Epoch 36/50, iter: 2200/3382, mean loss: 0.029921047885264968\n",
      "Epoch 36/50, iter: 2300/3382, mean loss: 0.013520950915745473\n",
      "Epoch 36/50, iter: 2400/3382, mean loss: 0.02482013152963084\n",
      "Epoch 36/50, iter: 2500/3382, mean loss: 0.007556370514746646\n",
      "Epoch 36/50, iter: 2600/3382, mean loss: 0.04827101556275238\n",
      "Epoch 36/50, iter: 2700/3382, mean loss: 0.008647261695827205\n",
      "Epoch 36/50, iter: 2800/3382, mean loss: 0.01290168875396514\n",
      "Epoch 36/50, iter: 2900/3382, mean loss: 0.008793215941932147\n",
      "Epoch 36/50, iter: 3000/3382, mean loss: 0.03317225047592522\n",
      "Epoch 36/50, iter: 3100/3382, mean loss: 0.01608992718607695\n",
      "Epoch 36/50, iter: 3200/3382, mean loss: 0.0208177556740052\n",
      "Epoch 36/50, iter: 3300/3382, mean loss: 0.012042240285033898\n",
      "Epoch 37/50, iter: 100/3382, mean loss: 0.02054624507479083\n",
      "Epoch 37/50, iter: 200/3382, mean loss: 0.02311461054036517\n",
      "Epoch 37/50, iter: 300/3382, mean loss: 0.0016808526043703153\n",
      "Epoch 37/50, iter: 400/3382, mean loss: 0.001517888194475816\n",
      "Epoch 37/50, iter: 500/3382, mean loss: 0.004535757059764442\n",
      "Epoch 37/50, iter: 600/3382, mean loss: 0.0003998362972212277\n",
      "Epoch 37/50, iter: 700/3382, mean loss: 0.0011987835426231187\n",
      "Epoch 37/50, iter: 800/3382, mean loss: 0.0036860372978284772\n",
      "Epoch 37/50, iter: 900/3382, mean loss: 0.004585031758909999\n",
      "Epoch 37/50, iter: 1000/3382, mean loss: 0.00872780364666351\n",
      "Epoch 37/50, iter: 1100/3382, mean loss: 0.01151400808354463\n",
      "Epoch 37/50, iter: 1200/3382, mean loss: 0.05432898654802266\n",
      "Epoch 37/50, iter: 1300/3382, mean loss: 0.03679291716534898\n",
      "Epoch 37/50, iter: 1400/3382, mean loss: 0.009015627294883153\n",
      "Epoch 37/50, iter: 1500/3382, mean loss: 0.031175669379169976\n",
      "Epoch 37/50, iter: 1600/3382, mean loss: 0.015722283620761245\n",
      "Epoch 37/50, iter: 1700/3382, mean loss: 0.001437323064742344\n",
      "Epoch 37/50, iter: 1800/3382, mean loss: 0.04231470724704945\n",
      "Epoch 37/50, iter: 1900/3382, mean loss: 0.0471273437196486\n",
      "Epoch 37/50, iter: 2000/3382, mean loss: 0.010303110421423156\n",
      "Epoch 37/50, iter: 2100/3382, mean loss: 0.3636447569168344\n",
      "Epoch 37/50, iter: 2200/3382, mean loss: 0.02982326236684276\n",
      "Epoch 37/50, iter: 2300/3382, mean loss: 0.08263833289977303\n",
      "Epoch 37/50, iter: 2400/3382, mean loss: 0.09147194845206456\n",
      "Epoch 37/50, iter: 2500/3382, mean loss: 0.01355453888584698\n",
      "Epoch 37/50, iter: 2600/3382, mean loss: 0.0655977897640901\n",
      "Epoch 37/50, iter: 2700/3382, mean loss: 0.03293153577547834\n",
      "Epoch 37/50, iter: 2800/3382, mean loss: 0.03883636674588388\n",
      "Epoch 37/50, iter: 2900/3382, mean loss: 0.02297344583392366\n",
      "Epoch 37/50, iter: 3000/3382, mean loss: 0.02457885322458317\n",
      "Epoch 37/50, iter: 3100/3382, mean loss: 0.017198962846407255\n",
      "Epoch 37/50, iter: 3200/3382, mean loss: 0.029381241639792784\n",
      "Epoch 37/50, iter: 3300/3382, mean loss: 0.019936790918932915\n",
      "Epoch 38/50, iter: 100/3382, mean loss: 0.010853441586642525\n",
      "Epoch 38/50, iter: 200/3382, mean loss: 0.01994491807119619\n",
      "Epoch 38/50, iter: 300/3382, mean loss: 0.010117393578712709\n",
      "Epoch 38/50, iter: 400/3382, mean loss: 0.007653066947851705\n",
      "Epoch 38/50, iter: 500/3382, mean loss: 0.06370311757371788\n",
      "Epoch 38/50, iter: 600/3382, mean loss: 0.0009904024748855988\n",
      "Epoch 38/50, iter: 700/3382, mean loss: 0.0006172136712044818\n",
      "Epoch 38/50, iter: 800/3382, mean loss: 0.00013611211478156804\n",
      "Epoch 38/50, iter: 900/3382, mean loss: 0.00584556817597452\n",
      "Epoch 38/50, iter: 1000/3382, mean loss: 0.004581763900591404\n",
      "Epoch 38/50, iter: 1100/3382, mean loss: 0.010189710431816117\n",
      "Epoch 38/50, iter: 1200/3382, mean loss: 0.03145103769347664\n",
      "Epoch 38/50, iter: 1300/3382, mean loss: 0.021103601650231382\n",
      "Epoch 38/50, iter: 1400/3382, mean loss: 0.02362593448005768\n",
      "Epoch 38/50, iter: 1500/3382, mean loss: 0.013779932065025377\n",
      "Epoch 38/50, iter: 1600/3382, mean loss: 0.012167744276652855\n",
      "Epoch 38/50, iter: 1700/3382, mean loss: 0.04441538964094814\n",
      "Epoch 38/50, iter: 1800/3382, mean loss: 0.05976924104690187\n",
      "Epoch 38/50, iter: 1900/3382, mean loss: 0.07849139553331931\n",
      "Epoch 38/50, iter: 2000/3382, mean loss: 0.019720198853857483\n",
      "Epoch 38/50, iter: 2100/3382, mean loss: 0.4037987697797811\n",
      "Epoch 38/50, iter: 2200/3382, mean loss: 0.07968910945556856\n",
      "Epoch 38/50, iter: 2300/3382, mean loss: 0.07203519123094196\n",
      "Epoch 38/50, iter: 2400/3382, mean loss: 0.2692699145499851\n",
      "Epoch 38/50, iter: 2500/3382, mean loss: 0.23022393374990038\n",
      "Epoch 38/50, iter: 2600/3382, mean loss: 0.10420916570607304\n",
      "Epoch 38/50, iter: 2700/3382, mean loss: 0.009684307498669576\n",
      "Epoch 38/50, iter: 2800/3382, mean loss: 0.03266384226128245\n",
      "Epoch 38/50, iter: 2900/3382, mean loss: 0.009077642340360974\n",
      "Epoch 38/50, iter: 3000/3382, mean loss: 0.05792892436235672\n",
      "Epoch 38/50, iter: 3100/3382, mean loss: 0.0182323276583546\n",
      "Epoch 38/50, iter: 3200/3382, mean loss: 0.02212052862657725\n",
      "Epoch 38/50, iter: 3300/3382, mean loss: 0.009540606534756328\n",
      "Epoch 39/50, iter: 100/3382, mean loss: 0.01650383990532223\n",
      "Epoch 39/50, iter: 200/3382, mean loss: 0.05295053806506662\n",
      "Epoch 39/50, iter: 300/3382, mean loss: 0.0009614121293140343\n",
      "Epoch 39/50, iter: 400/3382, mean loss: 0.006684162968549607\n",
      "Epoch 39/50, iter: 500/3382, mean loss: 0.02727576557867568\n",
      "Epoch 39/50, iter: 600/3382, mean loss: 0.04262080354587539\n",
      "Epoch 39/50, iter: 700/3382, mean loss: 0.0009956460005439282\n",
      "Epoch 39/50, iter: 800/3382, mean loss: 0.001372435599816555\n",
      "Epoch 39/50, iter: 900/3382, mean loss: 0.023944342531517542\n",
      "Epoch 39/50, iter: 1000/3382, mean loss: 0.006779291862566979\n",
      "Epoch 39/50, iter: 1100/3382, mean loss: 0.010397861301950187\n",
      "Epoch 39/50, iter: 1200/3382, mean loss: 0.018356563408560938\n",
      "Epoch 39/50, iter: 1300/3382, mean loss: 0.02392689074258648\n",
      "Epoch 39/50, iter: 1400/3382, mean loss: 0.01725510550254594\n",
      "Epoch 39/50, iter: 1500/3382, mean loss: 0.023025390596391093\n",
      "Epoch 39/50, iter: 1600/3382, mean loss: 0.06845591454603216\n",
      "Epoch 39/50, iter: 1700/3382, mean loss: 0.04188815393785621\n",
      "Epoch 39/50, iter: 1800/3382, mean loss: 0.02652762762447292\n",
      "Epoch 39/50, iter: 1900/3382, mean loss: 0.0569389285455194\n",
      "Epoch 39/50, iter: 2000/3382, mean loss: 0.014354738325915797\n",
      "Epoch 39/50, iter: 2100/3382, mean loss: 0.033560913124135755\n",
      "Epoch 39/50, iter: 2200/3382, mean loss: 0.03269692216292839\n",
      "Epoch 39/50, iter: 2300/3382, mean loss: 0.015369251467540614\n",
      "Epoch 39/50, iter: 2400/3382, mean loss: 0.04146958816361437\n",
      "Epoch 39/50, iter: 2500/3382, mean loss: 0.06628022761633524\n",
      "Epoch 39/50, iter: 2600/3382, mean loss: 0.07316559587130822\n",
      "Epoch 39/50, iter: 2700/3382, mean loss: 0.006112668302317239\n",
      "Epoch 39/50, iter: 2800/3382, mean loss: 0.016289896981686525\n",
      "Epoch 39/50, iter: 2900/3382, mean loss: 0.03990490658154204\n",
      "Epoch 39/50, iter: 3000/3382, mean loss: 0.01819818568439423\n",
      "Epoch 39/50, iter: 3100/3382, mean loss: 0.03752908402001765\n",
      "Epoch 39/50, iter: 3200/3382, mean loss: 0.009238710100802123\n",
      "Epoch 39/50, iter: 3300/3382, mean loss: 0.007407063193615571\n",
      "Epoch 40/50, iter: 100/3382, mean loss: 0.03374902041888419\n",
      "Epoch 40/50, iter: 200/3382, mean loss: 0.02027062579179695\n",
      "Epoch 40/50, iter: 300/3382, mean loss: 6.85853166077166e-05\n",
      "Epoch 40/50, iter: 400/3382, mean loss: 0.0006892757750097544\n",
      "Epoch 40/50, iter: 500/3382, mean loss: 0.00916370085741569\n",
      "Epoch 40/50, iter: 600/3382, mean loss: 0.006885133174427445\n",
      "Epoch 40/50, iter: 700/3382, mean loss: 0.0007492632556819601\n",
      "Epoch 40/50, iter: 800/3382, mean loss: 0.00027375755585445916\n",
      "Epoch 40/50, iter: 900/3382, mean loss: 0.001999060323741446\n",
      "Epoch 40/50, iter: 1000/3382, mean loss: 0.016619123312808314\n",
      "Epoch 40/50, iter: 1100/3382, mean loss: 0.00816737500570678\n",
      "Epoch 40/50, iter: 1200/3382, mean loss: 0.031133925677215794\n",
      "Epoch 40/50, iter: 1300/3382, mean loss: 0.01562653257362772\n",
      "Epoch 40/50, iter: 1400/3382, mean loss: 0.019936660293018063\n",
      "Epoch 40/50, iter: 1500/3382, mean loss: 0.005515573252983259\n",
      "Epoch 40/50, iter: 1600/3382, mean loss: 0.012484281630778754\n",
      "Epoch 40/50, iter: 1700/3382, mean loss: 0.02116072887874747\n",
      "Epoch 40/50, iter: 1800/3382, mean loss: 0.03641025828264301\n",
      "Epoch 40/50, iter: 1900/3382, mean loss: 0.05598645823497513\n",
      "Epoch 40/50, iter: 2000/3382, mean loss: 0.010241428074755348\n",
      "Epoch 40/50, iter: 2100/3382, mean loss: 0.061214659049590454\n",
      "Epoch 40/50, iter: 2200/3382, mean loss: 0.02325929858582345\n",
      "Epoch 40/50, iter: 2300/3382, mean loss: 0.005919004467975881\n",
      "Epoch 40/50, iter: 2400/3382, mean loss: 0.03892228025505311\n",
      "Epoch 40/50, iter: 2500/3382, mean loss: 0.027231333084922617\n",
      "Epoch 40/50, iter: 2600/3382, mean loss: 0.08032349726659639\n",
      "Epoch 40/50, iter: 2700/3382, mean loss: 0.015679268801267802\n",
      "Epoch 40/50, iter: 2800/3382, mean loss: 0.005190139872172814\n",
      "Epoch 40/50, iter: 2900/3382, mean loss: 0.017883335644651766\n",
      "Epoch 40/50, iter: 3000/3382, mean loss: 0.014835090041694272\n",
      "Epoch 40/50, iter: 3100/3382, mean loss: 0.015503911994673167\n",
      "Epoch 40/50, iter: 3200/3382, mean loss: 0.021482266265274604\n",
      "Epoch 40/50, iter: 3300/3382, mean loss: 0.00444027188720689\n",
      "Epoch 41/50, iter: 100/3382, mean loss: 0.012047126688481171\n",
      "Epoch 41/50, iter: 200/3382, mean loss: 0.022434976970856047\n",
      "Epoch 41/50, iter: 300/3382, mean loss: 0.0002712055059681262\n",
      "Epoch 41/50, iter: 400/3382, mean loss: 0.0013810734451849172\n",
      "Epoch 41/50, iter: 500/3382, mean loss: 0.007948247104067434\n",
      "Epoch 41/50, iter: 600/3382, mean loss: 0.00039698620535734365\n",
      "Epoch 41/50, iter: 700/3382, mean loss: 6.957617654432369e-05\n",
      "Epoch 41/50, iter: 800/3382, mean loss: 0.0013105769022501335\n",
      "Epoch 41/50, iter: 900/3382, mean loss: 0.003007177976440154\n",
      "Epoch 41/50, iter: 1000/3382, mean loss: 0.002498180475068601\n",
      "Epoch 41/50, iter: 1100/3382, mean loss: 0.022608966014382618\n",
      "Epoch 41/50, iter: 1200/3382, mean loss: 0.019491444279881767\n",
      "Epoch 41/50, iter: 1300/3382, mean loss: 0.015229924446874463\n",
      "Epoch 41/50, iter: 1400/3382, mean loss: 0.021571574412852144\n",
      "Epoch 41/50, iter: 1500/3382, mean loss: 0.010038334875987723\n",
      "Epoch 41/50, iter: 1600/3382, mean loss: 0.010766621664470044\n",
      "Epoch 41/50, iter: 1700/3382, mean loss: 0.0037041486432527293\n",
      "Epoch 41/50, iter: 1800/3382, mean loss: 0.009208326372103812\n",
      "Epoch 41/50, iter: 1900/3382, mean loss: 0.044927358239939395\n",
      "Epoch 41/50, iter: 2000/3382, mean loss: 0.010318722861231039\n",
      "Epoch 41/50, iter: 2100/3382, mean loss: 0.029512513628438732\n",
      "Epoch 41/50, iter: 2200/3382, mean loss: 0.032736711979953946\n",
      "Epoch 41/50, iter: 2300/3382, mean loss: 0.01244437038606428\n",
      "Epoch 41/50, iter: 2400/3382, mean loss: 0.014673909087475536\n",
      "Epoch 41/50, iter: 2500/3382, mean loss: 0.009101019025480354\n",
      "Epoch 41/50, iter: 2600/3382, mean loss: 0.08014441980560544\n",
      "Epoch 41/50, iter: 2700/3382, mean loss: 0.005671719437335696\n",
      "Epoch 41/50, iter: 2800/3382, mean loss: 0.011784850387869205\n",
      "Epoch 41/50, iter: 2900/3382, mean loss: 0.004033081619844339\n",
      "Epoch 41/50, iter: 3000/3382, mean loss: 0.009255733166727892\n",
      "Epoch 41/50, iter: 3100/3382, mean loss: 0.01594734975792061\n",
      "Epoch 41/50, iter: 3200/3382, mean loss: 0.0032136003207471476\n",
      "Epoch 41/50, iter: 3300/3382, mean loss: 0.003495808905732716\n",
      "Epoch 42/50, iter: 100/3382, mean loss: 0.004415623699301747\n",
      "Epoch 42/50, iter: 200/3382, mean loss: 0.02542661179462673\n",
      "Epoch 42/50, iter: 300/3382, mean loss: 0.0001067534576140261\n",
      "Epoch 42/50, iter: 400/3382, mean loss: 0.0006492827696202142\n",
      "Epoch 42/50, iter: 500/3382, mean loss: 0.002848855098623062\n",
      "Epoch 42/50, iter: 600/3382, mean loss: 0.001155354964694375\n",
      "Epoch 42/50, iter: 700/3382, mean loss: 4.070568878798753e-05\n",
      "Epoch 42/50, iter: 800/3382, mean loss: 0.000546522083661074\n",
      "Epoch 42/50, iter: 900/3382, mean loss: 0.00431560751697976\n",
      "Epoch 42/50, iter: 1000/3382, mean loss: 0.008720534160747456\n",
      "Epoch 42/50, iter: 1100/3382, mean loss: 0.0233045194985138\n",
      "Epoch 42/50, iter: 1200/3382, mean loss: 0.032374091654405995\n",
      "Epoch 42/50, iter: 1300/3382, mean loss: 0.019366546902015395\n",
      "Epoch 42/50, iter: 1400/3382, mean loss: 0.011199619222202983\n",
      "Epoch 42/50, iter: 1500/3382, mean loss: 0.012930601930007661\n",
      "Epoch 42/50, iter: 1600/3382, mean loss: 0.011096025910128092\n",
      "Epoch 42/50, iter: 1700/3382, mean loss: 0.02262384041499956\n",
      "Epoch 42/50, iter: 1800/3382, mean loss: 0.02725401518377101\n",
      "Epoch 42/50, iter: 1900/3382, mean loss: 0.06658230631945262\n",
      "Epoch 42/50, iter: 2000/3382, mean loss: 0.014134075599536474\n",
      "Epoch 42/50, iter: 2100/3382, mean loss: 0.03449832889034941\n",
      "Epoch 42/50, iter: 2200/3382, mean loss: 0.030689465674808538\n",
      "Epoch 42/50, iter: 2300/3382, mean loss: 0.016790587885211716\n",
      "Epoch 42/50, iter: 2400/3382, mean loss: 0.013957900631266434\n",
      "Epoch 42/50, iter: 2500/3382, mean loss: 0.00388392371076268\n",
      "Epoch 42/50, iter: 2600/3382, mean loss: 0.07202092857210143\n",
      "Epoch 42/50, iter: 2700/3382, mean loss: 0.020395796233681443\n",
      "Epoch 42/50, iter: 2800/3382, mean loss: 0.03445985457757533\n",
      "Epoch 42/50, iter: 2900/3382, mean loss: 0.004229009014851357\n",
      "Epoch 42/50, iter: 3000/3382, mean loss: 0.019376201562065418\n",
      "Epoch 42/50, iter: 3100/3382, mean loss: 0.01081190852401196\n",
      "Epoch 42/50, iter: 3200/3382, mean loss: 0.0017112807219010762\n",
      "Epoch 42/50, iter: 3300/3382, mean loss: 0.0025880709904737742\n",
      "Epoch 43/50, iter: 100/3382, mean loss: 0.04278676080066358\n",
      "Epoch 43/50, iter: 200/3382, mean loss: 0.04329909176411931\n",
      "Epoch 43/50, iter: 300/3382, mean loss: 0.037555470535261364\n",
      "Epoch 43/50, iter: 400/3382, mean loss: 0.0002899686691968384\n",
      "Epoch 43/50, iter: 500/3382, mean loss: 0.0029095088070672046\n",
      "Epoch 43/50, iter: 600/3382, mean loss: 0.015875499239862555\n",
      "Epoch 43/50, iter: 700/3382, mean loss: 0.0019992310022090365\n",
      "Epoch 43/50, iter: 800/3382, mean loss: 0.04799424725997845\n",
      "Epoch 43/50, iter: 900/3382, mean loss: 0.0002913650517414723\n",
      "Epoch 43/50, iter: 1000/3382, mean loss: 0.008112935343369508\n",
      "Epoch 43/50, iter: 1100/3382, mean loss: 0.015797654058961753\n",
      "Epoch 43/50, iter: 1200/3382, mean loss: 0.03735832476353146\n",
      "Epoch 43/50, iter: 1300/3382, mean loss: 0.013048667716973661\n",
      "Epoch 43/50, iter: 1400/3382, mean loss: 0.01836919673190586\n",
      "Epoch 43/50, iter: 1500/3382, mean loss: 0.016772049426841528\n",
      "Epoch 43/50, iter: 1600/3382, mean loss: 0.01240085204241737\n",
      "Epoch 43/50, iter: 1700/3382, mean loss: 0.006487285819159005\n",
      "Epoch 43/50, iter: 1800/3382, mean loss: 0.017221153183038993\n",
      "Epoch 43/50, iter: 1900/3382, mean loss: 0.029382128902936344\n",
      "Epoch 43/50, iter: 2000/3382, mean loss: 0.008808909570963301\n",
      "Epoch 43/50, iter: 2100/3382, mean loss: 0.01355013775049386\n",
      "Epoch 43/50, iter: 2200/3382, mean loss: 0.022915400056772377\n",
      "Epoch 43/50, iter: 2300/3382, mean loss: 0.005298246771883726\n",
      "Epoch 43/50, iter: 2400/3382, mean loss: 0.007523509341090424\n",
      "Epoch 43/50, iter: 2500/3382, mean loss: 0.008467632325186755\n",
      "Epoch 43/50, iter: 2600/3382, mean loss: 0.055250390265791226\n",
      "Epoch 43/50, iter: 2700/3382, mean loss: 0.0165514434270872\n",
      "Epoch 43/50, iter: 2800/3382, mean loss: 0.01964381382835562\n",
      "Epoch 43/50, iter: 2900/3382, mean loss: 0.007787361025478674\n",
      "Epoch 43/50, iter: 3000/3382, mean loss: 0.0065963523309070385\n",
      "Epoch 43/50, iter: 3100/3382, mean loss: 0.020847348987764924\n",
      "Epoch 43/50, iter: 3200/3382, mean loss: 0.0014854604642720304\n",
      "Epoch 43/50, iter: 3300/3382, mean loss: 0.0018822546149370822\n",
      "Epoch 44/50, iter: 100/3382, mean loss: 0.0065506421538667325\n",
      "Epoch 44/50, iter: 200/3382, mean loss: 0.011419376590953512\n",
      "Epoch 44/50, iter: 300/3382, mean loss: 0.0008684157594500163\n",
      "Epoch 44/50, iter: 400/3382, mean loss: 0.0007435355515967501\n",
      "Epoch 44/50, iter: 500/3382, mean loss: 0.004847575999401919\n",
      "Epoch 44/50, iter: 600/3382, mean loss: 0.002122889673921513\n",
      "Epoch 44/50, iter: 700/3382, mean loss: 5.251045054897929e-05\n",
      "Epoch 44/50, iter: 800/3382, mean loss: 0.0014819771679547955\n",
      "Epoch 44/50, iter: 900/3382, mean loss: 0.0064943862998779875\n",
      "Epoch 44/50, iter: 1000/3382, mean loss: 0.0133503706290184\n",
      "Epoch 44/50, iter: 1100/3382, mean loss: 0.011412369544859437\n",
      "Epoch 44/50, iter: 1200/3382, mean loss: 0.027437304636090402\n",
      "Epoch 44/50, iter: 1300/3382, mean loss: 0.020892588240929263\n",
      "Epoch 44/50, iter: 1400/3382, mean loss: 0.019614863582198404\n",
      "Epoch 44/50, iter: 1500/3382, mean loss: 0.018445510165613365\n",
      "Epoch 44/50, iter: 1600/3382, mean loss: 0.003851280118621787\n",
      "Epoch 44/50, iter: 1700/3382, mean loss: 0.01147736161606325\n",
      "Epoch 44/50, iter: 1800/3382, mean loss: 0.013870702500518134\n",
      "Epoch 44/50, iter: 1900/3382, mean loss: 0.06562410736712217\n",
      "Epoch 44/50, iter: 2000/3382, mean loss: 0.008517354440323678\n",
      "Epoch 44/50, iter: 2100/3382, mean loss: 0.04078214900834954\n",
      "Epoch 44/50, iter: 2200/3382, mean loss: 0.01786482191384774\n",
      "Epoch 44/50, iter: 2300/3382, mean loss: 0.002042084102348802\n",
      "Epoch 44/50, iter: 2400/3382, mean loss: 0.00487062483358983\n",
      "Epoch 44/50, iter: 2500/3382, mean loss: 0.003689858871043228\n",
      "Epoch 44/50, iter: 2600/3382, mean loss: 0.06544859585338926\n",
      "Epoch 44/50, iter: 2700/3382, mean loss: 0.017844957842983254\n",
      "Epoch 44/50, iter: 2800/3382, mean loss: 0.0047857492925468745\n",
      "Epoch 44/50, iter: 2900/3382, mean loss: 0.004234261725164288\n",
      "Epoch 44/50, iter: 3000/3382, mean loss: 0.004071681030709691\n",
      "Epoch 44/50, iter: 3100/3382, mean loss: 0.00934703918220908\n",
      "Epoch 44/50, iter: 3200/3382, mean loss: 0.002530625096425716\n",
      "Epoch 44/50, iter: 3300/3382, mean loss: 0.008354541379373543\n",
      "Epoch 45/50, iter: 100/3382, mean loss: 0.010596629645228362\n",
      "Epoch 45/50, iter: 200/3382, mean loss: 0.028396086834338946\n",
      "Epoch 45/50, iter: 300/3382, mean loss: 0.00011306301889487003\n",
      "Epoch 45/50, iter: 400/3382, mean loss: 0.00048152827628271665\n",
      "Epoch 45/50, iter: 500/3382, mean loss: 0.0024342201305472245\n",
      "Epoch 45/50, iter: 600/3382, mean loss: 0.0005372271893800118\n",
      "Epoch 45/50, iter: 700/3382, mean loss: 0.00010504095525739388\n",
      "Epoch 45/50, iter: 800/3382, mean loss: 5.458662073440479e-05\n",
      "Epoch 45/50, iter: 900/3382, mean loss: 0.0008129210884551696\n",
      "Epoch 45/50, iter: 1000/3382, mean loss: 0.0020309220032195085\n",
      "Epoch 45/50, iter: 1100/3382, mean loss: 0.027955551782446336\n",
      "Epoch 45/50, iter: 1200/3382, mean loss: 0.045592152703859516\n",
      "Epoch 45/50, iter: 1300/3382, mean loss: 0.017273225554481117\n",
      "Epoch 45/50, iter: 1400/3382, mean loss: 0.023077869909322358\n",
      "Epoch 45/50, iter: 1500/3382, mean loss: 0.010502846319775508\n",
      "Epoch 45/50, iter: 1600/3382, mean loss: 0.01826785480450397\n",
      "Epoch 45/50, iter: 1700/3382, mean loss: 0.029556804461183254\n",
      "Epoch 45/50, iter: 1800/3382, mean loss: 0.026519222328340853\n",
      "Epoch 45/50, iter: 1900/3382, mean loss: 0.057541583409368754\n",
      "Epoch 45/50, iter: 2000/3382, mean loss: 0.01493027896200111\n",
      "Epoch 45/50, iter: 2100/3382, mean loss: 0.04075798906525375\n",
      "Epoch 45/50, iter: 2200/3382, mean loss: 0.013270378015863855\n",
      "Epoch 45/50, iter: 2300/3382, mean loss: 0.025354495201144793\n",
      "Epoch 45/50, iter: 2400/3382, mean loss: 0.008999014408774748\n",
      "Epoch 45/50, iter: 2500/3382, mean loss: 0.02747375368847699\n",
      "Epoch 45/50, iter: 2600/3382, mean loss: 0.07501969055614545\n",
      "Epoch 45/50, iter: 2700/3382, mean loss: 0.005478563376071613\n",
      "Epoch 45/50, iter: 2800/3382, mean loss: 0.019598663878922375\n",
      "Epoch 45/50, iter: 2900/3382, mean loss: 0.011271005637959916\n",
      "Epoch 45/50, iter: 3000/3382, mean loss: 0.010004922906202722\n",
      "Epoch 45/50, iter: 3100/3382, mean loss: 0.006473575806486913\n",
      "Epoch 45/50, iter: 3200/3382, mean loss: 0.0014999984424153112\n",
      "Epoch 45/50, iter: 3300/3382, mean loss: 0.011172379654842928\n",
      "Epoch 46/50, iter: 100/3382, mean loss: 0.010325955429159634\n",
      "Epoch 46/50, iter: 200/3382, mean loss: 0.01862328047171715\n",
      "Epoch 46/50, iter: 300/3382, mean loss: 0.0003974355118609907\n",
      "Epoch 46/50, iter: 400/3382, mean loss: 0.006660195815612191\n",
      "Epoch 46/50, iter: 500/3382, mean loss: 0.0014853354363163617\n",
      "Epoch 46/50, iter: 600/3382, mean loss: 0.0038428429869837542\n",
      "Epoch 46/50, iter: 700/3382, mean loss: 0.0002106302723056075\n",
      "Epoch 46/50, iter: 800/3382, mean loss: 0.00010433064869641128\n",
      "Epoch 46/50, iter: 900/3382, mean loss: 0.0014326685844824284\n",
      "Epoch 46/50, iter: 1000/3382, mean loss: 0.0030319907760161867\n",
      "Epoch 46/50, iter: 1100/3382, mean loss: 0.016182373249968515\n",
      "Epoch 46/50, iter: 1200/3382, mean loss: 0.03294549184518306\n",
      "Epoch 46/50, iter: 1300/3382, mean loss: 0.005432530428276188\n",
      "Epoch 46/50, iter: 1400/3382, mean loss: 0.017401041971675718\n",
      "Epoch 46/50, iter: 1500/3382, mean loss: 0.01252118431277175\n",
      "Epoch 46/50, iter: 1600/3382, mean loss: 0.009177134394455244\n",
      "Epoch 46/50, iter: 1700/3382, mean loss: 0.013068232862573338\n",
      "Epoch 46/50, iter: 1800/3382, mean loss: 0.021174303105040444\n",
      "Epoch 46/50, iter: 1900/3382, mean loss: 0.04678079783220994\n",
      "Epoch 46/50, iter: 2000/3382, mean loss: 0.022714426074734603\n",
      "Epoch 46/50, iter: 2100/3382, mean loss: 0.02084719175677929\n",
      "Epoch 46/50, iter: 2200/3382, mean loss: 0.01316770349577638\n",
      "Epoch 46/50, iter: 2300/3382, mean loss: 0.009737279868286456\n",
      "Epoch 46/50, iter: 2400/3382, mean loss: 0.015307826793050658\n",
      "Epoch 46/50, iter: 2500/3382, mean loss: 0.012925315017996972\n",
      "Epoch 46/50, iter: 2600/3382, mean loss: 0.06200356977983436\n",
      "Epoch 46/50, iter: 2700/3382, mean loss: 0.017949857642178664\n",
      "Epoch 46/50, iter: 2800/3382, mean loss: 0.0027730458660235866\n",
      "Epoch 46/50, iter: 2900/3382, mean loss: 0.005999533820462161\n",
      "Epoch 46/50, iter: 3000/3382, mean loss: 0.003365425375353759\n",
      "Epoch 46/50, iter: 3100/3382, mean loss: 0.01904632279873262\n",
      "Epoch 46/50, iter: 3200/3382, mean loss: 0.005930739143103842\n",
      "Epoch 46/50, iter: 3300/3382, mean loss: 0.005136606028449968\n",
      "Epoch 47/50, iter: 100/3382, mean loss: 0.0055932270888308724\n",
      "Epoch 47/50, iter: 200/3382, mean loss: 0.021720551238025684\n",
      "Epoch 47/50, iter: 300/3382, mean loss: 0.0002054445100686664\n",
      "Epoch 47/50, iter: 400/3382, mean loss: 0.00265055891766707\n",
      "Epoch 47/50, iter: 500/3382, mean loss: 0.005439796125727519\n",
      "Epoch 47/50, iter: 600/3382, mean loss: 0.0013463595135457496\n",
      "Epoch 47/50, iter: 700/3382, mean loss: 0.00034269879464975616\n",
      "Epoch 47/50, iter: 800/3382, mean loss: 5.8510722415370255e-05\n",
      "Epoch 47/50, iter: 900/3382, mean loss: 0.00028832236978519886\n",
      "Epoch 47/50, iter: 1000/3382, mean loss: 0.004057781369727387\n",
      "Epoch 47/50, iter: 1100/3382, mean loss: 0.013486738975263392\n",
      "Epoch 47/50, iter: 1200/3382, mean loss: 0.047769338526231914\n",
      "Epoch 47/50, iter: 1300/3382, mean loss: 0.05121779832785496\n",
      "Epoch 47/50, iter: 1400/3382, mean loss: 0.01619401932047808\n",
      "Epoch 47/50, iter: 1500/3382, mean loss: 0.008037987314685217\n",
      "Epoch 47/50, iter: 1600/3382, mean loss: 0.011822036986378244\n",
      "Epoch 47/50, iter: 1700/3382, mean loss: 0.00326073448451389\n",
      "Epoch 47/50, iter: 1800/3382, mean loss: 0.020555338021858844\n",
      "Epoch 47/50, iter: 1900/3382, mean loss: 0.05565271769457333\n",
      "Epoch 47/50, iter: 2000/3382, mean loss: 0.014021178611129557\n",
      "Epoch 47/50, iter: 2100/3382, mean loss: 0.024841149874469365\n",
      "Epoch 47/50, iter: 2200/3382, mean loss: 0.05568035984167295\n",
      "Epoch 47/50, iter: 2300/3382, mean loss: 0.0076517572930513466\n",
      "Epoch 47/50, iter: 2400/3382, mean loss: 0.003681288387564976\n",
      "Epoch 47/50, iter: 2500/3382, mean loss: 0.011284252285596423\n",
      "Epoch 47/50, iter: 2600/3382, mean loss: 0.08283637226804264\n",
      "Epoch 47/50, iter: 2700/3382, mean loss: 0.029027651553167395\n",
      "Epoch 47/50, iter: 2800/3382, mean loss: 0.044583866389995494\n",
      "Epoch 47/50, iter: 2900/3382, mean loss: 0.0034078524929131502\n",
      "Epoch 47/50, iter: 3000/3382, mean loss: 0.012355638264475069\n",
      "Epoch 47/50, iter: 3100/3382, mean loss: 0.021295912463238552\n",
      "Epoch 47/50, iter: 3200/3382, mean loss: 0.0047516845636185676\n",
      "Epoch 47/50, iter: 3300/3382, mean loss: 0.0102115726950057\n",
      "Epoch 48/50, iter: 100/3382, mean loss: 0.004140815628445899\n",
      "Epoch 48/50, iter: 200/3382, mean loss: 0.038246939688699196\n",
      "Epoch 48/50, iter: 300/3382, mean loss: 0.0006136926106332296\n",
      "Epoch 48/50, iter: 400/3382, mean loss: 7.816589750291314e-05\n",
      "Epoch 48/50, iter: 500/3382, mean loss: 0.0028284594855986713\n",
      "Epoch 48/50, iter: 600/3382, mean loss: 0.00665939707558497\n",
      "Epoch 48/50, iter: 700/3382, mean loss: 0.00038881583010883956\n",
      "Epoch 48/50, iter: 800/3382, mean loss: 0.0052366460444710225\n",
      "Epoch 48/50, iter: 900/3382, mean loss: 0.0007168595574104586\n",
      "Epoch 48/50, iter: 1000/3382, mean loss: 0.005724216293576809\n",
      "Epoch 48/50, iter: 1100/3382, mean loss: 0.0404669726403143\n",
      "Epoch 48/50, iter: 1200/3382, mean loss: 0.03525937060820741\n",
      "Epoch 48/50, iter: 1300/3382, mean loss: 0.028530638653941124\n",
      "Epoch 48/50, iter: 1400/3382, mean loss: 0.04960596552586896\n",
      "Epoch 48/50, iter: 1500/3382, mean loss: 0.006567375921197041\n",
      "Epoch 48/50, iter: 1600/3382, mean loss: 0.03200716622931218\n",
      "Epoch 48/50, iter: 1700/3382, mean loss: 0.02179472647571636\n",
      "Epoch 48/50, iter: 1800/3382, mean loss: 0.01022543478623394\n",
      "Epoch 48/50, iter: 1900/3382, mean loss: 0.08970447061834814\n",
      "Epoch 48/50, iter: 2000/3382, mean loss: 0.05254484762051405\n",
      "Epoch 48/50, iter: 2100/3382, mean loss: 0.022015311627970425\n",
      "Epoch 48/50, iter: 2200/3382, mean loss: 0.037902216823250574\n",
      "Epoch 48/50, iter: 2300/3382, mean loss: 0.006049738820769051\n",
      "Epoch 48/50, iter: 2400/3382, mean loss: 0.013511003817185632\n",
      "Epoch 48/50, iter: 2500/3382, mean loss: 0.0050983945461761234\n",
      "Epoch 48/50, iter: 2600/3382, mean loss: 0.1046555459239028\n",
      "Epoch 48/50, iter: 2700/3382, mean loss: 0.007933743998705545\n",
      "Epoch 48/50, iter: 2800/3382, mean loss: 0.010313074312349286\n",
      "Epoch 48/50, iter: 2900/3382, mean loss: 0.009663561649135595\n",
      "Epoch 48/50, iter: 3000/3382, mean loss: 0.010017171628322892\n",
      "Epoch 48/50, iter: 3100/3382, mean loss: 0.009946487083922158\n",
      "Epoch 48/50, iter: 3200/3382, mean loss: 0.0073872149290795976\n",
      "Epoch 48/50, iter: 3300/3382, mean loss: 0.006174914192118308\n",
      "Epoch 49/50, iter: 100/3382, mean loss: 0.010576572522993431\n",
      "Epoch 49/50, iter: 200/3382, mean loss: 0.024468468161240153\n",
      "Epoch 49/50, iter: 300/3382, mean loss: 0.0003854855207602625\n",
      "Epoch 49/50, iter: 400/3382, mean loss: 0.01980200836411214\n",
      "Epoch 49/50, iter: 500/3382, mean loss: 0.0006507281688610434\n",
      "Epoch 49/50, iter: 600/3382, mean loss: 0.0012203329534626662\n",
      "Epoch 49/50, iter: 700/3382, mean loss: 0.006993609970282258\n",
      "Epoch 49/50, iter: 800/3382, mean loss: 0.00027543388376550127\n",
      "Epoch 49/50, iter: 900/3382, mean loss: 0.0003477469025809654\n",
      "Epoch 49/50, iter: 1000/3382, mean loss: 0.0023437549187910276\n",
      "Epoch 49/50, iter: 1100/3382, mean loss: 0.030648287385214346\n",
      "Epoch 49/50, iter: 1200/3382, mean loss: 0.028377210507173237\n",
      "Epoch 49/50, iter: 1300/3382, mean loss: 0.021223641488540893\n",
      "Epoch 49/50, iter: 1400/3382, mean loss: 0.015286456140584192\n",
      "Epoch 49/50, iter: 1500/3382, mean loss: 0.004988053230716396\n",
      "Epoch 49/50, iter: 1600/3382, mean loss: 0.010757780545986187\n",
      "Epoch 49/50, iter: 1700/3382, mean loss: 0.02255211935164265\n",
      "Epoch 49/50, iter: 1800/3382, mean loss: 0.04865911511314785\n",
      "Epoch 49/50, iter: 1900/3382, mean loss: 0.04622703442216739\n",
      "Epoch 49/50, iter: 2000/3382, mean loss: 0.004482514518672005\n",
      "Epoch 49/50, iter: 2100/3382, mean loss: 0.04670442862679376\n",
      "Epoch 49/50, iter: 2200/3382, mean loss: 0.049021773117193704\n",
      "Epoch 49/50, iter: 2300/3382, mean loss: 0.015824998954720507\n",
      "Epoch 49/50, iter: 2400/3382, mean loss: 0.010543398070882474\n",
      "Epoch 49/50, iter: 2500/3382, mean loss: 0.0030169812772342297\n",
      "Epoch 49/50, iter: 2600/3382, mean loss: 0.08105889394787781\n",
      "Epoch 49/50, iter: 2700/3382, mean loss: 0.008447064653042027\n",
      "Epoch 49/50, iter: 2800/3382, mean loss: 0.017374799403332624\n",
      "Epoch 49/50, iter: 2900/3382, mean loss: 0.0039253913220605695\n",
      "Epoch 49/50, iter: 3000/3382, mean loss: 0.006464143620950508\n",
      "Epoch 49/50, iter: 3100/3382, mean loss: 0.02398850353766047\n",
      "Epoch 49/50, iter: 3200/3382, mean loss: 0.0441982840097965\n",
      "Epoch 49/50, iter: 3300/3382, mean loss: 0.003263093708310585\n",
      "Epoch 50/50, iter: 100/3382, mean loss: 0.009974384780356544\n",
      "Epoch 50/50, iter: 200/3382, mean loss: 0.03293370431522941\n",
      "Epoch 50/50, iter: 300/3382, mean loss: 0.016538902604449356\n",
      "Epoch 50/50, iter: 400/3382, mean loss: 0.00019775150968406763\n",
      "Epoch 50/50, iter: 500/3382, mean loss: 0.003978626911101521\n",
      "Epoch 50/50, iter: 600/3382, mean loss: 0.00019468168493691707\n",
      "Epoch 50/50, iter: 700/3382, mean loss: 0.0001012924201274501\n",
      "Epoch 50/50, iter: 800/3382, mean loss: 0.00037282053370059744\n",
      "Epoch 50/50, iter: 900/3382, mean loss: 0.0005197942437741076\n",
      "Epoch 50/50, iter: 1000/3382, mean loss: 0.008103162986797833\n",
      "Epoch 50/50, iter: 1100/3382, mean loss: 0.03293336986489269\n",
      "Epoch 50/50, iter: 1200/3382, mean loss: 0.046288752878065116\n",
      "Epoch 50/50, iter: 1300/3382, mean loss: 0.014858916870224234\n",
      "Epoch 50/50, iter: 1400/3382, mean loss: 0.030218492762054225\n",
      "Epoch 50/50, iter: 1500/3382, mean loss: 0.04069067598529031\n",
      "Epoch 50/50, iter: 1600/3382, mean loss: 0.015953045395172047\n",
      "Epoch 50/50, iter: 1700/3382, mean loss: 0.003073784340107437\n",
      "Epoch 50/50, iter: 1800/3382, mean loss: 0.012749817246754346\n",
      "Epoch 50/50, iter: 1900/3382, mean loss: 0.05513945917804285\n",
      "Epoch 50/50, iter: 2000/3382, mean loss: 0.005167163450218837\n",
      "Epoch 50/50, iter: 2100/3382, mean loss: 0.01168236101741222\n",
      "Epoch 50/50, iter: 2200/3382, mean loss: 0.012330645580408514\n",
      "Epoch 50/50, iter: 2300/3382, mean loss: 0.01899434725143813\n",
      "Epoch 50/50, iter: 2400/3382, mean loss: 0.05674797562451758\n",
      "Epoch 50/50, iter: 2500/3382, mean loss: 0.011861082034199945\n",
      "Epoch 50/50, iter: 2600/3382, mean loss: 0.08194688901429031\n",
      "Epoch 50/50, iter: 2700/3382, mean loss: 0.009076744645377985\n",
      "Epoch 50/50, iter: 2800/3382, mean loss: 0.010812094662912735\n",
      "Epoch 50/50, iter: 2900/3382, mean loss: 0.004033198838562732\n",
      "Epoch 50/50, iter: 3000/3382, mean loss: 0.013159525733505682\n",
      "Epoch 50/50, iter: 3100/3382, mean loss: 0.004692295216214646\n",
      "Epoch 50/50, iter: 3200/3382, mean loss: 0.003127876916518382\n",
      "Epoch 50/50, iter: 3300/3382, mean loss: 0.007155872174439537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "use_wandb = True\n",
    "\n",
    "lr = 0.0005\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "epochs_cnt = 50\n",
    "embeddings = \"random\"\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "task = \"text2sentiment\" # text2company\n",
    "use_company_info = True\n",
    "\n",
    "get_dataloaders = get_twit_company_dataloaders if task == \"text2company\" else\\\n",
    "get_twit_sentiment_dataloaders if not use_company_info else get_twit_company_sentiment_dataloaders\n",
    "\n",
    "dataset_train, dataloader_train, dataset_test, dataloader_test = get_twit_company_dataloaders(embedding_dim=embedding_size, embedding=embeddings)\n",
    "\n",
    "model = LSTMTwitClassifier(4, embedding_dim=embedding_size, hidden_dim=hidden_size, dropout=dropout, lstm_layers=lstm_layers)\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project=task + '_twit_classification', entity='ars860')\n",
    "\n",
    "    config = wandb.config\n",
    "    config.loss = \"BCE\"\n",
    "    config.optimizer = \"Adam\"\n",
    "    config.learning_rate = lr\n",
    "    config.hidden_size = hidden_size\n",
    "    config.embedding_size = embedding_size\n",
    "    config.embeddings = embeddings\n",
    "    config.epochs = epochs_cnt\n",
    "    config.dropout = dropout\n",
    "    config.lstm_layers = lstm_layers\n",
    "    config.stem = \"snowballstemmer\"\n",
    "\n",
    "    if task == \"text2sentiment\":\n",
    "        config.use_company_info = use_company_info\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def loss_on_test():\n",
    "    correct = 0\n",
    "    losses = np.zeros(len(dataloader_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (*args, target) in enumerate(dataloader_test):\n",
    "            prediction = model(*args)\n",
    "            prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "            losses[i] = F.binary_cross_entropy(prediction, target.view(-1))\n",
    "            if torch.argmax(prediction) == torch.argmax(target):\n",
    "                correct += 1\n",
    "\n",
    "            # predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "    model.train()\n",
    "    if use_wandb:\n",
    "        wandb.log({\"test_loss\": np.mean(losses), \"test_accuracy\": correct / len(dataloader_test)})\n",
    "\n",
    "losses = np.empty(100)\n",
    "model.train()\n",
    "for epoch in range(epochs_cnt):\n",
    "    epoch_loss = np.zeros(len(dataloader_train))\n",
    "\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        model.zero_grad()\n",
    "\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        loss = criterion(prediction, target.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        losses[i % 100] = loss\n",
    "        epoch_loss[i] = loss\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs_cnt}, iter: {i + 1}/{len(dataloader_train)}, mean loss: {np.mean(losses)}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"loss\": np.mean(losses)})\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "        loss_on_test()\n",
    "\n",
    "# [model.get_word_embedding(word) for word in \"hello_world\".split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on train\n",
      "Iter: 0/3382\n",
      "Iter: 100/3382\n",
      "Iter: 200/3382\n",
      "Iter: 300/3382\n",
      "Iter: 400/3382\n",
      "Iter: 500/3382\n",
      "Iter: 600/3382\n",
      "Iter: 700/3382\n",
      "Iter: 800/3382\n",
      "Iter: 900/3382\n",
      "Iter: 1000/3382\n",
      "Iter: 1100/3382\n",
      "Iter: 1200/3382\n",
      "Iter: 1300/3382\n",
      "Iter: 1400/3382\n",
      "Iter: 1500/3382\n",
      "Iter: 1600/3382\n",
      "Iter: 1700/3382\n",
      "Iter: 1800/3382\n",
      "Iter: 1900/3382\n",
      "Iter: 2000/3382\n",
      "Iter: 2100/3382\n",
      "Iter: 2200/3382\n",
      "Iter: 2300/3382\n",
      "Iter: 2400/3382\n",
      "Iter: 2500/3382\n",
      "Iter: 2600/3382\n",
      "Iter: 2700/3382\n",
      "Iter: 2800/3382\n",
      "Iter: 2900/3382\n",
      "Iter: 3000/3382\n",
      "Iter: 3100/3382\n",
      "Iter: 3200/3382\n",
      "Iter: 3300/3382\n",
      "Accuracy 0.9943820224719101\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 5408<br/>Program ended successfully."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "068ef0df98184c3dbdda6f029a3e4c46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_213327-3dq0a2rt\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_213327-3dq0a2rt\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>0.00716</td></tr><tr><td>_runtime</td><td>1598</td></tr><tr><td>_timestamp</td><td>1633892405</td></tr><tr><td>_step</td><td>1749</td></tr><tr><td>epoch_loss</td><td>0.01722</td></tr><tr><td>test_loss</td><td>0.54065</td></tr><tr><td>test_accuracy</td><td>0.80473</td></tr><tr><td>train_accuracy</td><td>0.99438</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>▁▁▁▁▅█▁▁▁▂▁▁▁▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▇██▇▇▇▇█▇▇▆▆▄▅▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>██▇█▇▇▆▅▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▂▂▃▄▅▆▇▇▇█████████████████▇██████</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">electric-smoke-2</strong>: <a href=\"https://wandb.ai/ars860/text2sentiment_twit_classification/runs/3dq0a2rt\" target=\"_blank\">https://wandb.ai/ars860/text2sentiment_twit_classification/runs/3dq0a2rt</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Testing on train\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_train)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_train)}\")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.run.summary.train_accuracy = correct / len(dataloader_train)\n",
    "    wandb.run.summary.classified_as = {\n",
    "        \"apple\": predictions_cnt[0],\n",
    "        \"google\": predictions_cnt[1],\n",
    "        \"microsoft\": predictions_cnt[2],\n",
    "        \"twitter\": predictions_cnt[3]\n",
    "    }\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test\n",
      "Iter: 0/338\n",
      "Iter: 100/338\n",
      "Iter: 200/338\n",
      "Iter: 300/338\n",
      "Accuracy 0.8047337278106509\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_test):\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}