{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset import get_twit_company_dataloaders, split_sentence\n",
    "from model import LSTMTwitClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# text, label = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://t.co/48emAEID \n",
      "http://t.co/Izh7KaiU \n",
      "http://t.co/e5ClGzsI \n",
      "http://t.co/18xg3ivo! \n",
      "Поиск от \n",
      "サムスン電子のスマートフォン新機種「ギャラクシー・ネクサス」、グーグルの基本ソフト（ＯＳ）「アンドロイド」最新版を搭載。「クラウド」活用、音声認識やカメラの機能も向上させた戦略モデル \n",
      "Новите \n",
      "اعرف الكثير عن نظام ايسكريم ساندويتش http://t.co/Fzjd2Zx1 \n",
      "看見 \n",
      "نظام جديد .. و جهاز جديد شكراً جزيلاً \n",
      "ايسكريم ساندويش، عسل، زنجبيل .. مشكلة من كثر المسميات احسهم مسوين مقادير مب انظمة !! 😝  \n",
      "الجهاز الجديد عجيب   \n",
      "Я немного потрясен :) \n",
      "今日発表だった＾ﾛ＾　 \n",
      "يبدو ان طفرة الاجهزة الالكترونية القادمة ستكون بقيادة موتورولا ،، لاسيم بعد استحواذ قوقل عليها.   \n",
      "顔認識ロック解除失敗してる・・・デモで失敗しちゃっていいのか？ \n",
      "Με συγχισες \n",
      "デフォでデータ通信制御？　\n",
      "http://t.co/gAPEyL5N \n",
      "http://t.co/J3p3KYHf \n",
      "http://t.co/h1IH7FN6 مايكروسوفت تقوم بتطوير تقنية تمكنك من استخدام يدك كهاتف  \n",
      "http://t.co/ONI0JX8B \n",
      "http://t.co/JVidt6U4 \n",
      "На сайте \n",
      "☼ \n",
      "Настоящий твиттерянин как только попадает в толпу стремиться тут же как можно быстрее попасть в \n",
      "Доброе утро \n",
      "【\n",
      "なにやらフォロー制限に引っ掛かったようです…もっとフォロアーを増やさなくちゃ♪　\n",
      "ツイッターを利用して感謝の気持ちとともに約２０００円が振り込まれ続ける方法→ｺｺ→ http://t.co/TyjUGsnQ ←ｺｺ← :) \n",
      "رقم الفلو والفلورز والتويتات  للبيع لاعلى سعر \n",
      "قال الرئيس التنفيذي لشركة \n",
      "Улучшим продукты компании \n",
      "نفسي يوم يعدي علي تويتر من غير مشاكل فنية \n",
      "ツイッター検索 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-d394c1dc3791>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m         \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtxt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprediction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\acady\\learning\\sma\\twit_classifier\\model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;31m# embedded = self._get_sentence_embedding(sentence)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\acady\\learning\\sma\\twit_classifier\\model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;31m# embedded = self._get_sentence_embedding(sentence)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\212.5284.44\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\212.5284.44\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "use_wandb = False\n",
    "\n",
    "lr = 0.0005\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "epochs_cnt = 50\n",
    "embeddings = \"word2vec\"\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "\n",
    "dataset_train, dataloader_train, dataset_test, dataloader_test = get_twit_company_dataloaders(embedding_dim=embedding_size, embedding=embeddings)\n",
    "\n",
    "model = LSTMTwitClassifier(4, embedding_dim=embedding_size, hidden_dim=hidden_size, dropout=dropout, lstm_layers=lstm_layers)\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project='twit_classification', entity='ars860')\n",
    "\n",
    "    config = wandb.config\n",
    "    config.loss = \"BCE\"\n",
    "    config.optimizer = \"Adam\"\n",
    "    config.learning_rate = lr\n",
    "    config.hidden_size = hidden_size\n",
    "    config.embedding_size = embedding_size\n",
    "    config.embeddings = embeddings\n",
    "    config.epochs = epochs_cnt\n",
    "    config.dropout = dropout\n",
    "    config.lstm_layers = lstm_layers\n",
    "    config.stem = \"snowballstemmer\"\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def loss_on_test():\n",
    "    correct = 0\n",
    "    losses = np.zeros(len(dataloader_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (txt, company) in enumerate(dataloader_test):\n",
    "            prediction = model(txt)\n",
    "            prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "            losses[i] = F.binary_cross_entropy(prediction, company.view(-1))\n",
    "            if torch.argmax(prediction) == torch.argmax(company):\n",
    "                correct += 1\n",
    "\n",
    "            # predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "    model.train()\n",
    "    if use_wandb:\n",
    "        wandb.log({\"test_loss\": np.mean(losses), \"test_accuracy\": correct / len(dataloader_test)})\n",
    "\n",
    "losses = np.empty(100)\n",
    "model.train()\n",
    "for epoch in range(epochs_cnt):\n",
    "    epoch_loss = np.zeros(len(dataloader_train))\n",
    "\n",
    "    for i, (txt, company) in enumerate(dataloader_train):\n",
    "        model.zero_grad()\n",
    "\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        loss = criterion(prediction, company.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        losses[i % 100] = loss\n",
    "        epoch_loss[i] = loss\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs_cnt}, iter: {i + 1}/{len(dataloader_train)}, mean loss: {np.mean(losses)}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"loss\": np.mean(losses)})\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "        loss_on_test()\n",
    "\n",
    "# [model.get_word_embedding(word) for word in \"hello_world\".split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on train\n",
      "Iter: 0/3382\n",
      "Iter: 100/3382\n",
      "Iter: 200/3382\n",
      "Iter: 300/3382\n",
      "Iter: 400/3382\n",
      "Iter: 500/3382\n",
      "Iter: 600/3382\n",
      "Iter: 700/3382\n",
      "Iter: 800/3382\n",
      "Iter: 900/3382\n",
      "Iter: 1000/3382\n",
      "Iter: 1100/3382\n",
      "Iter: 1200/3382\n",
      "Iter: 1300/3382\n",
      "Iter: 1400/3382\n",
      "Iter: 1500/3382\n",
      "Iter: 1600/3382\n",
      "Iter: 1700/3382\n",
      "Iter: 1800/3382\n",
      "Iter: 1900/3382\n",
      "Iter: 2000/3382\n",
      "Iter: 2100/3382\n",
      "Iter: 2200/3382\n",
      "Iter: 2300/3382\n",
      "Iter: 2400/3382\n",
      "Iter: 2500/3382\n",
      "Iter: 2600/3382\n",
      "Iter: 2700/3382\n",
      "Iter: 2800/3382\n",
      "Iter: 2900/3382\n",
      "Iter: 3000/3382\n",
      "Iter: 3100/3382\n",
      "Iter: 3200/3382\n",
      "Iter: 3300/3382\n",
      "Accuracy 0.9911295091661738\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 13152<br/>Program ended successfully."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2062f60bff854a4fba741f277f171156"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_002819-19ohh73m\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_002819-19ohh73m\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>0.00455</td></tr><tr><td>_runtime</td><td>1582</td></tr><tr><td>_timestamp</td><td>1633816481</td></tr><tr><td>_step</td><td>1749</td></tr><tr><td>epoch_loss</td><td>0.01621</td></tr><tr><td>test_loss</td><td>0.40269</td></tr><tr><td>test_accuracy</td><td>0.81065</td></tr><tr><td>train_accuracy</td><td>0.99113</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>▁▁▁▁▅█▁▁▁▂▁▂▁▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▇█▇▇█▇▇▇▆▇▅▅▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>████▆▆▆▄▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▃▅▅▆▆▇▇▇▇▇▇▇▇███████▇▇█▇▇█▇█████</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">devout-dream-31</strong>: <a href=\"https://wandb.ai/ars860/twit_classification/runs/19ohh73m\" target=\"_blank\">https://wandb.ai/ars860/twit_classification/runs/19ohh73m</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Testing on train\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (txt, company) in enumerate(dataloader_train):\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(company):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_train)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_train)}\")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.run.summary.train_accuracy = correct / len(dataloader_train)\n",
    "    wandb.run.summary.classified_as = {\n",
    "        \"apple\": predictions_cnt[0],\n",
    "        \"google\": predictions_cnt[1],\n",
    "        \"microsoft\": predictions_cnt[2],\n",
    "        \"twitter\": predictions_cnt[3]\n",
    "    }\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test\n",
      "Iter: 0/338\n",
      "Iter: 100/338\n",
      "Iter: 200/338\n",
      "Iter: 300/338\n",
      "Accuracy 0.8106508875739645\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (txt, company) in enumerate(dataloader_test):\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(company):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}