{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset import get_twit_company_dataloaders, get_twit_sentiment_dataloaders, get_twit_company_sentiment_dataloaders\n",
    "from model import LSTMTwitClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# text, label = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ignored due to unreadability: http://t.co/48emAEID \n",
      "Tweet ignored due to unreadability: http://t.co/Izh7KaiU \n",
      "Tweet ignored due to unreadability: http://t.co/e5ClGzsI \n",
      "Tweet ignored due to unreadability: http://t.co/18xg3ivo! \n",
      "Tweet ignored due to unreadability: Поиск от \n",
      "Tweet ignored due to unreadability: サムスン電子のスマートフォン新機種「ギャラクシー・ネクサス」、グーグルの基本ソフト（ＯＳ）「アンドロイド」最新版を搭載。「クラウド」活用、音声認識やカメラの機能も向上させた戦略モデル \n",
      "Tweet ignored due to unreadability: Новите \n",
      "Tweet ignored due to unreadability: اعرف الكثير عن نظام ايسكريم ساندويتش http://t.co/Fzjd2Zx1 \n",
      "Tweet ignored due to unreadability: 看見 \n",
      "Tweet ignored due to unreadability: نظام جديد .. و جهاز جديد شكراً جزيلاً \n",
      "Tweet ignored due to unreadability: ايسكريم ساندويش، عسل، زنجبيل .. مشكلة من كثر المسميات احسهم مسوين مقادير مب انظمة !! 😝  \n",
      "Tweet ignored due to unreadability: الجهاز الجديد عجيب   \n",
      "Tweet ignored due to unreadability: Я немного потрясен :) \n",
      "Tweet ignored due to unreadability: 今日発表だった＾ﾛ＾　 \n",
      "Tweet ignored due to unreadability: يبدو ان طفرة الاجهزة الالكترونية القادمة ستكون بقيادة موتورولا ،، لاسيم بعد استحواذ قوقل عليها.   \n",
      "Tweet ignored due to unreadability: 顔認識ロック解除失敗してる・・・デモで失敗しちゃっていいのか？ \n",
      "Tweet ignored due to unreadability: Με συγχισες \n",
      "Tweet ignored due to unreadability: デフォでデータ通信制御？　\n",
      "Tweet ignored due to unreadability: http://t.co/gAPEyL5N \n",
      "Tweet ignored due to unreadability: http://t.co/J3p3KYHf \n",
      "Tweet ignored due to unreadability: http://t.co/h1IH7FN6 مايكروسوفت تقوم بتطوير تقنية تمكنك من استخدام يدك كهاتف  \n",
      "Tweet ignored due to unreadability: http://t.co/ONI0JX8B \n",
      "Tweet ignored due to unreadability: http://t.co/JVidt6U4 \n",
      "Tweet ignored due to unreadability: На сайте \n",
      "Tweet ignored due to unreadability: ☼ \n",
      "Tweet ignored due to unreadability: Настоящий твиттерянин как только попадает в толпу стремиться тут же как можно быстрее попасть в \n",
      "Tweet ignored due to unreadability: Доброе утро \n",
      "Tweet ignored due to unreadability: 【\n",
      "Tweet ignored due to unreadability: なにやらフォロー制限に引っ掛かったようです…もっとフォロアーを増やさなくちゃ♪　\n",
      "Tweet ignored due to unreadability: ツイッターを利用して感謝の気持ちとともに約２０００円が振り込まれ続ける方法→ｺｺ→ http://t.co/TyjUGsnQ ←ｺｺ← :) \n",
      "Tweet ignored due to unreadability: رقم الفلو والفلورز والتويتات  للبيع لاعلى سعر \n",
      "Tweet ignored due to unreadability: قال الرئيس التنفيذي لشركة \n",
      "Tweet ignored due to unreadability: Улучшим продукты компании \n",
      "Tweet ignored due to unreadability: نفسي يوم يعدي علي تويتر من غير مشاكل فنية \n",
      "Tweet ignored due to unreadability: ツイッター検索 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "wandb: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">easy-hill-34</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/ars860/text2company_twit_classification\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification</a><br/>\n                Run page: <a href=\"https://wandb.ai/ars860/text2company_twit_classification/runs/2o2x3xk4\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification/runs/2o2x3xk4</a><br/>\n                Run data is saved locally in <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211020_160846-2o2x3xk4</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, iter: 100/3382, mean loss: 0.40328207742422817\n",
      "Epoch 1/50, iter: 200/3382, mean loss: 0.02301423473196337\n",
      "Epoch 1/50, iter: 300/3382, mean loss: 0.010356963625745265\n",
      "Epoch 1/50, iter: 400/3382, mean loss: 0.007011925775295822\n",
      "Epoch 1/50, iter: 500/3382, mean loss: 0.019734412022371542\n",
      "Epoch 1/50, iter: 600/3382, mean loss: 0.003019193868772163\n",
      "Epoch 1/50, iter: 700/3382, mean loss: 0.0036084522963369635\n",
      "Epoch 1/50, iter: 800/3382, mean loss: 0.0013299169642868947\n",
      "Epoch 1/50, iter: 900/3382, mean loss: 0.0018665826538563123\n",
      "Epoch 1/50, iter: 1000/3382, mean loss: 0.5299105244494581\n",
      "Epoch 1/50, iter: 1100/3382, mean loss: 0.3103803308587521\n",
      "Epoch 1/50, iter: 1200/3382, mean loss: 0.07790507380734198\n",
      "Epoch 1/50, iter: 1300/3382, mean loss: 0.031593161730233986\n",
      "Epoch 1/50, iter: 1400/3382, mean loss: 0.03502980155870319\n",
      "Epoch 1/50, iter: 1500/3382, mean loss: 0.02183175711219519\n",
      "Epoch 1/50, iter: 1600/3382, mean loss: 0.03820241368048301\n",
      "Epoch 1/50, iter: 1700/3382, mean loss: 0.011973951025320275\n",
      "Epoch 1/50, iter: 1800/3382, mean loss: 1.0130007307707183\n",
      "Epoch 1/50, iter: 1900/3382, mean loss: 0.17423951362026854\n",
      "Epoch 1/50, iter: 2000/3382, mean loss: 0.0653446041297866\n",
      "Epoch 1/50, iter: 2100/3382, mean loss: 0.04012131582443544\n",
      "Epoch 1/50, iter: 2200/3382, mean loss: 0.04881480275627837\n",
      "Epoch 1/50, iter: 2300/3382, mean loss: 0.027861863379803252\n",
      "Epoch 1/50, iter: 2400/3382, mean loss: 0.02480186863966992\n",
      "Epoch 1/50, iter: 2500/3382, mean loss: 0.037578658625407116\n",
      "Epoch 1/50, iter: 2600/3382, mean loss: 1.0396775069095292\n",
      "Epoch 1/50, iter: 2700/3382, mean loss: 0.1678132939315401\n",
      "Epoch 1/50, iter: 2800/3382, mean loss: 0.07089453362103086\n",
      "Epoch 1/50, iter: 2900/3382, mean loss: 0.052228351919548006\n",
      "Epoch 1/50, iter: 3000/3382, mean loss: 0.05128532067576089\n",
      "Epoch 1/50, iter: 3100/3382, mean loss: 0.0318599545023335\n",
      "Epoch 1/50, iter: 3200/3382, mean loss: 0.023651833973599424\n",
      "Epoch 1/50, iter: 3300/3382, mean loss: 0.022906299822111578\n",
      "Epoch 2/50, iter: 100/3382, mean loss: 1.0440191499795766\n",
      "Epoch 2/50, iter: 200/3382, mean loss: 0.04736050891398918\n",
      "Epoch 2/50, iter: 300/3382, mean loss: 0.023145222610910423\n",
      "Epoch 2/50, iter: 400/3382, mean loss: 0.01745875780718052\n",
      "Epoch 2/50, iter: 500/3382, mean loss: 0.03245507897685457\n",
      "Epoch 2/50, iter: 600/3382, mean loss: 0.008383862369773851\n",
      "Epoch 2/50, iter: 700/3382, mean loss: 0.005205062164855008\n",
      "Epoch 2/50, iter: 800/3382, mean loss: 0.003185379602491594\n",
      "Epoch 2/50, iter: 900/3382, mean loss: 0.002392781033249776\n",
      "Epoch 2/50, iter: 1000/3382, mean loss: 0.47818450338397267\n",
      "Epoch 2/50, iter: 1100/3382, mean loss: 0.4055070304684341\n",
      "Epoch 2/50, iter: 1200/3382, mean loss: 0.08936020929599181\n",
      "Epoch 2/50, iter: 1300/3382, mean loss: 0.052436136021897256\n",
      "Epoch 2/50, iter: 1400/3382, mean loss: 0.04662172933698457\n",
      "Epoch 2/50, iter: 1500/3382, mean loss: 0.027077708301949315\n",
      "Epoch 2/50, iter: 1600/3382, mean loss: 0.04185766893151595\n",
      "Epoch 2/50, iter: 1700/3382, mean loss: 0.016680975182571275\n",
      "Epoch 2/50, iter: 1800/3382, mean loss: 0.8585565746329212\n",
      "Epoch 2/50, iter: 1900/3382, mean loss: 0.25851187120308167\n",
      "Epoch 2/50, iter: 2000/3382, mean loss: 0.11687015906805755\n",
      "Epoch 2/50, iter: 2100/3382, mean loss: 0.06695544878217334\n",
      "Epoch 2/50, iter: 2200/3382, mean loss: 0.05819788285443792\n",
      "Epoch 2/50, iter: 2300/3382, mean loss: 0.03308905872021569\n",
      "Epoch 2/50, iter: 2400/3382, mean loss: 0.020719556235671916\n",
      "Epoch 2/50, iter: 2500/3382, mean loss: 0.026443660101826937\n",
      "Epoch 2/50, iter: 2600/3382, mean loss: 0.9988472463109792\n",
      "Epoch 2/50, iter: 2700/3382, mean loss: 0.15561892756959422\n",
      "Epoch 2/50, iter: 2800/3382, mean loss: 0.061707679876126346\n",
      "Epoch 2/50, iter: 2900/3382, mean loss: 0.04211735478762421\n",
      "Epoch 2/50, iter: 3000/3382, mean loss: 0.04310583666723687\n",
      "Epoch 2/50, iter: 3100/3382, mean loss: 0.027859108146512882\n",
      "Epoch 2/50, iter: 3200/3382, mean loss: 0.02349927812918395\n",
      "Epoch 2/50, iter: 3300/3382, mean loss: 0.016207101323789174\n",
      "Epoch 3/50, iter: 100/3382, mean loss: 0.9186289391620085\n",
      "Epoch 3/50, iter: 200/3382, mean loss: 0.04585852581629297\n",
      "Epoch 3/50, iter: 300/3382, mean loss: 0.02371907632517832\n",
      "Epoch 3/50, iter: 400/3382, mean loss: 0.016485309137351578\n",
      "Epoch 3/50, iter: 500/3382, mean loss: 0.024506389942907846\n",
      "Epoch 3/50, iter: 600/3382, mean loss: 0.0080342162490615\n",
      "Epoch 3/50, iter: 700/3382, mean loss: 0.006142061129176\n",
      "Epoch 3/50, iter: 800/3382, mean loss: 0.00592855026478901\n",
      "Epoch 3/50, iter: 900/3382, mean loss: 0.0029538035373752793\n",
      "Epoch 3/50, iter: 1000/3382, mean loss: 0.4683878260629172\n",
      "Epoch 3/50, iter: 1100/3382, mean loss: 0.523264542967081\n",
      "Epoch 3/50, iter: 1200/3382, mean loss: 0.15505529022193515\n",
      "Epoch 3/50, iter: 1300/3382, mean loss: 0.0706379671517061\n",
      "Epoch 3/50, iter: 1400/3382, mean loss: 0.043528502993140136\n",
      "Epoch 3/50, iter: 1500/3382, mean loss: 0.028275728921980773\n",
      "Epoch 3/50, iter: 1600/3382, mean loss: 0.04460779382949113\n",
      "Epoch 3/50, iter: 1700/3382, mean loss: 0.01919540516813868\n",
      "Epoch 3/50, iter: 1800/3382, mean loss: 0.7910036720611879\n",
      "Epoch 3/50, iter: 1900/3382, mean loss: 0.36469638663344084\n",
      "Epoch 3/50, iter: 2000/3382, mean loss: 0.10150968261470553\n",
      "Epoch 3/50, iter: 2100/3382, mean loss: 0.047617786852933934\n",
      "Epoch 3/50, iter: 2200/3382, mean loss: 0.05287242766786221\n",
      "Epoch 3/50, iter: 2300/3382, mean loss: 0.027431659669582588\n",
      "Epoch 3/50, iter: 2400/3382, mean loss: 0.019273629819699635\n",
      "Epoch 3/50, iter: 2500/3382, mean loss: 0.020947030730985715\n",
      "Epoch 3/50, iter: 2600/3382, mean loss: 0.9694018833841256\n",
      "Epoch 3/50, iter: 2700/3382, mean loss: 0.17314642794663088\n",
      "Epoch 3/50, iter: 2800/3382, mean loss: 0.04883706824941328\n",
      "Epoch 3/50, iter: 2900/3382, mean loss: 0.03676626496089739\n",
      "Epoch 3/50, iter: 3000/3382, mean loss: 0.03729946468614798\n",
      "Epoch 3/50, iter: 3100/3382, mean loss: 0.022022251063390286\n",
      "Epoch 3/50, iter: 3200/3382, mean loss: 0.01727120457793717\n",
      "Epoch 3/50, iter: 3300/3382, mean loss: 0.017124562021099337\n",
      "Epoch 4/50, iter: 100/3382, mean loss: 0.6891947981185512\n",
      "Epoch 4/50, iter: 200/3382, mean loss: 0.031613060019626577\n",
      "Epoch 4/50, iter: 300/3382, mean loss: 0.0216450078663911\n",
      "Epoch 4/50, iter: 400/3382, mean loss: 0.009623496620224613\n",
      "Epoch 4/50, iter: 500/3382, mean loss: 0.025283699174469803\n",
      "Epoch 4/50, iter: 600/3382, mean loss: 0.015111955048887467\n",
      "Epoch 4/50, iter: 700/3382, mean loss: 0.00778461743155276\n",
      "Epoch 4/50, iter: 800/3382, mean loss: 0.003396599748502922\n",
      "Epoch 4/50, iter: 900/3382, mean loss: 0.007019040356935875\n",
      "Epoch 4/50, iter: 1000/3382, mean loss: 0.40054301851946095\n",
      "Epoch 4/50, iter: 1100/3382, mean loss: 0.36408070132136344\n",
      "Epoch 4/50, iter: 1200/3382, mean loss: 0.09937553522089729\n",
      "Epoch 4/50, iter: 1300/3382, mean loss: 0.052955675473131125\n",
      "Epoch 4/50, iter: 1400/3382, mean loss: 0.026959158293566363\n",
      "Epoch 4/50, iter: 1500/3382, mean loss: 0.018014546913982486\n",
      "Epoch 4/50, iter: 1600/3382, mean loss: 0.03746824270241632\n",
      "Epoch 4/50, iter: 1700/3382, mean loss: 0.014168367628599299\n",
      "Epoch 4/50, iter: 1800/3382, mean loss: 0.7285696419132364\n",
      "Epoch 4/50, iter: 1900/3382, mean loss: 0.32575119892600923\n",
      "Epoch 4/50, iter: 2000/3382, mean loss: 0.07595641084946692\n",
      "Epoch 4/50, iter: 2100/3382, mean loss: 0.0502330219047144\n",
      "Epoch 4/50, iter: 2200/3382, mean loss: 0.047180986878411206\n",
      "Epoch 4/50, iter: 2300/3382, mean loss: 0.028171707019637324\n",
      "Epoch 4/50, iter: 2400/3382, mean loss: 0.014460778044804102\n",
      "Epoch 4/50, iter: 2500/3382, mean loss: 0.02205669699070768\n",
      "Epoch 4/50, iter: 2600/3382, mean loss: 0.9574064157008615\n",
      "Epoch 4/50, iter: 2700/3382, mean loss: 0.1718638847512193\n",
      "Epoch 4/50, iter: 2800/3382, mean loss: 0.05327970892685698\n",
      "Epoch 4/50, iter: 2900/3382, mean loss: 0.032021763372322314\n",
      "Epoch 4/50, iter: 3000/3382, mean loss: 0.04147858183947392\n",
      "Epoch 4/50, iter: 3100/3382, mean loss: 0.02145321345529737\n",
      "Epoch 4/50, iter: 3200/3382, mean loss: 0.015607388602129504\n",
      "Epoch 4/50, iter: 3300/3382, mean loss: 0.011049944982569287\n",
      "Epoch 5/50, iter: 100/3382, mean loss: 0.6534156001638621\n",
      "Epoch 5/50, iter: 200/3382, mean loss: 0.023070522394991713\n",
      "Epoch 5/50, iter: 300/3382, mean loss: 0.01696031860426956\n",
      "Epoch 5/50, iter: 400/3382, mean loss: 0.007472454725357239\n",
      "Epoch 5/50, iter: 500/3382, mean loss: 0.02582830691493655\n",
      "Epoch 5/50, iter: 600/3382, mean loss: 0.021115661084386374\n",
      "Epoch 5/50, iter: 700/3382, mean loss: 0.00673959292791551\n",
      "Epoch 5/50, iter: 800/3382, mean loss: 0.003006915332935023\n",
      "Epoch 5/50, iter: 900/3382, mean loss: 0.0036168754396589974\n",
      "Epoch 5/50, iter: 1000/3382, mean loss: 0.3079245950865561\n",
      "Epoch 5/50, iter: 1100/3382, mean loss: 0.3458421987993643\n",
      "Epoch 5/50, iter: 1200/3382, mean loss: 0.12674343172227964\n",
      "Epoch 5/50, iter: 1300/3382, mean loss: 0.06223685408200254\n",
      "Epoch 5/50, iter: 1400/3382, mean loss: 0.03220043995690503\n",
      "Epoch 5/50, iter: 1500/3382, mean loss: 0.02788582313940424\n",
      "Epoch 5/50, iter: 1600/3382, mean loss: 0.03647399168591619\n",
      "Epoch 5/50, iter: 1700/3382, mean loss: 0.016395703076705105\n",
      "Epoch 5/50, iter: 1800/3382, mean loss: 0.6585856367349152\n",
      "Epoch 5/50, iter: 1900/3382, mean loss: 0.40364728585351256\n",
      "Epoch 5/50, iter: 2000/3382, mean loss: 0.14730962418136187\n",
      "Epoch 5/50, iter: 2100/3382, mean loss: 0.053933673856809035\n",
      "Epoch 5/50, iter: 2200/3382, mean loss: 0.04908604597425437\n",
      "Epoch 5/50, iter: 2300/3382, mean loss: 0.028968446769504226\n",
      "Epoch 5/50, iter: 2400/3382, mean loss: 0.0158761153964042\n",
      "Epoch 5/50, iter: 2500/3382, mean loss: 0.021038330783844685\n",
      "Epoch 5/50, iter: 2600/3382, mean loss: 0.8542740272820447\n",
      "Epoch 5/50, iter: 2700/3382, mean loss: 0.19375628544483334\n",
      "Epoch 5/50, iter: 2800/3382, mean loss: 0.0644190146055189\n",
      "Epoch 5/50, iter: 2900/3382, mean loss: 0.038588758686892106\n",
      "Epoch 5/50, iter: 3000/3382, mean loss: 0.04256671599490801\n",
      "Epoch 5/50, iter: 3100/3382, mean loss: 0.026031930462013405\n",
      "Epoch 5/50, iter: 3200/3382, mean loss: 0.0176568366372112\n",
      "Epoch 5/50, iter: 3300/3382, mean loss: 0.010930921455901625\n",
      "Epoch 6/50, iter: 100/3382, mean loss: 0.5498184892794233\n",
      "Epoch 6/50, iter: 200/3382, mean loss: 0.029990323429155977\n",
      "Epoch 6/50, iter: 300/3382, mean loss: 0.010944100921260542\n",
      "Epoch 6/50, iter: 400/3382, mean loss: 0.013183221920844517\n",
      "Epoch 6/50, iter: 500/3382, mean loss: 0.02876171532094304\n",
      "Epoch 6/50, iter: 600/3382, mean loss: 0.016064586015822897\n",
      "Epoch 6/50, iter: 700/3382, mean loss: 0.007020717910177154\n",
      "Epoch 6/50, iter: 800/3382, mean loss: 0.004962012201362995\n",
      "Epoch 6/50, iter: 900/3382, mean loss: 0.005081264543498491\n",
      "Epoch 6/50, iter: 1000/3382, mean loss: 0.2655197974184762\n",
      "Epoch 6/50, iter: 1100/3382, mean loss: 0.33198922517942264\n",
      "Epoch 6/50, iter: 1200/3382, mean loss: 0.1548004706937354\n",
      "Epoch 6/50, iter: 1300/3382, mean loss: 0.05085563479777193\n",
      "Epoch 6/50, iter: 1400/3382, mean loss: 0.024921458358803647\n",
      "Epoch 6/50, iter: 1500/3382, mean loss: 0.0228624075551852\n",
      "Epoch 6/50, iter: 1600/3382, mean loss: 0.040643829137989085\n",
      "Epoch 6/50, iter: 1700/3382, mean loss: 0.020895349514712506\n",
      "Epoch 6/50, iter: 1800/3382, mean loss: 0.560332782707942\n",
      "Epoch 6/50, iter: 1900/3382, mean loss: 0.38595010854303835\n",
      "Epoch 6/50, iter: 2000/3382, mean loss: 0.13993908257340082\n",
      "Epoch 6/50, iter: 2100/3382, mean loss: 0.05789219725961629\n",
      "Epoch 6/50, iter: 2200/3382, mean loss: 0.04747385161337661\n",
      "Epoch 6/50, iter: 2300/3382, mean loss: 0.027143321044750337\n",
      "Epoch 6/50, iter: 2400/3382, mean loss: 0.022438856604976534\n",
      "Epoch 6/50, iter: 2500/3382, mean loss: 0.02617439684400324\n",
      "Epoch 6/50, iter: 2600/3382, mean loss: 0.7526098325115618\n",
      "Epoch 6/50, iter: 2700/3382, mean loss: 0.23014719891361893\n",
      "Epoch 6/50, iter: 2800/3382, mean loss: 0.07795721694477833\n",
      "Epoch 6/50, iter: 2900/3382, mean loss: 0.05081603043683572\n",
      "Epoch 6/50, iter: 3000/3382, mean loss: 0.04774712126771192\n",
      "Epoch 6/50, iter: 3100/3382, mean loss: 0.026648234741778652\n",
      "Epoch 6/50, iter: 3200/3382, mean loss: 0.016380198777778788\n",
      "Epoch 6/50, iter: 3300/3382, mean loss: 0.01210781383650101\n",
      "Epoch 7/50, iter: 100/3382, mean loss: 0.32162625912635123\n",
      "Epoch 7/50, iter: 200/3382, mean loss: 0.04851196942016031\n",
      "Epoch 7/50, iter: 300/3382, mean loss: 0.020890587022768158\n",
      "Epoch 7/50, iter: 400/3382, mean loss: 0.012368019401656057\n",
      "Epoch 7/50, iter: 500/3382, mean loss: 0.03753116021626738\n",
      "Epoch 7/50, iter: 600/3382, mean loss: 0.04216986263765648\n",
      "Epoch 7/50, iter: 700/3382, mean loss: 0.009993712855198282\n",
      "Epoch 7/50, iter: 800/3382, mean loss: 0.010661786891014345\n",
      "Epoch 7/50, iter: 900/3382, mean loss: 0.010420279769084573\n",
      "Epoch 7/50, iter: 1000/3382, mean loss: 0.21837897067250198\n",
      "Epoch 7/50, iter: 1100/3382, mean loss: 0.35496620228979736\n",
      "Epoch 7/50, iter: 1200/3382, mean loss: 0.251109035940608\n",
      "Epoch 7/50, iter: 1300/3382, mean loss: 0.10332553615593497\n",
      "Epoch 7/50, iter: 1400/3382, mean loss: 0.0544269015017926\n",
      "Epoch 7/50, iter: 1500/3382, mean loss: 0.031691971861655475\n",
      "Epoch 7/50, iter: 1600/3382, mean loss: 0.03319147645051999\n",
      "Epoch 7/50, iter: 1700/3382, mean loss: 0.016204659616323624\n",
      "Epoch 7/50, iter: 1800/3382, mean loss: 0.5213659752724266\n",
      "Epoch 7/50, iter: 1900/3382, mean loss: 0.43847783566452564\n",
      "Epoch 7/50, iter: 2000/3382, mean loss: 0.2860548837040551\n",
      "Epoch 7/50, iter: 2100/3382, mean loss: 0.12104491173551651\n",
      "Epoch 7/50, iter: 2200/3382, mean loss: 0.0690130901667726\n",
      "Epoch 7/50, iter: 2300/3382, mean loss: 0.04286838966460891\n",
      "Epoch 7/50, iter: 2400/3382, mean loss: 0.024131129092374977\n",
      "Epoch 7/50, iter: 2500/3382, mean loss: 0.028712637887180106\n",
      "Epoch 7/50, iter: 2600/3382, mean loss: 0.6950890877517486\n",
      "Epoch 7/50, iter: 2700/3382, mean loss: 0.3021174142707605\n",
      "Epoch 7/50, iter: 2800/3382, mean loss: 0.11499157567275688\n",
      "Epoch 7/50, iter: 2900/3382, mean loss: 0.07177262546450948\n",
      "Epoch 7/50, iter: 3000/3382, mean loss: 0.060670873951894466\n",
      "Epoch 7/50, iter: 3100/3382, mean loss: 0.032752878038954804\n",
      "Epoch 7/50, iter: 3200/3382, mean loss: 0.025172698650076198\n",
      "Epoch 7/50, iter: 3300/3382, mean loss: 0.015858633588377417\n",
      "Epoch 8/50, iter: 100/3382, mean loss: 0.35685312873742076\n",
      "Epoch 8/50, iter: 200/3382, mean loss: 0.038819914143896316\n",
      "Epoch 8/50, iter: 300/3382, mean loss: 0.027688457745261984\n",
      "Epoch 8/50, iter: 400/3382, mean loss: 0.022546541266947315\n",
      "Epoch 8/50, iter: 500/3382, mean loss: 0.028736145159000442\n",
      "Epoch 8/50, iter: 600/3382, mean loss: 0.02103283010495943\n",
      "Epoch 8/50, iter: 700/3382, mean loss: 0.011637483230588259\n",
      "Epoch 8/50, iter: 800/3382, mean loss: 0.017346456820243928\n",
      "Epoch 8/50, iter: 900/3382, mean loss: 0.015459805504145835\n",
      "Epoch 8/50, iter: 1000/3382, mean loss: 0.1813380408821513\n",
      "Epoch 8/50, iter: 1100/3382, mean loss: 0.2970952622545883\n",
      "Epoch 8/50, iter: 1200/3382, mean loss: 0.2029892465134617\n",
      "Epoch 8/50, iter: 1300/3382, mean loss: 0.12086556296300842\n",
      "Epoch 8/50, iter: 1400/3382, mean loss: 0.05787966988037624\n",
      "Epoch 8/50, iter: 1500/3382, mean loss: 0.028235882495409897\n",
      "Epoch 8/50, iter: 1600/3382, mean loss: 0.04816749758418837\n",
      "Epoch 8/50, iter: 1700/3382, mean loss: 0.021162345308694056\n",
      "Epoch 8/50, iter: 1800/3382, mean loss: 0.4272907558032489\n",
      "Epoch 8/50, iter: 1900/3382, mean loss: 0.4346339622978121\n",
      "Epoch 8/50, iter: 2000/3382, mean loss: 0.267118233719375\n",
      "Epoch 8/50, iter: 2100/3382, mean loss: 0.13037850730863285\n",
      "Epoch 8/50, iter: 2200/3382, mean loss: 0.06964793748295961\n",
      "Epoch 8/50, iter: 2300/3382, mean loss: 0.03722705656200787\n",
      "Epoch 8/50, iter: 2400/3382, mean loss: 0.030968425564653897\n",
      "Epoch 8/50, iter: 2500/3382, mean loss: 0.023065844653590375\n",
      "Epoch 8/50, iter: 2600/3382, mean loss: 0.6882337142463985\n",
      "Epoch 8/50, iter: 2700/3382, mean loss: 0.24032243501278572\n",
      "Epoch 8/50, iter: 2800/3382, mean loss: 0.10864732850459405\n",
      "Epoch 8/50, iter: 2900/3382, mean loss: 0.07892746037963662\n",
      "Epoch 8/50, iter: 3000/3382, mean loss: 0.04674740557849873\n",
      "Epoch 8/50, iter: 3100/3382, mean loss: 0.03188997701992832\n",
      "Epoch 8/50, iter: 3200/3382, mean loss: 0.020693938238128453\n",
      "Epoch 8/50, iter: 3300/3382, mean loss: 0.0133817309093331\n",
      "Epoch 9/50, iter: 100/3382, mean loss: 0.27013555162004194\n",
      "Epoch 9/50, iter: 200/3382, mean loss: 0.07147390165213437\n",
      "Epoch 9/50, iter: 300/3382, mean loss: 0.01170883698951002\n",
      "Epoch 9/50, iter: 400/3382, mean loss: 0.009984887410182637\n",
      "Epoch 9/50, iter: 500/3382, mean loss: 0.023862371094428455\n",
      "Epoch 9/50, iter: 600/3382, mean loss: 0.012746277292044396\n",
      "Epoch 9/50, iter: 700/3382, mean loss: 0.006129712342788025\n",
      "Epoch 9/50, iter: 800/3382, mean loss: 0.021827086121145384\n",
      "Epoch 9/50, iter: 900/3382, mean loss: 0.022510403831644224\n",
      "Epoch 9/50, iter: 1000/3382, mean loss: 0.15093622097228263\n",
      "Epoch 9/50, iter: 1100/3382, mean loss: 0.3209915911592543\n",
      "Epoch 9/50, iter: 1200/3382, mean loss: 0.24191806545597502\n",
      "Epoch 9/50, iter: 1300/3382, mean loss: 0.15639084704627748\n",
      "Epoch 9/50, iter: 1400/3382, mean loss: 0.08240593739632458\n",
      "Epoch 9/50, iter: 1500/3382, mean loss: 0.04524048362167377\n",
      "Epoch 9/50, iter: 1600/3382, mean loss: 0.0597476039916728\n",
      "Epoch 9/50, iter: 1700/3382, mean loss: 0.021509166506384646\n",
      "Epoch 9/50, iter: 1800/3382, mean loss: 0.3827649387656857\n",
      "Epoch 9/50, iter: 1900/3382, mean loss: 0.35778396915877236\n",
      "Epoch 9/50, iter: 2000/3382, mean loss: 0.26746882652165366\n",
      "Epoch 9/50, iter: 2100/3382, mean loss: 0.13445457214431372\n",
      "Epoch 9/50, iter: 2200/3382, mean loss: 0.09075878530618865\n",
      "Epoch 9/50, iter: 2300/3382, mean loss: 0.05680190188872075\n",
      "Epoch 9/50, iter: 2400/3382, mean loss: 0.030482867405235082\n",
      "Epoch 9/50, iter: 2500/3382, mean loss: 0.024193473206776162\n",
      "Epoch 9/50, iter: 2600/3382, mean loss: 0.6517230032778207\n",
      "Epoch 9/50, iter: 2700/3382, mean loss: 0.2584365048156178\n",
      "Epoch 9/50, iter: 2800/3382, mean loss: 0.16006463926009018\n",
      "Epoch 9/50, iter: 2900/3382, mean loss: 0.10811333281602856\n",
      "Epoch 9/50, iter: 3000/3382, mean loss: 0.08842613360262476\n",
      "Epoch 9/50, iter: 3100/3382, mean loss: 0.03382694288010384\n",
      "Epoch 9/50, iter: 3200/3382, mean loss: 0.024886084947960966\n",
      "Epoch 9/50, iter: 3300/3382, mean loss: 0.015791050190890984\n",
      "Epoch 10/50, iter: 100/3382, mean loss: 0.304612706987391\n",
      "Epoch 10/50, iter: 200/3382, mean loss: 0.06490012487451167\n",
      "Epoch 10/50, iter: 300/3382, mean loss: 0.022176308834459632\n",
      "Epoch 10/50, iter: 400/3382, mean loss: 0.043028661785665466\n",
      "Epoch 10/50, iter: 500/3382, mean loss: 0.056630919297149376\n",
      "Epoch 10/50, iter: 600/3382, mean loss: 0.033103001341114574\n",
      "Epoch 10/50, iter: 700/3382, mean loss: 0.011149216434573646\n",
      "Epoch 10/50, iter: 800/3382, mean loss: 0.016772407814914913\n",
      "Epoch 10/50, iter: 900/3382, mean loss: 0.03188213373688995\n",
      "Epoch 10/50, iter: 1000/3382, mean loss: 0.12320523571077956\n",
      "Epoch 10/50, iter: 1100/3382, mean loss: 0.31174902397440746\n",
      "Epoch 10/50, iter: 1200/3382, mean loss: 0.2822124371957034\n",
      "Epoch 10/50, iter: 1300/3382, mean loss: 0.1949104372417787\n",
      "Epoch 10/50, iter: 1400/3382, mean loss: 0.15588434545788915\n",
      "Epoch 10/50, iter: 1500/3382, mean loss: 0.09331464732244057\n",
      "Epoch 10/50, iter: 1600/3382, mean loss: 0.07206516340396775\n",
      "Epoch 10/50, iter: 1700/3382, mean loss: 0.03279609286711093\n",
      "Epoch 10/50, iter: 1800/3382, mean loss: 0.39139144650122487\n",
      "Epoch 10/50, iter: 1900/3382, mean loss: 0.3641302320268005\n",
      "Epoch 10/50, iter: 2000/3382, mean loss: 0.3082721002330072\n",
      "Epoch 10/50, iter: 2100/3382, mean loss: 0.16924865963694175\n",
      "Epoch 10/50, iter: 2200/3382, mean loss: 0.11270109893266636\n",
      "Epoch 10/50, iter: 2300/3382, mean loss: 0.09071527573963976\n",
      "Epoch 10/50, iter: 2400/3382, mean loss: 0.04449263797164349\n",
      "Epoch 10/50, iter: 2500/3382, mean loss: 0.02123093982461796\n",
      "Epoch 10/50, iter: 2600/3382, mean loss: 0.6659050318759546\n",
      "Epoch 10/50, iter: 2700/3382, mean loss: 0.33674158447305674\n",
      "Epoch 10/50, iter: 2800/3382, mean loss: 0.14967514517484232\n",
      "Epoch 10/50, iter: 2900/3382, mean loss: 0.13450040908079244\n",
      "Epoch 10/50, iter: 3000/3382, mean loss: 0.08915941117335023\n",
      "Epoch 10/50, iter: 3100/3382, mean loss: 0.06298702699619753\n",
      "Epoch 10/50, iter: 3200/3382, mean loss: 0.043633287376687806\n",
      "Epoch 10/50, iter: 3300/3382, mean loss: 0.0253573071630035\n",
      "Epoch 11/50, iter: 100/3382, mean loss: 0.2142960340580612\n",
      "Epoch 11/50, iter: 200/3382, mean loss: 0.05394658296747366\n",
      "Epoch 11/50, iter: 300/3382, mean loss: 0.03353875956647243\n",
      "Epoch 11/50, iter: 400/3382, mean loss: 0.011835142584495771\n",
      "Epoch 11/50, iter: 500/3382, mean loss: 0.032696232724701985\n",
      "Epoch 11/50, iter: 600/3382, mean loss: 0.03226659307786349\n",
      "Epoch 11/50, iter: 700/3382, mean loss: 0.01663056911035994\n",
      "Epoch 11/50, iter: 800/3382, mean loss: 0.015599698179456141\n",
      "Epoch 11/50, iter: 900/3382, mean loss: 0.010453580044859336\n",
      "Epoch 11/50, iter: 1000/3382, mean loss: 0.08127571214824514\n",
      "Epoch 11/50, iter: 1100/3382, mean loss: 0.2165081143254065\n",
      "Epoch 11/50, iter: 1200/3382, mean loss: 0.14960116196831222\n",
      "Epoch 11/50, iter: 1300/3382, mean loss: 0.10194049419660586\n",
      "Epoch 11/50, iter: 1400/3382, mean loss: 0.08816754624545865\n",
      "Epoch 11/50, iter: 1500/3382, mean loss: 0.04314320090750698\n",
      "Epoch 11/50, iter: 1600/3382, mean loss: 0.05366390809740551\n",
      "Epoch 11/50, iter: 1700/3382, mean loss: 0.022238922958940747\n",
      "Epoch 11/50, iter: 1800/3382, mean loss: 0.26853769557405033\n",
      "Epoch 11/50, iter: 1900/3382, mean loss: 0.3337714265228715\n",
      "Epoch 11/50, iter: 2000/3382, mean loss: 0.2249923764311825\n",
      "Epoch 11/50, iter: 2100/3382, mean loss: 0.14381764916004613\n",
      "Epoch 11/50, iter: 2200/3382, mean loss: 0.08477569003764074\n",
      "Epoch 11/50, iter: 2300/3382, mean loss: 0.09369123947472872\n",
      "Epoch 11/50, iter: 2400/3382, mean loss: 0.031915480332531845\n",
      "Epoch 11/50, iter: 2500/3382, mean loss: 0.03336895235415795\n",
      "Epoch 11/50, iter: 2600/3382, mean loss: 0.43230478243076503\n",
      "Epoch 11/50, iter: 2700/3382, mean loss: 0.20657821595377754\n",
      "Epoch 11/50, iter: 2800/3382, mean loss: 0.09638129589497112\n",
      "Epoch 11/50, iter: 2900/3382, mean loss: 0.07714557879415224\n",
      "Epoch 11/50, iter: 3000/3382, mean loss: 0.07435085261309723\n",
      "Epoch 11/50, iter: 3100/3382, mean loss: 0.04177588606113204\n",
      "Epoch 11/50, iter: 3200/3382, mean loss: 0.03327738684567521\n",
      "Epoch 11/50, iter: 3300/3382, mean loss: 0.016859563333205187\n",
      "Epoch 12/50, iter: 100/3382, mean loss: 0.19462107829822345\n",
      "Epoch 12/50, iter: 200/3382, mean loss: 0.051996301363124074\n",
      "Epoch 12/50, iter: 300/3382, mean loss: 0.019857243499072866\n",
      "Epoch 12/50, iter: 400/3382, mean loss: 0.01734519274492868\n",
      "Epoch 12/50, iter: 500/3382, mean loss: 0.02349537142072677\n",
      "Epoch 12/50, iter: 600/3382, mean loss: 0.014464820288487772\n",
      "Epoch 12/50, iter: 700/3382, mean loss: 0.0077581341375480405\n",
      "Epoch 12/50, iter: 800/3382, mean loss: 0.008662272584452922\n",
      "Epoch 12/50, iter: 900/3382, mean loss: 0.017128968060665387\n",
      "Epoch 12/50, iter: 1000/3382, mean loss: 0.08441537958743794\n",
      "Epoch 12/50, iter: 1100/3382, mean loss: 0.15313197885407134\n",
      "Epoch 12/50, iter: 1200/3382, mean loss: 0.1566078017930704\n",
      "Epoch 12/50, iter: 1300/3382, mean loss: 0.0806663541947637\n",
      "Epoch 12/50, iter: 1400/3382, mean loss: 0.058429228835884715\n",
      "Epoch 12/50, iter: 1500/3382, mean loss: 0.03284985815986147\n",
      "Epoch 12/50, iter: 1600/3382, mean loss: 0.04575550994502464\n",
      "Epoch 12/50, iter: 1700/3382, mean loss: 0.023599356708547247\n",
      "Epoch 12/50, iter: 1800/3382, mean loss: 0.21628741728718068\n",
      "Epoch 12/50, iter: 1900/3382, mean loss: 0.2960319394528051\n",
      "Epoch 12/50, iter: 2000/3382, mean loss: 0.17841051399802382\n",
      "Epoch 12/50, iter: 2100/3382, mean loss: 0.09327040723874233\n",
      "Epoch 12/50, iter: 2200/3382, mean loss: 0.10028666007965512\n",
      "Epoch 12/50, iter: 2300/3382, mean loss: 0.050333385415888186\n",
      "Epoch 12/50, iter: 2400/3382, mean loss: 0.04354446849330998\n",
      "Epoch 12/50, iter: 2500/3382, mean loss: 0.027807388896583234\n",
      "Epoch 12/50, iter: 2600/3382, mean loss: 0.3805368324870432\n",
      "Epoch 12/50, iter: 2700/3382, mean loss: 0.18289135199651355\n",
      "Epoch 12/50, iter: 2800/3382, mean loss: 0.12548345269908168\n",
      "Epoch 12/50, iter: 2900/3382, mean loss: 0.05798478750781214\n",
      "Epoch 12/50, iter: 3000/3382, mean loss: 0.05934639384682669\n",
      "Epoch 12/50, iter: 3100/3382, mean loss: 0.060228673520578015\n",
      "Epoch 12/50, iter: 3200/3382, mean loss: 0.03479524700529055\n",
      "Epoch 12/50, iter: 3300/3382, mean loss: 0.019019093081294614\n",
      "Epoch 13/50, iter: 100/3382, mean loss: 0.13231467068384517\n",
      "Epoch 13/50, iter: 200/3382, mean loss: 0.059198767400157525\n",
      "Epoch 13/50, iter: 300/3382, mean loss: 0.029861712771298697\n",
      "Epoch 13/50, iter: 400/3382, mean loss: 0.010721402535015159\n",
      "Epoch 13/50, iter: 500/3382, mean loss: 0.03116572849609952\n",
      "Epoch 13/50, iter: 600/3382, mean loss: 0.01141550221586897\n",
      "Epoch 13/50, iter: 700/3382, mean loss: 0.009048915965912271\n",
      "Epoch 13/50, iter: 800/3382, mean loss: 0.009296140022893268\n",
      "Epoch 13/50, iter: 900/3382, mean loss: 0.012621109591627188\n",
      "Epoch 13/50, iter: 1000/3382, mean loss: 0.0869328480842151\n",
      "Epoch 13/50, iter: 1100/3382, mean loss: 0.1691876865478116\n",
      "Epoch 13/50, iter: 1200/3382, mean loss: 0.12384463016507652\n",
      "Epoch 13/50, iter: 1300/3382, mean loss: 0.12511169511263687\n",
      "Epoch 13/50, iter: 1400/3382, mean loss: 0.07839209561216648\n",
      "Epoch 13/50, iter: 1500/3382, mean loss: 0.04677089045646426\n",
      "Epoch 13/50, iter: 1600/3382, mean loss: 0.05149047635064789\n",
      "Epoch 13/50, iter: 1700/3382, mean loss: 0.033896394593512014\n",
      "Epoch 13/50, iter: 1800/3382, mean loss: 0.1686767563632202\n",
      "Epoch 13/50, iter: 1900/3382, mean loss: 0.265560760983426\n",
      "Epoch 13/50, iter: 2000/3382, mean loss: 0.1542201165696315\n",
      "Epoch 13/50, iter: 2100/3382, mean loss: 0.08203636540623847\n",
      "Epoch 13/50, iter: 2200/3382, mean loss: 0.12319663391867834\n",
      "Epoch 13/50, iter: 2300/3382, mean loss: 0.05147103193840849\n",
      "Epoch 13/50, iter: 2400/3382, mean loss: 0.045110711538166016\n",
      "Epoch 13/50, iter: 2500/3382, mean loss: 0.03499802026658926\n",
      "Epoch 13/50, iter: 2600/3382, mean loss: 0.39133460812719933\n",
      "Epoch 13/50, iter: 2700/3382, mean loss: 0.18528892117908982\n",
      "Epoch 13/50, iter: 2800/3382, mean loss: 0.08918316972209141\n",
      "Epoch 13/50, iter: 2900/3382, mean loss: 0.07024098046309518\n",
      "Epoch 13/50, iter: 3000/3382, mean loss: 0.08850691002222448\n",
      "Epoch 13/50, iter: 3100/3382, mean loss: 0.051566238869713746\n",
      "Epoch 13/50, iter: 3200/3382, mean loss: 0.03471931168298397\n",
      "Epoch 13/50, iter: 3300/3382, mean loss: 0.014054252554313963\n",
      "Epoch 14/50, iter: 100/3382, mean loss: 0.11874996391074091\n",
      "Epoch 14/50, iter: 200/3382, mean loss: 0.08363544554310508\n",
      "Epoch 14/50, iter: 300/3382, mean loss: 0.011785886508150725\n",
      "Epoch 14/50, iter: 400/3382, mean loss: 0.012533789012832131\n",
      "Epoch 14/50, iter: 500/3382, mean loss: 0.026209563351319503\n",
      "Epoch 14/50, iter: 600/3382, mean loss: 0.02121654177812161\n",
      "Epoch 14/50, iter: 700/3382, mean loss: 0.013753783619070249\n",
      "Epoch 14/50, iter: 800/3382, mean loss: 0.006815074721868939\n",
      "Epoch 14/50, iter: 900/3382, mean loss: 0.024532471635434448\n",
      "Epoch 14/50, iter: 1000/3382, mean loss: 0.05871337801609684\n",
      "Epoch 14/50, iter: 1100/3382, mean loss: 0.13461764166564535\n",
      "Epoch 14/50, iter: 1200/3382, mean loss: 0.15732089822085982\n",
      "Epoch 14/50, iter: 1300/3382, mean loss: 0.10494313031857018\n",
      "Epoch 14/50, iter: 1400/3382, mean loss: 0.04872584642784204\n",
      "Epoch 14/50, iter: 1500/3382, mean loss: 0.041215392913313734\n",
      "Epoch 14/50, iter: 1600/3382, mean loss: 0.05177525686763602\n",
      "Epoch 14/50, iter: 1700/3382, mean loss: 0.04773906919642172\n",
      "Epoch 14/50, iter: 1800/3382, mean loss: 0.1838119915928928\n",
      "Epoch 14/50, iter: 1900/3382, mean loss: 0.23146043880980868\n",
      "Epoch 14/50, iter: 2000/3382, mean loss: 0.14527948253766226\n",
      "Epoch 14/50, iter: 2100/3382, mean loss: 0.07879408535125548\n",
      "Epoch 14/50, iter: 2200/3382, mean loss: 0.0685943588813825\n",
      "Epoch 14/50, iter: 2300/3382, mean loss: 0.07724650096266941\n",
      "Epoch 14/50, iter: 2400/3382, mean loss: 0.04334830714216878\n",
      "Epoch 14/50, iter: 2500/3382, mean loss: 0.02905893441206686\n",
      "Epoch 14/50, iter: 2600/3382, mean loss: 0.28763976390171364\n",
      "Epoch 14/50, iter: 2700/3382, mean loss: 0.1561773561332302\n",
      "Epoch 14/50, iter: 2800/3382, mean loss: 0.06783508878374506\n",
      "Epoch 14/50, iter: 2900/3382, mean loss: 0.07258153246099482\n",
      "Epoch 14/50, iter: 3000/3382, mean loss: 0.07393241081963936\n",
      "Epoch 14/50, iter: 3100/3382, mean loss: 0.07023159461522938\n",
      "Epoch 14/50, iter: 3200/3382, mean loss: 0.021975412970033404\n",
      "Epoch 14/50, iter: 3300/3382, mean loss: 0.017467031358792157\n",
      "Epoch 15/50, iter: 100/3382, mean loss: 0.09047033351165851\n",
      "Epoch 15/50, iter: 200/3382, mean loss: 0.03278602410640417\n",
      "Epoch 15/50, iter: 300/3382, mean loss: 0.039524625917645155\n",
      "Epoch 15/50, iter: 400/3382, mean loss: 0.04043435651956429\n",
      "Epoch 15/50, iter: 500/3382, mean loss: 0.01878303728253343\n",
      "Epoch 15/50, iter: 600/3382, mean loss: 0.06814893531797281\n",
      "Epoch 15/50, iter: 700/3382, mean loss: 0.0036053427723022934\n",
      "Epoch 15/50, iter: 800/3382, mean loss: 0.007738613423433662\n",
      "Epoch 15/50, iter: 900/3382, mean loss: 0.03431772822978964\n",
      "Epoch 15/50, iter: 1000/3382, mean loss: 0.04930584685293425\n",
      "Epoch 15/50, iter: 1100/3382, mean loss: 0.12834761053491092\n",
      "Epoch 15/50, iter: 1200/3382, mean loss: 0.1310052925670243\n",
      "Epoch 15/50, iter: 1300/3382, mean loss: 0.08508231695818722\n",
      "Epoch 15/50, iter: 1400/3382, mean loss: 0.05309881384159098\n",
      "Epoch 15/50, iter: 1500/3382, mean loss: 0.04848459946456387\n",
      "Epoch 15/50, iter: 1600/3382, mean loss: 0.06412879399987786\n",
      "Epoch 15/50, iter: 1700/3382, mean loss: 0.021031038801444593\n",
      "Epoch 15/50, iter: 1800/3382, mean loss: 0.13288360492580978\n",
      "Epoch 15/50, iter: 1900/3382, mean loss: 0.16398524264557637\n",
      "Epoch 15/50, iter: 2000/3382, mean loss: 0.17690453944334877\n",
      "Epoch 15/50, iter: 2100/3382, mean loss: 0.11171701616234714\n",
      "Epoch 15/50, iter: 2200/3382, mean loss: 0.09092491719003021\n",
      "Epoch 15/50, iter: 2300/3382, mean loss: 0.07735047862094689\n",
      "Epoch 15/50, iter: 2400/3382, mean loss: 0.02890656058511979\n",
      "Epoch 15/50, iter: 2500/3382, mean loss: 0.051498118647682105\n",
      "Epoch 15/50, iter: 2600/3382, mean loss: 0.2822748771316947\n",
      "Epoch 15/50, iter: 2700/3382, mean loss: 0.14219367704441538\n",
      "Epoch 15/50, iter: 2800/3382, mean loss: 0.1414816497668653\n",
      "Epoch 15/50, iter: 2900/3382, mean loss: 0.09924070046515227\n",
      "Epoch 15/50, iter: 3000/3382, mean loss: 0.08809298770189343\n",
      "Epoch 15/50, iter: 3100/3382, mean loss: 0.043485849250359934\n",
      "Epoch 15/50, iter: 3200/3382, mean loss: 0.04899046103073374\n",
      "Epoch 15/50, iter: 3300/3382, mean loss: 0.014389230101739975\n",
      "Epoch 16/50, iter: 100/3382, mean loss: 0.05807738146550946\n",
      "Epoch 16/50, iter: 200/3382, mean loss: 0.04438045453683912\n",
      "Epoch 16/50, iter: 300/3382, mean loss: 0.010015500619100805\n",
      "Epoch 16/50, iter: 400/3382, mean loss: 0.020730566647748104\n",
      "Epoch 16/50, iter: 500/3382, mean loss: 0.02697021754131214\n",
      "Epoch 16/50, iter: 600/3382, mean loss: 0.017828705723997088\n",
      "Epoch 16/50, iter: 700/3382, mean loss: 0.0058362966702688365\n",
      "Epoch 16/50, iter: 800/3382, mean loss: 0.025317989533664972\n",
      "Epoch 16/50, iter: 900/3382, mean loss: 0.01607367084041421\n",
      "Epoch 16/50, iter: 1000/3382, mean loss: 0.03405180775625645\n",
      "Epoch 16/50, iter: 1100/3382, mean loss: 0.09952168149241515\n",
      "Epoch 16/50, iter: 1200/3382, mean loss: 0.08703230698821471\n",
      "Epoch 16/50, iter: 1300/3382, mean loss: 0.07631920770012592\n",
      "Epoch 16/50, iter: 1400/3382, mean loss: 0.07454557071297359\n",
      "Epoch 16/50, iter: 1500/3382, mean loss: 0.04340888403809117\n",
      "Epoch 16/50, iter: 1600/3382, mean loss: 0.03490278045720345\n",
      "Epoch 16/50, iter: 1700/3382, mean loss: 0.03417796935751198\n",
      "Epoch 16/50, iter: 1800/3382, mean loss: 0.14437314724817724\n",
      "Epoch 16/50, iter: 1900/3382, mean loss: 0.1701410604438206\n",
      "Epoch 16/50, iter: 2000/3382, mean loss: 0.1296347291060556\n",
      "Epoch 16/50, iter: 2100/3382, mean loss: 0.057921127991685355\n",
      "Epoch 16/50, iter: 2200/3382, mean loss: 0.07302604969919799\n",
      "Epoch 16/50, iter: 2300/3382, mean loss: 0.0404575146888962\n",
      "Epoch 16/50, iter: 2400/3382, mean loss: 0.04056794154214515\n",
      "Epoch 16/50, iter: 2500/3382, mean loss: 0.03091454313816314\n",
      "Epoch 16/50, iter: 2600/3382, mean loss: 0.19927282591254256\n",
      "Epoch 16/50, iter: 2700/3382, mean loss: 0.1108977059150675\n",
      "Epoch 16/50, iter: 2800/3382, mean loss: 0.1497276282066923\n",
      "Epoch 16/50, iter: 2900/3382, mean loss: 0.07797936163402483\n",
      "Epoch 16/50, iter: 3000/3382, mean loss: 0.061846987395365434\n",
      "Epoch 16/50, iter: 3100/3382, mean loss: 0.02692930191486255\n",
      "Epoch 16/50, iter: 3200/3382, mean loss: 0.053587406087190176\n",
      "Epoch 16/50, iter: 3300/3382, mean loss: 0.029884950753661314\n",
      "Epoch 17/50, iter: 100/3382, mean loss: 0.05772892323651604\n",
      "Epoch 17/50, iter: 200/3382, mean loss: 0.03465200087273054\n",
      "Epoch 17/50, iter: 300/3382, mean loss: 0.003429848887615208\n",
      "Epoch 17/50, iter: 400/3382, mean loss: 0.003624975763961018\n",
      "Epoch 17/50, iter: 500/3382, mean loss: 0.02149052085945229\n",
      "Epoch 17/50, iter: 600/3382, mean loss: 0.010257928216473929\n",
      "Epoch 17/50, iter: 700/3382, mean loss: 0.0075530355088130816\n",
      "Epoch 17/50, iter: 800/3382, mean loss: 0.03207871720713555\n",
      "Epoch 17/50, iter: 900/3382, mean loss: 0.012277887784561941\n",
      "Epoch 17/50, iter: 1000/3382, mean loss: 0.07704726467919766\n",
      "Epoch 17/50, iter: 1100/3382, mean loss: 0.12166770159291673\n",
      "Epoch 17/50, iter: 1200/3382, mean loss: 0.08647213994660888\n",
      "Epoch 17/50, iter: 1300/3382, mean loss: 0.07879719536134644\n",
      "Epoch 17/50, iter: 1400/3382, mean loss: 0.05672374894403902\n",
      "Epoch 17/50, iter: 1500/3382, mean loss: 0.0690230866733907\n",
      "Epoch 17/50, iter: 1600/3382, mean loss: 0.038205006265828914\n",
      "Epoch 17/50, iter: 1700/3382, mean loss: 0.018077806939124343\n",
      "Epoch 17/50, iter: 1800/3382, mean loss: 0.10277873589407363\n",
      "Epoch 17/50, iter: 1900/3382, mean loss: 0.1701671863370393\n",
      "Epoch 17/50, iter: 2000/3382, mean loss: 0.1851559869544508\n",
      "Epoch 17/50, iter: 2100/3382, mean loss: 0.06783458156021879\n",
      "Epoch 17/50, iter: 2200/3382, mean loss: 0.07189034715457111\n",
      "Epoch 17/50, iter: 2300/3382, mean loss: 0.04323551878527041\n",
      "Epoch 17/50, iter: 2400/3382, mean loss: 0.033684378402987394\n",
      "Epoch 17/50, iter: 2500/3382, mean loss: 0.04978317373484643\n",
      "Epoch 17/50, iter: 2600/3382, mean loss: 0.21307014747436262\n",
      "Epoch 17/50, iter: 2700/3382, mean loss: 0.15345888848347386\n",
      "Epoch 17/50, iter: 2800/3382, mean loss: 0.08255262336610031\n",
      "Epoch 17/50, iter: 2900/3382, mean loss: 0.08239240399031815\n",
      "Epoch 17/50, iter: 3000/3382, mean loss: 0.09706647358537225\n",
      "Epoch 17/50, iter: 3100/3382, mean loss: 0.08033690581905376\n",
      "Epoch 17/50, iter: 3200/3382, mean loss: 0.04907887950252302\n",
      "Epoch 17/50, iter: 3300/3382, mean loss: 0.028421122109882617\n",
      "Epoch 18/50, iter: 100/3382, mean loss: 0.06830280201954793\n",
      "Epoch 18/50, iter: 200/3382, mean loss: 0.0342067294731612\n",
      "Epoch 18/50, iter: 300/3382, mean loss: 0.011528394526391707\n",
      "Epoch 18/50, iter: 400/3382, mean loss: 0.0257186705789492\n",
      "Epoch 18/50, iter: 500/3382, mean loss: 0.02716457507533448\n",
      "Epoch 18/50, iter: 600/3382, mean loss: 0.02624523851521424\n",
      "Epoch 18/50, iter: 700/3382, mean loss: 0.006325931056004847\n",
      "Epoch 18/50, iter: 800/3382, mean loss: 0.003948979632552181\n",
      "Epoch 18/50, iter: 900/3382, mean loss: 0.02878369626713788\n",
      "Epoch 18/50, iter: 1000/3382, mean loss: 0.034940712188026524\n",
      "Epoch 18/50, iter: 1100/3382, mean loss: 0.06690232613739681\n",
      "Epoch 18/50, iter: 1200/3382, mean loss: 0.11709953344875203\n",
      "Epoch 18/50, iter: 1300/3382, mean loss: 0.062268311095231184\n",
      "Epoch 18/50, iter: 1400/3382, mean loss: 0.055406775931541\n",
      "Epoch 18/50, iter: 1500/3382, mean loss: 0.03532823249258001\n",
      "Epoch 18/50, iter: 1600/3382, mean loss: 0.04762056767480203\n",
      "Epoch 18/50, iter: 1700/3382, mean loss: 0.04111531295408497\n",
      "Epoch 18/50, iter: 1800/3382, mean loss: 0.10243998416826898\n",
      "Epoch 18/50, iter: 1900/3382, mean loss: 0.15156635808438296\n",
      "Epoch 18/50, iter: 2000/3382, mean loss: 0.06778936883461938\n",
      "Epoch 18/50, iter: 2100/3382, mean loss: 0.05022408273765905\n",
      "Epoch 18/50, iter: 2200/3382, mean loss: 0.08049232845258757\n",
      "Epoch 18/50, iter: 2300/3382, mean loss: 0.07731276737227681\n",
      "Epoch 18/50, iter: 2400/3382, mean loss: 0.036477578689045484\n",
      "Epoch 18/50, iter: 2500/3382, mean loss: 0.025730416312674153\n",
      "Epoch 18/50, iter: 2600/3382, mean loss: 0.1724350101295014\n",
      "Epoch 18/50, iter: 2700/3382, mean loss: 0.06945267432862239\n",
      "Epoch 18/50, iter: 2800/3382, mean loss: 0.06215181884773301\n",
      "Epoch 18/50, iter: 2900/3382, mean loss: 0.09821796026463744\n",
      "Epoch 18/50, iter: 3000/3382, mean loss: 0.08944930626636051\n",
      "Epoch 18/50, iter: 3100/3382, mean loss: 0.0504834207484862\n",
      "Epoch 18/50, iter: 3200/3382, mean loss: 0.030695258778537494\n",
      "Epoch 18/50, iter: 3300/3382, mean loss: 0.02187786875855622\n",
      "Epoch 19/50, iter: 100/3382, mean loss: 0.037621214492794694\n",
      "Epoch 19/50, iter: 200/3382, mean loss: 0.032378514570129795\n",
      "Epoch 19/50, iter: 300/3382, mean loss: 0.016911822183797085\n",
      "Epoch 19/50, iter: 400/3382, mean loss: 0.011043706292932321\n",
      "Epoch 19/50, iter: 500/3382, mean loss: 0.011829190626040785\n",
      "Epoch 19/50, iter: 600/3382, mean loss: 0.007705815156828173\n",
      "Epoch 19/50, iter: 700/3382, mean loss: 0.0036899496497510144\n",
      "Epoch 19/50, iter: 800/3382, mean loss: 0.01808546859677911\n",
      "Epoch 19/50, iter: 900/3382, mean loss: 0.009551002236532184\n",
      "Epoch 19/50, iter: 1000/3382, mean loss: 0.01689878192645825\n",
      "Epoch 19/50, iter: 1100/3382, mean loss: 0.07499096930071118\n",
      "Epoch 19/50, iter: 1200/3382, mean loss: 0.08644212304006033\n",
      "Epoch 19/50, iter: 1300/3382, mean loss: 0.07123277318785654\n",
      "Epoch 19/50, iter: 1400/3382, mean loss: 0.1039215030534359\n",
      "Epoch 19/50, iter: 1500/3382, mean loss: 0.02742359616501517\n",
      "Epoch 19/50, iter: 1600/3382, mean loss: 0.029612399811023805\n",
      "Epoch 19/50, iter: 1700/3382, mean loss: 0.024925706213815745\n",
      "Epoch 19/50, iter: 1800/3382, mean loss: 0.07422532959164102\n",
      "Epoch 19/50, iter: 1900/3382, mean loss: 0.1574815297782152\n",
      "Epoch 19/50, iter: 2000/3382, mean loss: 0.04851381154055389\n",
      "Epoch 19/50, iter: 2100/3382, mean loss: 0.06325624405628787\n",
      "Epoch 19/50, iter: 2200/3382, mean loss: 0.06509819954194995\n",
      "Epoch 19/50, iter: 2300/3382, mean loss: 0.05894776777780674\n",
      "Epoch 19/50, iter: 2400/3382, mean loss: 0.028023542038014427\n",
      "Epoch 19/50, iter: 2500/3382, mean loss: 0.02398397442011486\n",
      "Epoch 19/50, iter: 2600/3382, mean loss: 0.11072636263429786\n",
      "Epoch 19/50, iter: 2700/3382, mean loss: 0.08866277743522005\n",
      "Epoch 19/50, iter: 2800/3382, mean loss: 0.0493812035189876\n",
      "Epoch 19/50, iter: 2900/3382, mean loss: 0.07514887986469602\n",
      "Epoch 19/50, iter: 3000/3382, mean loss: 0.05580253492280917\n",
      "Epoch 19/50, iter: 3100/3382, mean loss: 0.05222274454910299\n",
      "Epoch 19/50, iter: 3200/3382, mean loss: 0.033289448913684794\n",
      "Epoch 19/50, iter: 3300/3382, mean loss: 0.019353111386237777\n",
      "Epoch 20/50, iter: 100/3382, mean loss: 0.05327323607178812\n",
      "Epoch 20/50, iter: 200/3382, mean loss: 0.04829891388075516\n",
      "Epoch 20/50, iter: 300/3382, mean loss: 0.012814775203358764\n",
      "Epoch 20/50, iter: 400/3382, mean loss: 0.007410392042451761\n",
      "Epoch 20/50, iter: 500/3382, mean loss: 0.018327835999778053\n",
      "Epoch 20/50, iter: 600/3382, mean loss: 0.0022661629495242864\n",
      "Epoch 20/50, iter: 700/3382, mean loss: 0.00904590661796\n",
      "Epoch 20/50, iter: 800/3382, mean loss: 0.00817522310288819\n",
      "Epoch 20/50, iter: 900/3382, mean loss: 0.013865426546710111\n",
      "Epoch 20/50, iter: 1000/3382, mean loss: 0.022790517667627234\n",
      "Epoch 20/50, iter: 1100/3382, mean loss: 0.09860577775001893\n",
      "Epoch 20/50, iter: 1200/3382, mean loss: 0.06524334386892462\n",
      "Epoch 20/50, iter: 1300/3382, mean loss: 0.04843604327207572\n",
      "Epoch 20/50, iter: 1400/3382, mean loss: 0.04483001228937056\n",
      "Epoch 20/50, iter: 1500/3382, mean loss: 0.03327622671612687\n",
      "Epoch 20/50, iter: 1600/3382, mean loss: 0.05071392494033493\n",
      "Epoch 20/50, iter: 1700/3382, mean loss: 0.01814141372274591\n",
      "Epoch 20/50, iter: 1800/3382, mean loss: 0.08727035142990132\n",
      "Epoch 20/50, iter: 1900/3382, mean loss: 0.12445338300937464\n",
      "Epoch 20/50, iter: 2000/3382, mean loss: 0.08825992805516762\n",
      "Epoch 20/50, iter: 2100/3382, mean loss: 0.03752124194501448\n",
      "Epoch 20/50, iter: 2200/3382, mean loss: 0.06660923314366812\n",
      "Epoch 20/50, iter: 2300/3382, mean loss: 0.07652491092553056\n",
      "Epoch 20/50, iter: 2400/3382, mean loss: 0.02424575331458225\n",
      "Epoch 20/50, iter: 2500/3382, mean loss: 0.03053643428111968\n",
      "Epoch 20/50, iter: 2600/3382, mean loss: 0.17148660689125605\n",
      "Epoch 20/50, iter: 2700/3382, mean loss: 0.09803813711422663\n",
      "Epoch 20/50, iter: 2800/3382, mean loss: 0.06607395614637313\n",
      "Epoch 20/50, iter: 2900/3382, mean loss: 0.10399798464878472\n",
      "Epoch 20/50, iter: 3000/3382, mean loss: 0.10985087819870387\n",
      "Epoch 20/50, iter: 3100/3382, mean loss: 0.05690507527723028\n",
      "Epoch 20/50, iter: 3200/3382, mean loss: 0.04364114389337292\n",
      "Epoch 20/50, iter: 3300/3382, mean loss: 0.01910508290595416\n",
      "Epoch 21/50, iter: 100/3382, mean loss: 0.029971173645474494\n",
      "Epoch 21/50, iter: 200/3382, mean loss: 0.04160832256445058\n",
      "Epoch 21/50, iter: 300/3382, mean loss: 0.0015860180215257458\n",
      "Epoch 21/50, iter: 400/3382, mean loss: 0.056150248586938074\n",
      "Epoch 21/50, iter: 500/3382, mean loss: 0.013214134017169279\n",
      "Epoch 21/50, iter: 600/3382, mean loss: 0.01054404618242355\n",
      "Epoch 21/50, iter: 700/3382, mean loss: 0.008194211207993156\n",
      "Epoch 21/50, iter: 800/3382, mean loss: 0.002546813018062011\n",
      "Epoch 21/50, iter: 900/3382, mean loss: 0.013497446814019582\n",
      "Epoch 21/50, iter: 1000/3382, mean loss: 0.018013500790693016\n",
      "Epoch 21/50, iter: 1100/3382, mean loss: 0.04994292043440168\n",
      "Epoch 21/50, iter: 1200/3382, mean loss: 0.04783056454655266\n",
      "Epoch 21/50, iter: 1300/3382, mean loss: 0.07418083256844867\n",
      "Epoch 21/50, iter: 1400/3382, mean loss: 0.045366725046660575\n",
      "Epoch 21/50, iter: 1500/3382, mean loss: 0.038187704476043575\n",
      "Epoch 21/50, iter: 1600/3382, mean loss: 0.048207296606000226\n",
      "Epoch 21/50, iter: 1700/3382, mean loss: 0.04639777393720063\n",
      "Epoch 21/50, iter: 1800/3382, mean loss: 0.06323863326048076\n",
      "Epoch 21/50, iter: 1900/3382, mean loss: 0.10567254201214837\n",
      "Epoch 21/50, iter: 2000/3382, mean loss: 0.09586253175553339\n",
      "Epoch 21/50, iter: 2100/3382, mean loss: 0.07300294593175749\n",
      "Epoch 21/50, iter: 2200/3382, mean loss: 0.11653213448825113\n",
      "Epoch 21/50, iter: 2300/3382, mean loss: 0.06970534282648262\n",
      "Epoch 21/50, iter: 2400/3382, mean loss: 0.04631938832653255\n",
      "Epoch 21/50, iter: 2500/3382, mean loss: 0.020152637274632214\n",
      "Epoch 21/50, iter: 2600/3382, mean loss: 0.14935389571878943\n",
      "Epoch 21/50, iter: 2700/3382, mean loss: 0.12527298621956107\n",
      "Epoch 21/50, iter: 2800/3382, mean loss: 0.055503499449632725\n",
      "Epoch 21/50, iter: 2900/3382, mean loss: 0.0434156954812704\n",
      "Epoch 21/50, iter: 3000/3382, mean loss: 0.08322738714205585\n",
      "Epoch 21/50, iter: 3100/3382, mean loss: 0.061780552595387415\n",
      "Epoch 21/50, iter: 3200/3382, mean loss: 0.06259597868483886\n",
      "Epoch 21/50, iter: 3300/3382, mean loss: 0.043355009085678374\n",
      "Epoch 22/50, iter: 100/3382, mean loss: 0.02479615578974162\n",
      "Epoch 22/50, iter: 200/3382, mean loss: 0.041321735038885164\n",
      "Epoch 22/50, iter: 300/3382, mean loss: 0.006045604149017621\n",
      "Epoch 22/50, iter: 400/3382, mean loss: 0.010556439148310268\n",
      "Epoch 22/50, iter: 500/3382, mean loss: 0.009710142180997926\n",
      "Epoch 22/50, iter: 600/3382, mean loss: 0.002779834082800363\n",
      "Epoch 22/50, iter: 700/3382, mean loss: 0.007368691443396785\n",
      "Epoch 22/50, iter: 800/3382, mean loss: 0.0064448163907936265\n",
      "Epoch 22/50, iter: 900/3382, mean loss: 0.008369628451987304\n",
      "Epoch 22/50, iter: 1000/3382, mean loss: 0.013972112941007033\n",
      "Epoch 22/50, iter: 1100/3382, mean loss: 0.03661590625607005\n",
      "Epoch 22/50, iter: 1200/3382, mean loss: 0.042461573346311995\n",
      "Epoch 22/50, iter: 1300/3382, mean loss: 0.04347913195249276\n",
      "Epoch 22/50, iter: 1400/3382, mean loss: 0.07436142594446167\n",
      "Epoch 22/50, iter: 1500/3382, mean loss: 0.07491058749525394\n",
      "Epoch 22/50, iter: 1600/3382, mean loss: 0.03268519348144196\n",
      "Epoch 22/50, iter: 1700/3382, mean loss: 0.012580223635111664\n",
      "Epoch 22/50, iter: 1800/3382, mean loss: 0.1033714368550001\n",
      "Epoch 22/50, iter: 1900/3382, mean loss: 0.1044851545650716\n",
      "Epoch 22/50, iter: 2000/3382, mean loss: 0.04639788897372298\n",
      "Epoch 22/50, iter: 2100/3382, mean loss: 0.035441560556050716\n",
      "Epoch 22/50, iter: 2200/3382, mean loss: 0.0785339377528959\n",
      "Epoch 22/50, iter: 2300/3382, mean loss: 0.059979693827492075\n",
      "Epoch 22/50, iter: 2400/3382, mean loss: 0.1003192405429337\n",
      "Epoch 22/50, iter: 2500/3382, mean loss: 0.017927583952146373\n",
      "Epoch 22/50, iter: 2600/3382, mean loss: 0.15361260074391964\n",
      "Epoch 22/50, iter: 2700/3382, mean loss: 0.06597846896232142\n",
      "Epoch 22/50, iter: 2800/3382, mean loss: 0.05656417652737218\n",
      "Epoch 22/50, iter: 2900/3382, mean loss: 0.04088493007418492\n",
      "Epoch 22/50, iter: 3000/3382, mean loss: 0.08765462529254166\n",
      "Epoch 22/50, iter: 3100/3382, mean loss: 0.06590114948452594\n",
      "Epoch 22/50, iter: 3200/3382, mean loss: 0.04466977089828163\n",
      "Epoch 22/50, iter: 3300/3382, mean loss: 0.033458391341824406\n",
      "Epoch 23/50, iter: 100/3382, mean loss: 0.034098174449557914\n",
      "Epoch 23/50, iter: 200/3382, mean loss: 0.04384805826533274\n",
      "Epoch 23/50, iter: 300/3382, mean loss: 0.004813983122814847\n",
      "Epoch 23/50, iter: 400/3382, mean loss: 0.0058001057505776285\n",
      "Epoch 23/50, iter: 500/3382, mean loss: 0.035568685981837336\n",
      "Epoch 23/50, iter: 600/3382, mean loss: 0.008636073088911794\n",
      "Epoch 23/50, iter: 700/3382, mean loss: 0.001060407875133791\n",
      "Epoch 23/50, iter: 800/3382, mean loss: 0.0035752051316866582\n",
      "Epoch 23/50, iter: 900/3382, mean loss: 0.015378488419931636\n",
      "Epoch 23/50, iter: 1000/3382, mean loss: 0.04461284873245358\n",
      "Epoch 23/50, iter: 1100/3382, mean loss: 0.038279785972131324\n",
      "Epoch 23/50, iter: 1200/3382, mean loss: 0.05667741447735466\n",
      "Epoch 23/50, iter: 1300/3382, mean loss: 0.04637341188011234\n",
      "Epoch 23/50, iter: 1400/3382, mean loss: 0.05140387106175922\n",
      "Epoch 23/50, iter: 1500/3382, mean loss: 0.027882054422031358\n",
      "Epoch 23/50, iter: 1600/3382, mean loss: 0.048594495268449334\n",
      "Epoch 23/50, iter: 1700/3382, mean loss: 0.027212454967216252\n",
      "Epoch 23/50, iter: 1800/3382, mean loss: 0.06017568986627452\n",
      "Epoch 23/50, iter: 1900/3382, mean loss: 0.09067594113777204\n",
      "Epoch 23/50, iter: 2000/3382, mean loss: 0.04723242869625779\n",
      "Epoch 23/50, iter: 2100/3382, mean loss: 0.03631045312045046\n",
      "Epoch 23/50, iter: 2200/3382, mean loss: 0.03260810906235576\n",
      "Epoch 23/50, iter: 2300/3382, mean loss: 0.10699429877086075\n",
      "Epoch 23/50, iter: 2400/3382, mean loss: 0.05816962483429524\n",
      "Epoch 23/50, iter: 2500/3382, mean loss: 0.07212594445346053\n",
      "Epoch 23/50, iter: 2600/3382, mean loss: 0.12698746184932577\n",
      "Epoch 23/50, iter: 2700/3382, mean loss: 0.03865342861937449\n",
      "Epoch 23/50, iter: 2800/3382, mean loss: 0.027394878974819223\n",
      "Epoch 23/50, iter: 2900/3382, mean loss: 0.0282807878646247\n",
      "Epoch 23/50, iter: 3000/3382, mean loss: 0.1135624445084352\n",
      "Epoch 23/50, iter: 3100/3382, mean loss: 0.1019124501936179\n",
      "Epoch 23/50, iter: 3200/3382, mean loss: 0.036060018921601336\n",
      "Epoch 23/50, iter: 3300/3382, mean loss: 0.020943045237175006\n",
      "Epoch 24/50, iter: 100/3382, mean loss: 0.047702648235993766\n",
      "Epoch 24/50, iter: 200/3382, mean loss: 0.02732957231406779\n",
      "Epoch 24/50, iter: 300/3382, mean loss: 0.012491210115140311\n",
      "Epoch 24/50, iter: 400/3382, mean loss: 0.025883387145088647\n",
      "Epoch 24/50, iter: 500/3382, mean loss: 0.003050430117755134\n",
      "Epoch 24/50, iter: 600/3382, mean loss: 0.001352633343743257\n",
      "Epoch 24/50, iter: 700/3382, mean loss: 0.0007515224507528373\n",
      "Epoch 24/50, iter: 800/3382, mean loss: 0.013962158286716857\n",
      "Epoch 24/50, iter: 900/3382, mean loss: 0.007533267429005619\n",
      "Epoch 24/50, iter: 1000/3382, mean loss: 0.0347985751580914\n",
      "Epoch 24/50, iter: 1100/3382, mean loss: 0.03998891732018052\n",
      "Epoch 24/50, iter: 1200/3382, mean loss: 0.06145582633147573\n",
      "Epoch 24/50, iter: 1300/3382, mean loss: 0.05112583595934438\n",
      "Epoch 24/50, iter: 1400/3382, mean loss: 0.040697251448209786\n",
      "Epoch 24/50, iter: 1500/3382, mean loss: 0.029038300410476267\n",
      "Epoch 24/50, iter: 1600/3382, mean loss: 0.029066335989245077\n",
      "Epoch 24/50, iter: 1700/3382, mean loss: 0.023378418820260122\n",
      "Epoch 24/50, iter: 1800/3382, mean loss: 0.044306696491972455\n",
      "Epoch 24/50, iter: 1900/3382, mean loss: 0.07386089384516424\n",
      "Epoch 24/50, iter: 2000/3382, mean loss: 0.05710271463810997\n",
      "Epoch 24/50, iter: 2100/3382, mean loss: 0.04919364069562476\n",
      "Epoch 24/50, iter: 2200/3382, mean loss: 0.03881075097782457\n",
      "Epoch 24/50, iter: 2300/3382, mean loss: 0.04359398673704817\n",
      "Epoch 24/50, iter: 2400/3382, mean loss: 0.031321992949071314\n",
      "Epoch 24/50, iter: 2500/3382, mean loss: 0.014481823100378577\n",
      "Epoch 24/50, iter: 2600/3382, mean loss: 0.06714259144142488\n",
      "Epoch 24/50, iter: 2700/3382, mean loss: 0.0320561880660847\n",
      "Epoch 24/50, iter: 2800/3382, mean loss: 0.04067696519016678\n",
      "Epoch 24/50, iter: 2900/3382, mean loss: 0.027146055992707332\n",
      "Epoch 24/50, iter: 3000/3382, mean loss: 0.06860830087321375\n",
      "Epoch 24/50, iter: 3100/3382, mean loss: 0.04093056899941075\n",
      "Epoch 24/50, iter: 3200/3382, mean loss: 0.04158982966971081\n",
      "Epoch 24/50, iter: 3300/3382, mean loss: 0.015784504157468574\n",
      "Epoch 25/50, iter: 100/3382, mean loss: 0.042682764410288385\n",
      "Epoch 25/50, iter: 200/3382, mean loss: 0.04237743957658843\n",
      "Epoch 25/50, iter: 300/3382, mean loss: 0.005453331525820992\n",
      "Epoch 25/50, iter: 400/3382, mean loss: 0.015117589342297216\n",
      "Epoch 25/50, iter: 500/3382, mean loss: 0.012913645025283423\n",
      "Epoch 25/50, iter: 600/3382, mean loss: 0.01685385591639797\n",
      "Epoch 25/50, iter: 700/3382, mean loss: 0.0014099547635221298\n",
      "Epoch 25/50, iter: 800/3382, mean loss: 0.002044746686938659\n",
      "Epoch 25/50, iter: 900/3382, mean loss: 0.0036613513310791747\n",
      "Epoch 25/50, iter: 1000/3382, mean loss: 0.013609925143826054\n",
      "Epoch 25/50, iter: 1100/3382, mean loss: 0.04537184498034513\n",
      "Epoch 25/50, iter: 1200/3382, mean loss: 0.04669015058128366\n",
      "Epoch 25/50, iter: 1300/3382, mean loss: 0.05580744643540122\n",
      "Epoch 25/50, iter: 1400/3382, mean loss: 0.0466845897994444\n",
      "Epoch 25/50, iter: 1500/3382, mean loss: 0.04153211546864924\n",
      "Epoch 25/50, iter: 1600/3382, mean loss: 0.06912188933201274\n",
      "Epoch 25/50, iter: 1700/3382, mean loss: 0.00709195194844419\n",
      "Epoch 25/50, iter: 1800/3382, mean loss: 0.059253163475960234\n",
      "Epoch 25/50, iter: 1900/3382, mean loss: 0.08797787148771363\n",
      "Epoch 25/50, iter: 2000/3382, mean loss: 0.05859970903486463\n",
      "Epoch 25/50, iter: 2100/3382, mean loss: 0.030945920284501653\n",
      "Epoch 25/50, iter: 2200/3382, mean loss: 0.048024784880341544\n",
      "Epoch 25/50, iter: 2300/3382, mean loss: 0.029560212763568076\n",
      "Epoch 25/50, iter: 2400/3382, mean loss: 0.07612420322715885\n",
      "Epoch 25/50, iter: 2500/3382, mean loss: 0.022135038627505706\n",
      "Epoch 25/50, iter: 2600/3382, mean loss: 0.09224092264114063\n",
      "Epoch 25/50, iter: 2700/3382, mean loss: 0.05317058396503857\n",
      "Epoch 25/50, iter: 2800/3382, mean loss: 0.03791474878083207\n",
      "Epoch 25/50, iter: 2900/3382, mean loss: 0.08477686218930447\n",
      "Epoch 25/50, iter: 3000/3382, mean loss: 0.03380641599519386\n",
      "Epoch 25/50, iter: 3100/3382, mean loss: 0.03203439643343188\n",
      "Epoch 25/50, iter: 3200/3382, mean loss: 0.024900594828384755\n",
      "Epoch 25/50, iter: 3300/3382, mean loss: 0.010423202912521176\n",
      "Epoch 26/50, iter: 100/3382, mean loss: 0.026913868060084098\n",
      "Epoch 26/50, iter: 200/3382, mean loss: 0.023566072334695178\n",
      "Epoch 26/50, iter: 300/3382, mean loss: 0.0038050828598043297\n",
      "Epoch 26/50, iter: 400/3382, mean loss: 0.0016469119055578575\n",
      "Epoch 26/50, iter: 500/3382, mean loss: 0.009534450793962854\n",
      "Epoch 26/50, iter: 600/3382, mean loss: 0.021884082445513754\n",
      "Epoch 26/50, iter: 700/3382, mean loss: 0.001444663217487694\n",
      "Epoch 26/50, iter: 800/3382, mean loss: 0.012547451733120276\n",
      "Epoch 26/50, iter: 900/3382, mean loss: 0.01935446761944764\n",
      "Epoch 26/50, iter: 1000/3382, mean loss: 0.013049861350973977\n",
      "Epoch 26/50, iter: 1100/3382, mean loss: 0.032391489953629386\n",
      "Epoch 26/50, iter: 1200/3382, mean loss: 0.05624544386602096\n",
      "Epoch 26/50, iter: 1300/3382, mean loss: 0.03655756902116614\n",
      "Epoch 26/50, iter: 1400/3382, mean loss: 0.01837008409255276\n",
      "Epoch 26/50, iter: 1500/3382, mean loss: 0.024613959727825617\n",
      "Epoch 26/50, iter: 1600/3382, mean loss: 0.04055385449447179\n",
      "Epoch 26/50, iter: 1700/3382, mean loss: 0.03468324275362477\n",
      "Epoch 26/50, iter: 1800/3382, mean loss: 0.05263383086265712\n",
      "Epoch 26/50, iter: 1900/3382, mean loss: 0.1167819189968776\n",
      "Epoch 26/50, iter: 2000/3382, mean loss: 0.03149068192889651\n",
      "Epoch 26/50, iter: 2100/3382, mean loss: 0.04322419000922935\n",
      "Epoch 26/50, iter: 2200/3382, mean loss: 0.044456826799250206\n",
      "Epoch 26/50, iter: 2300/3382, mean loss: 0.024191720374721937\n",
      "Epoch 26/50, iter: 2400/3382, mean loss: 0.02301573514389318\n",
      "Epoch 26/50, iter: 2500/3382, mean loss: 0.03458558864821974\n",
      "Epoch 26/50, iter: 2600/3382, mean loss: 0.10117416180933539\n",
      "Epoch 26/50, iter: 2700/3382, mean loss: 0.02808306525113437\n",
      "Epoch 26/50, iter: 2800/3382, mean loss: 0.06408276705905128\n",
      "Epoch 26/50, iter: 2900/3382, mean loss: 0.02887568961035768\n",
      "Epoch 26/50, iter: 3000/3382, mean loss: 0.03611007644303996\n",
      "Epoch 26/50, iter: 3100/3382, mean loss: 0.04795450695372019\n",
      "Epoch 26/50, iter: 3200/3382, mean loss: 0.016824992815018903\n",
      "Epoch 26/50, iter: 3300/3382, mean loss: 0.00923694508605557\n",
      "Epoch 27/50, iter: 100/3382, mean loss: 0.026322628840936772\n",
      "Epoch 27/50, iter: 200/3382, mean loss: 0.02426460426886411\n",
      "Epoch 27/50, iter: 300/3382, mean loss: 0.001252699139596416\n",
      "Epoch 27/50, iter: 400/3382, mean loss: 0.001488904711994543\n",
      "Epoch 27/50, iter: 500/3382, mean loss: 0.0058202340182077\n",
      "Epoch 27/50, iter: 600/3382, mean loss: 0.0037330916871329833\n",
      "Epoch 27/50, iter: 700/3382, mean loss: 0.0007108239240691106\n",
      "Epoch 27/50, iter: 800/3382, mean loss: 0.0076785076522808285\n",
      "Epoch 27/50, iter: 900/3382, mean loss: 0.005574091792162328\n",
      "Epoch 27/50, iter: 1000/3382, mean loss: 0.011728349199029466\n",
      "Epoch 27/50, iter: 1100/3382, mean loss: 0.03377368984328882\n",
      "Epoch 27/50, iter: 1200/3382, mean loss: 0.0244792796417034\n",
      "Epoch 27/50, iter: 1300/3382, mean loss: 0.052369376601584354\n",
      "Epoch 27/50, iter: 1400/3382, mean loss: 0.013232919628353131\n",
      "Epoch 27/50, iter: 1500/3382, mean loss: 0.057028093154787275\n",
      "Epoch 27/50, iter: 1600/3382, mean loss: 0.04590743801184523\n",
      "Epoch 27/50, iter: 1700/3382, mean loss: 0.019728516868151687\n",
      "Epoch 27/50, iter: 1800/3382, mean loss: 0.049522477723902225\n",
      "Epoch 27/50, iter: 1900/3382, mean loss: 0.12612397737611147\n",
      "Epoch 27/50, iter: 2000/3382, mean loss: 0.018713065139103015\n",
      "Epoch 27/50, iter: 2100/3382, mean loss: 0.057486931033755156\n",
      "Epoch 27/50, iter: 2200/3382, mean loss: 0.06825864858354513\n",
      "Epoch 27/50, iter: 2300/3382, mean loss: 0.04744141301552869\n",
      "Epoch 27/50, iter: 2400/3382, mean loss: 0.007622565614822747\n",
      "Epoch 27/50, iter: 2500/3382, mean loss: 0.03910638100458314\n",
      "Epoch 27/50, iter: 2600/3382, mean loss: 0.09753616467702252\n",
      "Epoch 27/50, iter: 2700/3382, mean loss: 0.03835323063973419\n",
      "Epoch 27/50, iter: 2800/3382, mean loss: 0.06965872493037586\n",
      "Epoch 27/50, iter: 2900/3382, mean loss: 0.04140711231284015\n",
      "Epoch 27/50, iter: 3000/3382, mean loss: 0.062390022896121486\n",
      "Epoch 27/50, iter: 3100/3382, mean loss: 0.039656621274802184\n",
      "Epoch 27/50, iter: 3200/3382, mean loss: 0.01330586851795946\n",
      "Epoch 27/50, iter: 3300/3382, mean loss: 0.03036410521898155\n",
      "Epoch 28/50, iter: 100/3382, mean loss: 0.01517748503285869\n",
      "Epoch 28/50, iter: 200/3382, mean loss: 0.015471371212397677\n",
      "Epoch 28/50, iter: 300/3382, mean loss: 0.003502493320192279\n",
      "Epoch 28/50, iter: 400/3382, mean loss: 0.000787326964623567\n",
      "Epoch 28/50, iter: 500/3382, mean loss: 0.002062576422854434\n",
      "Epoch 28/50, iter: 600/3382, mean loss: 0.003633838821249107\n",
      "Epoch 28/50, iter: 700/3382, mean loss: 0.0003441366124896206\n",
      "Epoch 28/50, iter: 800/3382, mean loss: 0.0002862250350797169\n",
      "Epoch 28/50, iter: 900/3382, mean loss: 0.0027223722970025933\n",
      "Epoch 28/50, iter: 1000/3382, mean loss: 0.025329381793667807\n",
      "Epoch 28/50, iter: 1100/3382, mean loss: 0.03128597464829497\n",
      "Epoch 28/50, iter: 1200/3382, mean loss: 0.05147059117761774\n",
      "Epoch 28/50, iter: 1300/3382, mean loss: 0.05000790301349138\n",
      "Epoch 28/50, iter: 1400/3382, mean loss: 0.044685057739046775\n",
      "Epoch 28/50, iter: 1500/3382, mean loss: 0.0046988048482073455\n",
      "Epoch 28/50, iter: 1600/3382, mean loss: 0.030732088695877843\n",
      "Epoch 28/50, iter: 1700/3382, mean loss: 0.02449414786134369\n",
      "Epoch 28/50, iter: 1800/3382, mean loss: 0.07133769097050052\n",
      "Epoch 28/50, iter: 1900/3382, mean loss: 0.07364215489814746\n",
      "Epoch 28/50, iter: 2000/3382, mean loss: 0.030392908083122023\n",
      "Epoch 28/50, iter: 2100/3382, mean loss: 0.039379189164916964\n",
      "Epoch 28/50, iter: 2200/3382, mean loss: 0.03789190350386022\n",
      "Epoch 28/50, iter: 2300/3382, mean loss: 0.05111028631788614\n",
      "Epoch 28/50, iter: 2400/3382, mean loss: 0.05451865809233976\n",
      "Epoch 28/50, iter: 2500/3382, mean loss: 0.011953674064023758\n",
      "Epoch 28/50, iter: 2600/3382, mean loss: 0.08564621815279437\n",
      "Epoch 28/50, iter: 2700/3382, mean loss: 0.016775063326818048\n",
      "Epoch 28/50, iter: 2800/3382, mean loss: 0.049421312074184126\n",
      "Epoch 28/50, iter: 2900/3382, mean loss: 0.03210675923733646\n",
      "Epoch 28/50, iter: 3000/3382, mean loss: 0.033651076806050534\n",
      "Epoch 28/50, iter: 3100/3382, mean loss: 0.02870334987448672\n",
      "Epoch 28/50, iter: 3200/3382, mean loss: 0.04133648119700421\n",
      "Epoch 28/50, iter: 3300/3382, mean loss: 0.02429035937553042\n",
      "Epoch 29/50, iter: 100/3382, mean loss: 0.0074914302704021905\n",
      "Epoch 29/50, iter: 200/3382, mean loss: 0.024673509507695604\n",
      "Epoch 29/50, iter: 300/3382, mean loss: 0.002726387778646817\n",
      "Epoch 29/50, iter: 400/3382, mean loss: 0.0025325654309504486\n",
      "Epoch 29/50, iter: 500/3382, mean loss: 0.0026682241258592755\n",
      "Epoch 29/50, iter: 600/3382, mean loss: 0.005245127207578939\n",
      "Epoch 29/50, iter: 700/3382, mean loss: 0.00414364218402568\n",
      "Epoch 29/50, iter: 800/3382, mean loss: 0.000991964093781661\n",
      "Epoch 29/50, iter: 900/3382, mean loss: 0.0004295203968492345\n",
      "Epoch 29/50, iter: 1000/3382, mean loss: 0.005338954433201728\n",
      "Epoch 29/50, iter: 1100/3382, mean loss: 0.029095856498324083\n",
      "Epoch 29/50, iter: 1200/3382, mean loss: 0.03412206651770923\n",
      "Epoch 29/50, iter: 1300/3382, mean loss: 0.03586293695561579\n",
      "Epoch 29/50, iter: 1400/3382, mean loss: 0.015259160148845652\n",
      "Epoch 29/50, iter: 1500/3382, mean loss: 0.016571886352945386\n",
      "Epoch 29/50, iter: 1600/3382, mean loss: 0.023236840032140868\n",
      "Epoch 29/50, iter: 1700/3382, mean loss: 0.03583557850741439\n",
      "Epoch 29/50, iter: 1800/3382, mean loss: 0.031692233001530144\n",
      "Epoch 29/50, iter: 1900/3382, mean loss: 0.05669281216905709\n",
      "Epoch 29/50, iter: 2000/3382, mean loss: 0.021383690884779084\n",
      "Epoch 29/50, iter: 2100/3382, mean loss: 0.03674318281017868\n",
      "Epoch 29/50, iter: 2200/3382, mean loss: 0.04450049935775013\n",
      "Epoch 29/50, iter: 2300/3382, mean loss: 0.051864343202960475\n",
      "Epoch 29/50, iter: 2400/3382, mean loss: 0.028438924800910002\n",
      "Epoch 29/50, iter: 2500/3382, mean loss: 0.012915666617582602\n",
      "Epoch 29/50, iter: 2600/3382, mean loss: 0.11632672693304201\n",
      "Epoch 29/50, iter: 2700/3382, mean loss: 0.032263458170726976\n",
      "Epoch 29/50, iter: 2800/3382, mean loss: 0.015677670692446383\n",
      "Epoch 29/50, iter: 2900/3382, mean loss: 0.021511982793527906\n",
      "Epoch 29/50, iter: 3000/3382, mean loss: 0.026144698760870496\n",
      "Epoch 29/50, iter: 3100/3382, mean loss: 0.04586040280740864\n",
      "Epoch 29/50, iter: 3200/3382, mean loss: 0.029115857563090302\n",
      "Epoch 29/50, iter: 3300/3382, mean loss: 0.04669663668809076\n",
      "Epoch 30/50, iter: 100/3382, mean loss: 0.011391876711120226\n",
      "Epoch 30/50, iter: 200/3382, mean loss: 0.04083998701376974\n",
      "Epoch 30/50, iter: 300/3382, mean loss: 0.0008625079980181738\n",
      "Epoch 30/50, iter: 400/3382, mean loss: 0.00019804685001258095\n",
      "Epoch 30/50, iter: 500/3382, mean loss: 0.005372513507085373\n",
      "Epoch 30/50, iter: 600/3382, mean loss: 0.009279582029031914\n",
      "Epoch 30/50, iter: 700/3382, mean loss: 0.0004425922865879528\n",
      "Epoch 30/50, iter: 800/3382, mean loss: 0.0029107090561275584\n",
      "Epoch 30/50, iter: 900/3382, mean loss: 0.0025949561381385065\n",
      "Epoch 30/50, iter: 1000/3382, mean loss: 0.023167345612365792\n",
      "Epoch 30/50, iter: 1100/3382, mean loss: 0.03600471113139392\n",
      "Epoch 30/50, iter: 1200/3382, mean loss: 0.07330475860964399\n",
      "Epoch 30/50, iter: 1300/3382, mean loss: 0.027372526656583674\n",
      "Epoch 30/50, iter: 1400/3382, mean loss: 0.018530103723559392\n",
      "Epoch 30/50, iter: 1500/3382, mean loss: 0.023585945958146476\n",
      "Epoch 30/50, iter: 1600/3382, mean loss: 0.011513353031366833\n",
      "Epoch 30/50, iter: 1700/3382, mean loss: 0.017369829232096096\n",
      "Epoch 30/50, iter: 1800/3382, mean loss: 0.03881140026203809\n",
      "Epoch 30/50, iter: 1900/3382, mean loss: 0.06017583506318292\n",
      "Epoch 30/50, iter: 2000/3382, mean loss: 0.014727700442918134\n",
      "Epoch 30/50, iter: 2100/3382, mean loss: 0.03621617106939198\n",
      "Epoch 30/50, iter: 2200/3382, mean loss: 0.056333698261121265\n",
      "Epoch 30/50, iter: 2300/3382, mean loss: 0.02062730706351921\n",
      "Epoch 30/50, iter: 2400/3382, mean loss: 0.02046347800273683\n",
      "Epoch 30/50, iter: 2500/3382, mean loss: 0.02943172397963224\n",
      "Epoch 30/50, iter: 2600/3382, mean loss: 0.0929294196232825\n",
      "Epoch 30/50, iter: 2700/3382, mean loss: 0.042165940508990724\n",
      "Epoch 30/50, iter: 2800/3382, mean loss: 0.019469683588854744\n",
      "Epoch 30/50, iter: 2900/3382, mean loss: 0.02224620371443976\n",
      "Epoch 30/50, iter: 3000/3382, mean loss: 0.030370595751534425\n",
      "Epoch 30/50, iter: 3100/3382, mean loss: 0.03496990689730556\n",
      "Epoch 30/50, iter: 3200/3382, mean loss: 0.014640205015910616\n",
      "Epoch 30/50, iter: 3300/3382, mean loss: 0.026499659486254393\n",
      "Epoch 31/50, iter: 100/3382, mean loss: 0.021566756391492987\n",
      "Epoch 31/50, iter: 200/3382, mean loss: 0.037160431981140364\n",
      "Epoch 31/50, iter: 300/3382, mean loss: 0.005109823584748412\n",
      "Epoch 31/50, iter: 400/3382, mean loss: 0.008780783097615163\n",
      "Epoch 31/50, iter: 500/3382, mean loss: 0.012965679452393495\n",
      "Epoch 31/50, iter: 600/3382, mean loss: 0.01231956300837009\n",
      "Epoch 31/50, iter: 700/3382, mean loss: 0.0056115488047550595\n",
      "Epoch 31/50, iter: 800/3382, mean loss: 0.0019334171839814828\n",
      "Epoch 31/50, iter: 900/3382, mean loss: 0.007145018478779583\n",
      "Epoch 31/50, iter: 1000/3382, mean loss: 0.0064468894300868836\n",
      "Epoch 31/50, iter: 1100/3382, mean loss: 0.015518889313400593\n",
      "Epoch 31/50, iter: 1200/3382, mean loss: 0.048427992579565926\n",
      "Epoch 31/50, iter: 1300/3382, mean loss: 0.03756032445264285\n",
      "Epoch 31/50, iter: 1400/3382, mean loss: 0.028238625371812917\n",
      "Epoch 31/50, iter: 1500/3382, mean loss: 0.013754797062487611\n",
      "Epoch 31/50, iter: 1600/3382, mean loss: 0.014538578332413864\n",
      "Epoch 31/50, iter: 1700/3382, mean loss: 0.01449621758787\n",
      "Epoch 31/50, iter: 1800/3382, mean loss: 0.06341806557737062\n",
      "Epoch 31/50, iter: 1900/3382, mean loss: 0.16565070766083637\n",
      "Epoch 31/50, iter: 2000/3382, mean loss: 0.016068082786757074\n",
      "Epoch 31/50, iter: 2100/3382, mean loss: 0.009211425394188667\n",
      "Epoch 31/50, iter: 2200/3382, mean loss: 0.02592312852703092\n",
      "Epoch 31/50, iter: 2300/3382, mean loss: 0.05731143799617407\n",
      "Epoch 31/50, iter: 2400/3382, mean loss: 0.006335727815829024\n",
      "Epoch 31/50, iter: 2500/3382, mean loss: 0.033009794384641786\n",
      "Epoch 31/50, iter: 2600/3382, mean loss: 0.058639611251013725\n",
      "Epoch 31/50, iter: 2700/3382, mean loss: 0.023450029889131727\n",
      "Epoch 31/50, iter: 2800/3382, mean loss: 0.01055676245114995\n",
      "Epoch 31/50, iter: 2900/3382, mean loss: 0.03946193616163427\n",
      "Epoch 31/50, iter: 3000/3382, mean loss: 0.029319800960628653\n",
      "Epoch 31/50, iter: 3100/3382, mean loss: 0.05170487178602873\n",
      "Epoch 31/50, iter: 3200/3382, mean loss: 0.011877842140643082\n",
      "Epoch 31/50, iter: 3300/3382, mean loss: 0.02149640195664176\n",
      "Epoch 32/50, iter: 100/3382, mean loss: 0.002768484583018669\n",
      "Epoch 32/50, iter: 200/3382, mean loss: 0.03425683419304271\n",
      "Epoch 32/50, iter: 300/3382, mean loss: 0.03359389714475352\n",
      "Epoch 32/50, iter: 400/3382, mean loss: 0.00743079923800483\n",
      "Epoch 32/50, iter: 500/3382, mean loss: 0.001817560667574547\n",
      "Epoch 32/50, iter: 600/3382, mean loss: 0.012566353850847846\n",
      "Epoch 32/50, iter: 700/3382, mean loss: 0.0008308097461805986\n",
      "Epoch 32/50, iter: 800/3382, mean loss: 0.0017213094003985675\n",
      "Epoch 32/50, iter: 900/3382, mean loss: 0.006483091380892922\n",
      "Epoch 32/50, iter: 1000/3382, mean loss: 0.012077256955421483\n",
      "Epoch 32/50, iter: 1100/3382, mean loss: 0.018902656779405228\n",
      "Epoch 32/50, iter: 1200/3382, mean loss: 0.05823826478870316\n",
      "Epoch 32/50, iter: 1300/3382, mean loss: 0.09427765011062235\n",
      "Epoch 32/50, iter: 1400/3382, mean loss: 0.025841933092207264\n",
      "Epoch 32/50, iter: 1500/3382, mean loss: 0.05581870309321204\n",
      "Epoch 32/50, iter: 1600/3382, mean loss: 0.017926054529006592\n",
      "Epoch 32/50, iter: 1700/3382, mean loss: 0.02022636463197447\n",
      "Epoch 32/50, iter: 1800/3382, mean loss: 0.02621942089180557\n",
      "Epoch 32/50, iter: 1900/3382, mean loss: 0.05612773345945829\n",
      "Epoch 32/50, iter: 2000/3382, mean loss: 0.02581908983424551\n",
      "Epoch 32/50, iter: 2100/3382, mean loss: 0.018655423198946756\n",
      "Epoch 32/50, iter: 2200/3382, mean loss: 0.01239722497557942\n",
      "Epoch 32/50, iter: 2300/3382, mean loss: 0.02196193916118929\n",
      "Epoch 32/50, iter: 2400/3382, mean loss: 0.07093981524158355\n",
      "Epoch 32/50, iter: 2500/3382, mean loss: 0.015427079446716832\n",
      "Epoch 32/50, iter: 2600/3382, mean loss: 0.055715667228429314\n",
      "Epoch 32/50, iter: 2700/3382, mean loss: 0.010325394872067762\n",
      "Epoch 32/50, iter: 2800/3382, mean loss: 0.0421641874054685\n",
      "Epoch 32/50, iter: 2900/3382, mean loss: 0.023344284306878363\n",
      "Epoch 32/50, iter: 3000/3382, mean loss: 0.011612122584731176\n",
      "Epoch 32/50, iter: 3100/3382, mean loss: 0.03314676115240111\n",
      "Epoch 32/50, iter: 3200/3382, mean loss: 0.018118044231924698\n",
      "Epoch 32/50, iter: 3300/3382, mean loss: 0.02478748152917909\n",
      "Epoch 33/50, iter: 100/3382, mean loss: 0.02182561496723341\n",
      "Epoch 33/50, iter: 200/3382, mean loss: 0.021698994413908074\n",
      "Epoch 33/50, iter: 300/3382, mean loss: 0.00039488539540680987\n",
      "Epoch 33/50, iter: 400/3382, mean loss: 0.0052375681865567\n",
      "Epoch 33/50, iter: 500/3382, mean loss: 0.0017060105798656622\n",
      "Epoch 33/50, iter: 600/3382, mean loss: 0.0007894661821381277\n",
      "Epoch 33/50, iter: 700/3382, mean loss: 0.000938147146569257\n",
      "Epoch 33/50, iter: 800/3382, mean loss: 0.011785808623341366\n",
      "Epoch 33/50, iter: 900/3382, mean loss: 0.0003565368370782451\n",
      "Epoch 33/50, iter: 1000/3382, mean loss: 0.010224212812483664\n",
      "Epoch 33/50, iter: 1100/3382, mean loss: 0.044414932291544744\n",
      "Epoch 33/50, iter: 1200/3382, mean loss: 0.04279683349485285\n",
      "Epoch 33/50, iter: 1300/3382, mean loss: 0.02087247124288659\n",
      "Epoch 33/50, iter: 1400/3382, mean loss: 0.009558216012691433\n",
      "Epoch 33/50, iter: 1500/3382, mean loss: 0.011951509912406521\n",
      "Epoch 33/50, iter: 1600/3382, mean loss: 0.01905793321145712\n",
      "Epoch 33/50, iter: 1700/3382, mean loss: 0.005673435095655713\n",
      "Epoch 33/50, iter: 1800/3382, mean loss: 0.02060643500554491\n",
      "Epoch 33/50, iter: 1900/3382, mean loss: 0.05563845219349026\n",
      "Epoch 33/50, iter: 2000/3382, mean loss: 0.031096721843345845\n",
      "Epoch 33/50, iter: 2100/3382, mean loss: 0.03140648814060214\n",
      "Epoch 33/50, iter: 2200/3382, mean loss: 0.026243750602814017\n",
      "Epoch 33/50, iter: 2300/3382, mean loss: 0.01070035430560754\n",
      "Epoch 33/50, iter: 2400/3382, mean loss: 0.011449038261188918\n",
      "Epoch 33/50, iter: 2500/3382, mean loss: 0.01229470960527344\n",
      "Epoch 33/50, iter: 2600/3382, mean loss: 0.0641478188685721\n",
      "Epoch 33/50, iter: 2700/3382, mean loss: 0.01834090541134575\n",
      "Epoch 33/50, iter: 2800/3382, mean loss: 0.061391021478152404\n",
      "Epoch 33/50, iter: 2900/3382, mean loss: 0.011142319032414355\n",
      "Epoch 33/50, iter: 3000/3382, mean loss: 0.012797856434738613\n",
      "Epoch 33/50, iter: 3100/3382, mean loss: 0.012837807172154214\n",
      "Epoch 33/50, iter: 3200/3382, mean loss: 0.015107438664445283\n",
      "Epoch 33/50, iter: 3300/3382, mean loss: 0.008868107807010759\n",
      "Epoch 34/50, iter: 100/3382, mean loss: 0.0059615412866136095\n",
      "Epoch 34/50, iter: 200/3382, mean loss: 0.009204707057181913\n",
      "Epoch 34/50, iter: 300/3382, mean loss: 0.002012135654375129\n",
      "Epoch 34/50, iter: 400/3382, mean loss: 0.0001955832362308385\n",
      "Epoch 34/50, iter: 500/3382, mean loss: 0.006101521526465596\n",
      "Epoch 34/50, iter: 600/3382, mean loss: 0.0009505530472432965\n",
      "Epoch 34/50, iter: 700/3382, mean loss: 0.0003912566291510089\n",
      "Epoch 34/50, iter: 800/3382, mean loss: 0.0006090017267316128\n",
      "Epoch 34/50, iter: 900/3382, mean loss: 0.0003882802050526735\n",
      "Epoch 34/50, iter: 1000/3382, mean loss: 0.0031160801094315006\n",
      "Epoch 34/50, iter: 1100/3382, mean loss: 0.03329028581264076\n",
      "Epoch 34/50, iter: 1200/3382, mean loss: 0.011669941093805463\n",
      "Epoch 34/50, iter: 1300/3382, mean loss: 0.01955851633804187\n",
      "Epoch 34/50, iter: 1400/3382, mean loss: 0.005762152979315189\n",
      "Epoch 34/50, iter: 1500/3382, mean loss: 0.06307687143113835\n",
      "Epoch 34/50, iter: 1600/3382, mean loss: 0.01954384510502873\n",
      "Epoch 34/50, iter: 1700/3382, mean loss: 0.0018089185757731484\n",
      "Epoch 34/50, iter: 1800/3382, mean loss: 0.02094419323812751\n",
      "Epoch 34/50, iter: 1900/3382, mean loss: 0.08388669474307232\n",
      "Epoch 34/50, iter: 2000/3382, mean loss: 0.020887737369409118\n",
      "Epoch 34/50, iter: 2100/3382, mean loss: 0.03625832297765868\n",
      "Epoch 34/50, iter: 2200/3382, mean loss: 0.07080718982058382\n",
      "Epoch 34/50, iter: 2300/3382, mean loss: 0.012002147363529937\n",
      "Epoch 34/50, iter: 2400/3382, mean loss: 0.022815141046103448\n",
      "Epoch 34/50, iter: 2500/3382, mean loss: 0.028678873406474743\n",
      "Epoch 34/50, iter: 2600/3382, mean loss: 0.07218322003601109\n",
      "Epoch 34/50, iter: 2700/3382, mean loss: 0.02268890572078348\n",
      "Epoch 34/50, iter: 2800/3382, mean loss: 0.031624050945208176\n",
      "Epoch 34/50, iter: 2900/3382, mean loss: 0.0412293825677602\n",
      "Epoch 34/50, iter: 3000/3382, mean loss: 0.013934828631205072\n",
      "Epoch 34/50, iter: 3100/3382, mean loss: 0.023077542879503064\n",
      "Epoch 34/50, iter: 3200/3382, mean loss: 0.024443736997468123\n",
      "Epoch 34/50, iter: 3300/3382, mean loss: 0.007925982612034943\n",
      "Epoch 35/50, iter: 100/3382, mean loss: 0.021699350552736724\n",
      "Epoch 35/50, iter: 200/3382, mean loss: 0.023663249680651324\n",
      "Epoch 35/50, iter: 300/3382, mean loss: 0.002177419047781015\n",
      "Epoch 35/50, iter: 400/3382, mean loss: 0.00012779845410499036\n",
      "Epoch 35/50, iter: 500/3382, mean loss: 0.0031170892358822044\n",
      "Epoch 35/50, iter: 600/3382, mean loss: 0.0015088348414712982\n",
      "Epoch 35/50, iter: 700/3382, mean loss: 0.0012829634484288377\n",
      "Epoch 35/50, iter: 800/3382, mean loss: 0.009822108163769983\n",
      "Epoch 35/50, iter: 900/3382, mean loss: 0.0025792598010222533\n",
      "Epoch 35/50, iter: 1000/3382, mean loss: 0.0022252785716655767\n",
      "Epoch 35/50, iter: 1100/3382, mean loss: 0.01164074340064797\n",
      "Epoch 35/50, iter: 1200/3382, mean loss: 0.032471691041512755\n",
      "Epoch 35/50, iter: 1300/3382, mean loss: 0.01362158046783179\n",
      "Epoch 35/50, iter: 1400/3382, mean loss: 0.03466859627039881\n",
      "Epoch 35/50, iter: 1500/3382, mean loss: 0.016001517943640558\n",
      "Epoch 35/50, iter: 1600/3382, mean loss: 0.017511881900573664\n",
      "Epoch 35/50, iter: 1700/3382, mean loss: 0.01033300035315321\n",
      "Epoch 35/50, iter: 1800/3382, mean loss: 0.028530058354100732\n",
      "Epoch 35/50, iter: 1900/3382, mean loss: 0.08476285533998112\n",
      "Epoch 35/50, iter: 2000/3382, mean loss: 0.019692762182635697\n",
      "Epoch 35/50, iter: 2100/3382, mean loss: 0.037799113722157\n",
      "Epoch 35/50, iter: 2200/3382, mean loss: 0.06464687472981297\n",
      "Epoch 35/50, iter: 2300/3382, mean loss: 0.010207979309386097\n",
      "Epoch 35/50, iter: 2400/3382, mean loss: 0.025292959839209813\n",
      "Epoch 35/50, iter: 2500/3382, mean loss: 0.011205284044114272\n",
      "Epoch 35/50, iter: 2600/3382, mean loss: 0.06830402309384642\n",
      "Epoch 35/50, iter: 2700/3382, mean loss: 0.024196111571007782\n",
      "Epoch 35/50, iter: 2800/3382, mean loss: 0.012952295996289998\n",
      "Epoch 35/50, iter: 2900/3382, mean loss: 0.014008124639928851\n",
      "Epoch 35/50, iter: 3000/3382, mean loss: 0.0240171311418878\n",
      "Epoch 35/50, iter: 3100/3382, mean loss: 0.025795032492895123\n",
      "Epoch 35/50, iter: 3200/3382, mean loss: 0.012470942199748158\n",
      "Epoch 35/50, iter: 3300/3382, mean loss: 0.005582843508112454\n",
      "Epoch 36/50, iter: 100/3382, mean loss: 0.01158504170994604\n",
      "Epoch 36/50, iter: 200/3382, mean loss: 0.01894110566569797\n",
      "Epoch 36/50, iter: 300/3382, mean loss: 0.01881218893192532\n",
      "Epoch 36/50, iter: 400/3382, mean loss: 0.007914516494082164\n",
      "Epoch 36/50, iter: 500/3382, mean loss: 0.004204541964113986\n",
      "Epoch 36/50, iter: 600/3382, mean loss: 0.00031484985777677113\n",
      "Epoch 36/50, iter: 700/3382, mean loss: 0.0008924757861415599\n",
      "Epoch 36/50, iter: 800/3382, mean loss: 0.0008866042338695123\n",
      "Epoch 36/50, iter: 900/3382, mean loss: 0.00044064887720395517\n",
      "Epoch 36/50, iter: 1000/3382, mean loss: 0.007058257518259587\n",
      "Epoch 36/50, iter: 1100/3382, mean loss: 0.011175310306007588\n",
      "Epoch 36/50, iter: 1200/3382, mean loss: 0.019412965064754602\n",
      "Epoch 36/50, iter: 1300/3382, mean loss: 0.02996213505363972\n",
      "Epoch 36/50, iter: 1400/3382, mean loss: 0.035088809727919494\n",
      "Epoch 36/50, iter: 1500/3382, mean loss: 0.009138506211752287\n",
      "Epoch 36/50, iter: 1600/3382, mean loss: 0.00835335366254217\n",
      "Epoch 36/50, iter: 1700/3382, mean loss: 0.007379545343958896\n",
      "Epoch 36/50, iter: 1800/3382, mean loss: 0.015202545300558548\n",
      "Epoch 36/50, iter: 1900/3382, mean loss: 0.04206054603020746\n",
      "Epoch 36/50, iter: 2000/3382, mean loss: 0.007510092199736213\n",
      "Epoch 36/50, iter: 2100/3382, mean loss: 0.03436893628168249\n",
      "Epoch 36/50, iter: 2200/3382, mean loss: 0.04232066455252084\n",
      "Epoch 36/50, iter: 2300/3382, mean loss: 0.008018685136086105\n",
      "Epoch 36/50, iter: 2400/3382, mean loss: 0.006973829001740981\n",
      "Epoch 36/50, iter: 2500/3382, mean loss: 0.009304383139378878\n",
      "Epoch 36/50, iter: 2600/3382, mean loss: 0.051302106530601216\n",
      "Epoch 36/50, iter: 2700/3382, mean loss: 0.015206981855434308\n",
      "Epoch 36/50, iter: 2800/3382, mean loss: 0.007060328982415207\n",
      "Epoch 36/50, iter: 2900/3382, mean loss: 0.006138815957420398\n",
      "Epoch 36/50, iter: 3000/3382, mean loss: 0.012327080609742823\n",
      "Epoch 36/50, iter: 3100/3382, mean loss: 0.03595443211019706\n",
      "Epoch 36/50, iter: 3200/3382, mean loss: 0.010682807446807593\n",
      "Epoch 36/50, iter: 3300/3382, mean loss: 0.009952406644458662\n",
      "Epoch 37/50, iter: 100/3382, mean loss: 0.014696092186324101\n",
      "Epoch 37/50, iter: 200/3382, mean loss: 0.03448691995282921\n",
      "Epoch 37/50, iter: 300/3382, mean loss: 0.0014248626373987606\n",
      "Epoch 37/50, iter: 400/3382, mean loss: 0.0007966692671580589\n",
      "Epoch 37/50, iter: 500/3382, mean loss: 0.004924176813721672\n",
      "Epoch 37/50, iter: 600/3382, mean loss: 0.0006479331069123262\n",
      "Epoch 37/50, iter: 700/3382, mean loss: 0.0020191714637420688\n",
      "Epoch 37/50, iter: 800/3382, mean loss: 0.0009599119455956994\n",
      "Epoch 37/50, iter: 900/3382, mean loss: 0.0007245945854569413\n",
      "Epoch 37/50, iter: 1000/3382, mean loss: 0.0015926714039317246\n",
      "Epoch 37/50, iter: 1100/3382, mean loss: 0.03994162402975693\n",
      "Epoch 37/50, iter: 1200/3382, mean loss: 0.030436450112985583\n",
      "Epoch 37/50, iter: 1300/3382, mean loss: 0.02948147094672187\n",
      "Epoch 37/50, iter: 1400/3382, mean loss: 0.009257784847223931\n",
      "Epoch 37/50, iter: 1500/3382, mean loss: 0.01176940725029869\n",
      "Epoch 37/50, iter: 1600/3382, mean loss: 0.02425718654948881\n",
      "Epoch 37/50, iter: 1700/3382, mean loss: 0.01567692596046431\n",
      "Epoch 37/50, iter: 1800/3382, mean loss: 0.022282338488223523\n",
      "Epoch 37/50, iter: 1900/3382, mean loss: 0.08159288789648897\n",
      "Epoch 37/50, iter: 2000/3382, mean loss: 0.0042236575754231965\n",
      "Epoch 37/50, iter: 2100/3382, mean loss: 0.024536620803648858\n",
      "Epoch 37/50, iter: 2200/3382, mean loss: 0.011673534775838873\n",
      "Epoch 37/50, iter: 2300/3382, mean loss: 0.018526929911052578\n",
      "Epoch 37/50, iter: 2400/3382, mean loss: 0.005325715457561699\n",
      "Epoch 37/50, iter: 2500/3382, mean loss: 0.02582413782451695\n",
      "Epoch 37/50, iter: 2600/3382, mean loss: 0.05191670881100762\n",
      "Epoch 37/50, iter: 2700/3382, mean loss: 0.029464010119224823\n",
      "Epoch 37/50, iter: 2800/3382, mean loss: 0.011429431115223423\n",
      "Epoch 37/50, iter: 2900/3382, mean loss: 0.009627603964960728\n",
      "Epoch 37/50, iter: 3000/3382, mean loss: 0.012007062748417105\n",
      "Epoch 37/50, iter: 3100/3382, mean loss: 0.00720690094473813\n",
      "Epoch 37/50, iter: 3200/3382, mean loss: 0.005974161604616057\n",
      "Epoch 37/50, iter: 3300/3382, mean loss: 0.014728080641078946\n",
      "Epoch 38/50, iter: 100/3382, mean loss: 0.009160510013033515\n",
      "Epoch 38/50, iter: 200/3382, mean loss: 0.026886461886885406\n",
      "Epoch 38/50, iter: 300/3382, mean loss: 0.00046429086845844124\n",
      "Epoch 38/50, iter: 400/3382, mean loss: 0.00020449056087336713\n",
      "Epoch 38/50, iter: 500/3382, mean loss: 0.001255212532657808\n",
      "Epoch 38/50, iter: 600/3382, mean loss: 0.012340754388315247\n",
      "Epoch 38/50, iter: 700/3382, mean loss: 0.00016683049263072292\n",
      "Epoch 38/50, iter: 800/3382, mean loss: 0.0023510747086630344\n",
      "Epoch 38/50, iter: 900/3382, mean loss: 0.002021167850668171\n",
      "Epoch 38/50, iter: 1000/3382, mean loss: 0.006156903765423358\n",
      "Epoch 38/50, iter: 1100/3382, mean loss: 0.01072198054945389\n",
      "Epoch 38/50, iter: 1200/3382, mean loss: 0.013379810615649319\n",
      "Epoch 38/50, iter: 1300/3382, mean loss: 0.01879122053205059\n",
      "Epoch 38/50, iter: 1400/3382, mean loss: 0.017304123736394884\n",
      "Epoch 38/50, iter: 1500/3382, mean loss: 0.012107378862422066\n",
      "Epoch 38/50, iter: 1600/3382, mean loss: 0.015272384287795511\n",
      "Epoch 38/50, iter: 1700/3382, mean loss: 0.002182542669769525\n",
      "Epoch 38/50, iter: 1800/3382, mean loss: 0.02946393621995945\n",
      "Epoch 38/50, iter: 1900/3382, mean loss: 0.0529976763763748\n",
      "Epoch 38/50, iter: 2000/3382, mean loss: 0.0071620986740297\n",
      "Epoch 38/50, iter: 2100/3382, mean loss: 0.035567324662428915\n",
      "Epoch 38/50, iter: 2200/3382, mean loss: 0.05004832356255285\n",
      "Epoch 38/50, iter: 2300/3382, mean loss: 0.013588567050367253\n",
      "Epoch 38/50, iter: 2400/3382, mean loss: 0.0035700821283523964\n",
      "Epoch 38/50, iter: 2500/3382, mean loss: 0.00869616315931495\n",
      "Epoch 38/50, iter: 2600/3382, mean loss: 0.05649929560476938\n",
      "Epoch 38/50, iter: 2700/3382, mean loss: 0.013042492688807385\n",
      "Epoch 38/50, iter: 2800/3382, mean loss: 0.02572726483721574\n",
      "Epoch 38/50, iter: 2900/3382, mean loss: 0.021680095162077286\n",
      "Epoch 38/50, iter: 3000/3382, mean loss: 0.007929482462132533\n",
      "Epoch 38/50, iter: 3100/3382, mean loss: 0.010388587792352695\n",
      "Epoch 38/50, iter: 3200/3382, mean loss: 0.014331855623852903\n",
      "Epoch 38/50, iter: 3300/3382, mean loss: 0.005202272275864317\n",
      "Epoch 39/50, iter: 100/3382, mean loss: 0.0033701072520858234\n",
      "Epoch 39/50, iter: 200/3382, mean loss: 0.018890005832991257\n",
      "Epoch 39/50, iter: 300/3382, mean loss: 0.002132787478960978\n",
      "Epoch 39/50, iter: 400/3382, mean loss: 0.0012189506524054395\n",
      "Epoch 39/50, iter: 500/3382, mean loss: 0.00504732384077446\n",
      "Epoch 39/50, iter: 600/3382, mean loss: 2.8558316055367072e-05\n",
      "Epoch 39/50, iter: 700/3382, mean loss: 0.001340876890051561\n",
      "Epoch 39/50, iter: 800/3382, mean loss: 0.001043703774552327\n",
      "Epoch 39/50, iter: 900/3382, mean loss: 0.04689166744532592\n",
      "Epoch 39/50, iter: 1000/3382, mean loss: 0.014297571809498422\n",
      "Epoch 39/50, iter: 1100/3382, mean loss: 0.03415409445318531\n",
      "Epoch 39/50, iter: 1200/3382, mean loss: 0.011989013286474481\n",
      "Epoch 39/50, iter: 1300/3382, mean loss: 0.008074331952265652\n",
      "Epoch 39/50, iter: 1400/3382, mean loss: 0.01011964427488909\n",
      "Epoch 39/50, iter: 1500/3382, mean loss: 0.019385668866531525\n",
      "Epoch 39/50, iter: 1600/3382, mean loss: 0.02005192306649157\n",
      "Epoch 39/50, iter: 1700/3382, mean loss: 0.0857541198290885\n",
      "Epoch 39/50, iter: 1800/3382, mean loss: 0.03311840733157055\n",
      "Epoch 39/50, iter: 1900/3382, mean loss: 0.10751986597261506\n",
      "Epoch 39/50, iter: 2000/3382, mean loss: 0.028615910674299166\n",
      "Epoch 39/50, iter: 2100/3382, mean loss: 0.09510175472781075\n",
      "Epoch 39/50, iter: 2200/3382, mean loss: 0.05862819375296904\n",
      "Epoch 39/50, iter: 2300/3382, mean loss: 0.034897145362873375\n",
      "Epoch 39/50, iter: 2400/3382, mean loss: 0.03399747488268552\n",
      "Epoch 39/50, iter: 2500/3382, mean loss: 0.05114871735263389\n",
      "Epoch 39/50, iter: 2600/3382, mean loss: 0.1153764006520004\n",
      "Epoch 39/50, iter: 2700/3382, mean loss: 0.03598331902968692\n",
      "Epoch 39/50, iter: 2800/3382, mean loss: 0.012884858023155452\n",
      "Epoch 39/50, iter: 2900/3382, mean loss: 0.019603300868316503\n",
      "Epoch 39/50, iter: 3000/3382, mean loss: 0.019894579692456383\n",
      "Epoch 39/50, iter: 3100/3382, mean loss: 0.04728361176650079\n",
      "Epoch 39/50, iter: 3200/3382, mean loss: 0.08922996873655802\n",
      "Epoch 39/50, iter: 3300/3382, mean loss: 0.016563156884560684\n",
      "Epoch 40/50, iter: 100/3382, mean loss: 0.01365180876947054\n",
      "Epoch 40/50, iter: 200/3382, mean loss: 0.027880566596919357\n",
      "Epoch 40/50, iter: 300/3382, mean loss: 0.0018314148077801917\n",
      "Epoch 40/50, iter: 400/3382, mean loss: 0.00025188842450351244\n",
      "Epoch 40/50, iter: 500/3382, mean loss: 0.0006464115633582778\n",
      "Epoch 40/50, iter: 600/3382, mean loss: 0.003595157366139219\n",
      "Epoch 40/50, iter: 700/3382, mean loss: 0.0022955423231625005\n",
      "Epoch 40/50, iter: 800/3382, mean loss: 0.0011054361694348813\n",
      "Epoch 40/50, iter: 900/3382, mean loss: 0.006163720349679309\n",
      "Epoch 40/50, iter: 1000/3382, mean loss: 0.008721205000849394\n",
      "Epoch 40/50, iter: 1100/3382, mean loss: 0.016845775031427906\n",
      "Epoch 40/50, iter: 1200/3382, mean loss: 0.027343744101128102\n",
      "Epoch 40/50, iter: 1300/3382, mean loss: 0.006911665585175513\n",
      "Epoch 40/50, iter: 1400/3382, mean loss: 0.02326367820821595\n",
      "Epoch 40/50, iter: 1500/3382, mean loss: 0.03689020209528799\n",
      "Epoch 40/50, iter: 1600/3382, mean loss: 0.021425934075010956\n",
      "Epoch 40/50, iter: 1700/3382, mean loss: 0.008600932178600935\n",
      "Epoch 40/50, iter: 1800/3382, mean loss: 0.046701054719470496\n",
      "Epoch 40/50, iter: 1900/3382, mean loss: 0.08100753044814496\n",
      "Epoch 40/50, iter: 2000/3382, mean loss: 0.02404166583877327\n",
      "Epoch 40/50, iter: 2100/3382, mean loss: 0.020096255362320223\n",
      "Epoch 40/50, iter: 2200/3382, mean loss: 0.03648176773583064\n",
      "Epoch 40/50, iter: 2300/3382, mean loss: 0.022603166765994588\n",
      "Epoch 40/50, iter: 2400/3382, mean loss: 0.007883298237034531\n",
      "Epoch 40/50, iter: 2500/3382, mean loss: 0.012638740976540391\n",
      "Epoch 40/50, iter: 2600/3382, mean loss: 0.11540278713635538\n",
      "Epoch 40/50, iter: 2700/3382, mean loss: 0.0059972121313518305\n",
      "Epoch 40/50, iter: 2800/3382, mean loss: 0.008393757427738109\n",
      "Epoch 40/50, iter: 2900/3382, mean loss: 0.01674467096743683\n",
      "Epoch 40/50, iter: 3000/3382, mean loss: 0.02346906095231347\n",
      "Epoch 40/50, iter: 3100/3382, mean loss: 0.028757818818480666\n",
      "Epoch 40/50, iter: 3200/3382, mean loss: 0.025406689994958924\n",
      "Epoch 40/50, iter: 3300/3382, mean loss: 0.019522296883534657\n",
      "Epoch 41/50, iter: 100/3382, mean loss: 0.006322130283022887\n",
      "Epoch 41/50, iter: 200/3382, mean loss: 0.0199240165621147\n",
      "Epoch 41/50, iter: 300/3382, mean loss: 0.002025715026655135\n",
      "Epoch 41/50, iter: 400/3382, mean loss: 0.002803044351649042\n",
      "Epoch 41/50, iter: 500/3382, mean loss: 0.0065680186398966\n",
      "Epoch 41/50, iter: 600/3382, mean loss: 0.010981480881567087\n",
      "Epoch 41/50, iter: 700/3382, mean loss: 0.0009003064696764085\n",
      "Epoch 41/50, iter: 800/3382, mean loss: 0.00039233234930609486\n",
      "Epoch 41/50, iter: 900/3382, mean loss: 0.0072962201713632525\n",
      "Epoch 41/50, iter: 1000/3382, mean loss: 0.0008363504869863547\n",
      "Epoch 41/50, iter: 1100/3382, mean loss: 0.013148993462469179\n",
      "Epoch 41/50, iter: 1200/3382, mean loss: 0.018807820847187493\n",
      "Epoch 41/50, iter: 1300/3382, mean loss: 0.038115643552086985\n",
      "Epoch 41/50, iter: 1400/3382, mean loss: 0.02462224504776195\n",
      "Epoch 41/50, iter: 1500/3382, mean loss: 0.013921992582693861\n",
      "Epoch 41/50, iter: 1600/3382, mean loss: 0.021588878232925025\n",
      "Epoch 41/50, iter: 1700/3382, mean loss: 0.0035110590066529212\n",
      "Epoch 41/50, iter: 1800/3382, mean loss: 0.015000395680577655\n",
      "Epoch 41/50, iter: 1900/3382, mean loss: 0.08800046858077373\n",
      "Epoch 41/50, iter: 2000/3382, mean loss: 0.004460053384062199\n",
      "Epoch 41/50, iter: 2100/3382, mean loss: 0.017642975576155778\n",
      "Epoch 41/50, iter: 2200/3382, mean loss: 0.03290040275245858\n",
      "Epoch 41/50, iter: 2300/3382, mean loss: 0.013782992934550613\n",
      "Epoch 41/50, iter: 2400/3382, mean loss: 0.0029482812247178815\n",
      "Epoch 41/50, iter: 2500/3382, mean loss: 0.018996905174376053\n",
      "Epoch 41/50, iter: 2600/3382, mean loss: 0.06280578355432542\n",
      "Epoch 41/50, iter: 2700/3382, mean loss: 0.012623066488174467\n",
      "Epoch 41/50, iter: 2800/3382, mean loss: 0.0023291893947210694\n",
      "Epoch 41/50, iter: 2900/3382, mean loss: 0.020405462491302585\n",
      "Epoch 41/50, iter: 3000/3382, mean loss: 0.03763699982180722\n",
      "Epoch 41/50, iter: 3100/3382, mean loss: 0.01448247205009686\n",
      "Epoch 41/50, iter: 3200/3382, mean loss: 0.01170211759139093\n",
      "Epoch 41/50, iter: 3300/3382, mean loss: 0.0034473920571671712\n",
      "Epoch 42/50, iter: 100/3382, mean loss: 0.0026125585025359756\n",
      "Epoch 42/50, iter: 200/3382, mean loss: 0.018813916803049332\n",
      "Epoch 42/50, iter: 300/3382, mean loss: 0.0006409710432098947\n",
      "Epoch 42/50, iter: 400/3382, mean loss: 0.00018405264669851817\n",
      "Epoch 42/50, iter: 500/3382, mean loss: 0.00040803489847700546\n",
      "Epoch 42/50, iter: 600/3382, mean loss: 0.00017973715876436812\n",
      "Epoch 42/50, iter: 700/3382, mean loss: 0.002726818247125351\n",
      "Epoch 42/50, iter: 800/3382, mean loss: 0.005948248296803413\n",
      "Epoch 42/50, iter: 900/3382, mean loss: 0.0001946215742503199\n",
      "Epoch 42/50, iter: 1000/3382, mean loss: 0.008560781703326512\n",
      "Epoch 42/50, iter: 1100/3382, mean loss: 0.01672924920571397\n",
      "Epoch 42/50, iter: 1200/3382, mean loss: 0.06470790536955776\n",
      "Epoch 42/50, iter: 1300/3382, mean loss: 0.016125291149691422\n",
      "Epoch 42/50, iter: 1400/3382, mean loss: 0.021097770061651568\n",
      "Epoch 42/50, iter: 1500/3382, mean loss: 0.017763151551005017\n",
      "Epoch 42/50, iter: 1600/3382, mean loss: 0.027494402612177636\n",
      "Epoch 42/50, iter: 1700/3382, mean loss: 0.0039380323372833455\n",
      "Epoch 42/50, iter: 1800/3382, mean loss: 0.008342306208093824\n",
      "Epoch 42/50, iter: 1900/3382, mean loss: 0.08411818479273642\n",
      "Epoch 42/50, iter: 2000/3382, mean loss: 0.0257236146062278\n",
      "Epoch 42/50, iter: 2100/3382, mean loss: 0.02517015422934911\n",
      "Epoch 42/50, iter: 2200/3382, mean loss: 0.029511629445896973\n",
      "Epoch 42/50, iter: 2300/3382, mean loss: 0.04245968851300702\n",
      "Epoch 42/50, iter: 2400/3382, mean loss: 0.005995225582347317\n",
      "Epoch 42/50, iter: 2500/3382, mean loss: 0.011976050518737616\n",
      "Epoch 42/50, iter: 2600/3382, mean loss: 0.052135328757573055\n",
      "Epoch 42/50, iter: 2700/3382, mean loss: 0.007589843715273865\n",
      "Epoch 42/50, iter: 2800/3382, mean loss: 0.007183647736146739\n",
      "Epoch 42/50, iter: 2900/3382, mean loss: 0.02990135463450617\n",
      "Epoch 42/50, iter: 3000/3382, mean loss: 0.018019649925834217\n",
      "Epoch 42/50, iter: 3100/3382, mean loss: 0.016019364070420358\n",
      "Epoch 42/50, iter: 3200/3382, mean loss: 0.04289924572980098\n",
      "Epoch 42/50, iter: 3300/3382, mean loss: 0.0032492240799267334\n",
      "Epoch 43/50, iter: 100/3382, mean loss: 0.00666586427057247\n",
      "Epoch 43/50, iter: 200/3382, mean loss: 0.040788604433432664\n",
      "Epoch 43/50, iter: 300/3382, mean loss: 0.02589482478625488\n",
      "Epoch 43/50, iter: 400/3382, mean loss: 0.0019365228091388076\n",
      "Epoch 43/50, iter: 500/3382, mean loss: 0.0038935262517606263\n",
      "Epoch 43/50, iter: 600/3382, mean loss: 0.004207183721188201\n",
      "Epoch 43/50, iter: 700/3382, mean loss: 0.002398119515637731\n",
      "Epoch 43/50, iter: 800/3382, mean loss: 0.0014858023076480009\n",
      "Epoch 43/50, iter: 900/3382, mean loss: 0.0022166218368694147\n",
      "Epoch 43/50, iter: 1000/3382, mean loss: 0.0021067655462302425\n",
      "Epoch 43/50, iter: 1100/3382, mean loss: 0.036544032064023464\n",
      "Epoch 43/50, iter: 1200/3382, mean loss: 0.04587787134919821\n",
      "Epoch 43/50, iter: 1300/3382, mean loss: 0.01749775005124995\n",
      "Epoch 43/50, iter: 1400/3382, mean loss: 0.1243098022906727\n",
      "Epoch 43/50, iter: 1500/3382, mean loss: 0.011404459078157706\n",
      "Epoch 43/50, iter: 1600/3382, mean loss: 0.013280423844835347\n",
      "Epoch 43/50, iter: 1700/3382, mean loss: 0.03464516260949761\n",
      "Epoch 43/50, iter: 1800/3382, mean loss: 0.050892987269181164\n",
      "Epoch 43/50, iter: 1900/3382, mean loss: 0.062465623948823816\n",
      "Epoch 43/50, iter: 2000/3382, mean loss: 0.020037200140760873\n",
      "Epoch 43/50, iter: 2100/3382, mean loss: 0.039441773257533515\n",
      "Epoch 43/50, iter: 2200/3382, mean loss: 0.04530428846121936\n",
      "Epoch 43/50, iter: 2300/3382, mean loss: 0.03292751284542316\n",
      "Epoch 43/50, iter: 2400/3382, mean loss: 0.010054662828072552\n",
      "Epoch 43/50, iter: 2500/3382, mean loss: 0.005209540164847332\n",
      "Epoch 43/50, iter: 2600/3382, mean loss: 0.05972252843059156\n",
      "Epoch 43/50, iter: 2700/3382, mean loss: 0.007726435648485647\n",
      "Epoch 43/50, iter: 2800/3382, mean loss: 0.02247691492959319\n",
      "Epoch 43/50, iter: 2900/3382, mean loss: 0.006336166838326669\n",
      "Epoch 43/50, iter: 3000/3382, mean loss: 0.018241837994752076\n",
      "Epoch 43/50, iter: 3100/3382, mean loss: 0.016024115588969358\n",
      "Epoch 43/50, iter: 3200/3382, mean loss: 0.02181906273335439\n",
      "Epoch 43/50, iter: 3300/3382, mean loss: 0.005865321388787912\n",
      "Epoch 44/50, iter: 100/3382, mean loss: 0.0016727532127444533\n",
      "Epoch 44/50, iter: 200/3382, mean loss: 0.020213972751345465\n",
      "Epoch 44/50, iter: 300/3382, mean loss: 0.0003380049492280079\n",
      "Epoch 44/50, iter: 400/3382, mean loss: 9.626614063048323e-05\n",
      "Epoch 44/50, iter: 500/3382, mean loss: 0.00843576207216259\n",
      "Epoch 44/50, iter: 600/3382, mean loss: 0.010468822191054378\n",
      "Epoch 44/50, iter: 700/3382, mean loss: 0.00020030467677422336\n",
      "Epoch 44/50, iter: 800/3382, mean loss: 0.001160572220344065\n",
      "Epoch 44/50, iter: 900/3382, mean loss: 0.00043310411958113803\n",
      "Epoch 44/50, iter: 1000/3382, mean loss: 0.00412566634093789\n",
      "Epoch 44/50, iter: 1100/3382, mean loss: 0.013709367232656788\n",
      "Epoch 44/50, iter: 1200/3382, mean loss: 0.02970573887297398\n",
      "Epoch 44/50, iter: 1300/3382, mean loss: 0.015477462807087719\n",
      "Epoch 44/50, iter: 1400/3382, mean loss: 0.08164852537729292\n",
      "Epoch 44/50, iter: 1500/3382, mean loss: 0.037309127321259086\n",
      "Epoch 44/50, iter: 1600/3382, mean loss: 0.04942951421665047\n",
      "Epoch 44/50, iter: 1700/3382, mean loss: 0.004775416765801452\n",
      "Epoch 44/50, iter: 1800/3382, mean loss: 0.009479298066630868\n",
      "Epoch 44/50, iter: 1900/3382, mean loss: 0.05616705628817389\n",
      "Epoch 44/50, iter: 2000/3382, mean loss: 0.013893911541607941\n",
      "Epoch 44/50, iter: 2100/3382, mean loss: 0.03190175024503027\n",
      "Epoch 44/50, iter: 2200/3382, mean loss: 0.0301722273006353\n",
      "Epoch 44/50, iter: 2300/3382, mean loss: 0.007819315223815338\n",
      "Epoch 44/50, iter: 2400/3382, mean loss: 0.001744049939372516\n",
      "Epoch 44/50, iter: 2500/3382, mean loss: 0.004791372314865043\n",
      "Epoch 44/50, iter: 2600/3382, mean loss: 0.03253364754982638\n",
      "Epoch 44/50, iter: 2700/3382, mean loss: 0.021744921167565892\n",
      "Epoch 44/50, iter: 2800/3382, mean loss: 0.007560794725912281\n",
      "Epoch 44/50, iter: 2900/3382, mean loss: 0.012022844049417251\n",
      "Epoch 44/50, iter: 3000/3382, mean loss: 0.008204291765170452\n",
      "Epoch 44/50, iter: 3100/3382, mean loss: 0.037685125970679356\n",
      "Epoch 44/50, iter: 3200/3382, mean loss: 0.023255383032874805\n",
      "Epoch 44/50, iter: 3300/3382, mean loss: 0.010159974401560348\n",
      "Epoch 45/50, iter: 100/3382, mean loss: 0.003944314780801577\n",
      "Epoch 45/50, iter: 200/3382, mean loss: 0.031622482444377195\n",
      "Epoch 45/50, iter: 300/3382, mean loss: 0.00029244329199361373\n",
      "Epoch 45/50, iter: 400/3382, mean loss: 0.0004749803007956643\n",
      "Epoch 45/50, iter: 500/3382, mean loss: 0.008419337781786744\n",
      "Epoch 45/50, iter: 600/3382, mean loss: 0.0030935333476601557\n",
      "Epoch 45/50, iter: 700/3382, mean loss: 0.000472999716653284\n",
      "Epoch 45/50, iter: 800/3382, mean loss: 0.00025737217165268335\n",
      "Epoch 45/50, iter: 900/3382, mean loss: 0.0013878112368587736\n",
      "Epoch 45/50, iter: 1000/3382, mean loss: 0.022263823795611978\n",
      "Epoch 45/50, iter: 1100/3382, mean loss: 0.02885033152044642\n",
      "Epoch 45/50, iter: 1200/3382, mean loss: 0.027651086494649525\n",
      "Epoch 45/50, iter: 1300/3382, mean loss: 0.01735545603706612\n",
      "Epoch 45/50, iter: 1400/3382, mean loss: 0.042654832293643564\n",
      "Epoch 45/50, iter: 1500/3382, mean loss: 0.01529615606085109\n",
      "Epoch 45/50, iter: 1600/3382, mean loss: 0.014032689820859473\n",
      "Epoch 45/50, iter: 1700/3382, mean loss: 0.0437360596466084\n",
      "Epoch 45/50, iter: 1800/3382, mean loss: 0.018539147612708078\n",
      "Epoch 45/50, iter: 1900/3382, mean loss: 0.07901988962867562\n",
      "Epoch 45/50, iter: 2000/3382, mean loss: 0.010488685637363347\n",
      "Epoch 45/50, iter: 2100/3382, mean loss: 0.023834616588217797\n",
      "Epoch 45/50, iter: 2200/3382, mean loss: 0.02273625144938965\n",
      "Epoch 45/50, iter: 2300/3382, mean loss: 0.0415536802008798\n",
      "Epoch 45/50, iter: 2400/3382, mean loss: 0.020463813753650015\n",
      "Epoch 45/50, iter: 2500/3382, mean loss: 0.00907601074340846\n",
      "Epoch 45/50, iter: 2600/3382, mean loss: 0.07229931693879582\n",
      "Epoch 45/50, iter: 2700/3382, mean loss: 0.013963754709467154\n",
      "Epoch 45/50, iter: 2800/3382, mean loss: 0.006315446968420737\n",
      "Epoch 45/50, iter: 2900/3382, mean loss: 0.012029801570792103\n",
      "Epoch 45/50, iter: 3000/3382, mean loss: 0.02185669582345426\n",
      "Epoch 45/50, iter: 3100/3382, mean loss: 0.008091860423142591\n",
      "Epoch 45/50, iter: 3200/3382, mean loss: 0.015062614154446194\n",
      "Epoch 45/50, iter: 3300/3382, mean loss: 0.01805847503118063\n",
      "Epoch 46/50, iter: 100/3382, mean loss: 0.005018181862588272\n",
      "Epoch 46/50, iter: 200/3382, mean loss: 0.01626781113707768\n",
      "Epoch 46/50, iter: 300/3382, mean loss: 0.004386527591777103\n",
      "Epoch 46/50, iter: 400/3382, mean loss: 0.0001024651717964531\n",
      "Epoch 46/50, iter: 500/3382, mean loss: 0.002765085096250921\n",
      "Epoch 46/50, iter: 600/3382, mean loss: 0.0011816372633132134\n",
      "Epoch 46/50, iter: 700/3382, mean loss: 0.000235368575145678\n",
      "Epoch 46/50, iter: 800/3382, mean loss: 0.0006345254159013436\n",
      "Epoch 46/50, iter: 900/3382, mean loss: 0.005491574467543536\n",
      "Epoch 46/50, iter: 1000/3382, mean loss: 0.0018304375352565926\n",
      "Epoch 46/50, iter: 1100/3382, mean loss: 0.028749272238371936\n",
      "Epoch 46/50, iter: 1200/3382, mean loss: 0.0503346757944286\n",
      "Epoch 46/50, iter: 1300/3382, mean loss: 0.021632281877164664\n",
      "Epoch 46/50, iter: 1400/3382, mean loss: 0.007110438105610015\n",
      "Epoch 46/50, iter: 1500/3382, mean loss: 0.014149232531542566\n",
      "Epoch 46/50, iter: 1600/3382, mean loss: 0.022743422743461892\n",
      "Epoch 46/50, iter: 1700/3382, mean loss: 0.04276194167412239\n",
      "Epoch 46/50, iter: 1800/3382, mean loss: 0.019894340978073542\n",
      "Epoch 46/50, iter: 1900/3382, mean loss: 0.07334711455610612\n",
      "Epoch 46/50, iter: 2000/3382, mean loss: 0.007984359801733518\n",
      "Epoch 46/50, iter: 2100/3382, mean loss: 0.020844016414746064\n",
      "Epoch 46/50, iter: 2200/3382, mean loss: 0.03006499519197707\n",
      "Epoch 46/50, iter: 2300/3382, mean loss: 0.01482781143808591\n",
      "Epoch 46/50, iter: 2400/3382, mean loss: 0.007883937411338913\n",
      "Epoch 46/50, iter: 2500/3382, mean loss: 0.015847049035046867\n",
      "Epoch 46/50, iter: 2600/3382, mean loss: 0.033887338138206505\n",
      "Epoch 46/50, iter: 2700/3382, mean loss: 0.0029996277392452695\n",
      "Epoch 46/50, iter: 2800/3382, mean loss: 0.02438163936939251\n",
      "Epoch 46/50, iter: 2900/3382, mean loss: 0.0033205947307338945\n",
      "Epoch 46/50, iter: 3000/3382, mean loss: 0.0072251521466523624\n",
      "Epoch 46/50, iter: 3100/3382, mean loss: 0.028848054007474\n",
      "Epoch 46/50, iter: 3200/3382, mean loss: 0.0022508343023882917\n",
      "Epoch 46/50, iter: 3300/3382, mean loss: 0.007425103645060283\n",
      "Epoch 47/50, iter: 100/3382, mean loss: 0.004160854652693189\n",
      "Epoch 47/50, iter: 200/3382, mean loss: 0.028492486308665157\n",
      "Epoch 47/50, iter: 300/3382, mean loss: 0.0015637166734843078\n",
      "Epoch 47/50, iter: 400/3382, mean loss: 0.00019166150308304707\n",
      "Epoch 47/50, iter: 500/3382, mean loss: 0.00028830344837825093\n",
      "Epoch 47/50, iter: 600/3382, mean loss: 0.0021619524350748875\n",
      "Epoch 47/50, iter: 700/3382, mean loss: 0.0006947289145223934\n",
      "Epoch 47/50, iter: 800/3382, mean loss: 0.02376037316352754\n",
      "Epoch 47/50, iter: 900/3382, mean loss: 0.0002837790906654547\n",
      "Epoch 47/50, iter: 1000/3382, mean loss: 0.014201761652027222\n",
      "Epoch 47/50, iter: 1100/3382, mean loss: 0.020045040385549127\n",
      "Epoch 47/50, iter: 1200/3382, mean loss: 0.038296497505032966\n",
      "Epoch 47/50, iter: 1300/3382, mean loss: 0.02374855876098941\n",
      "Epoch 47/50, iter: 1400/3382, mean loss: 0.023208143336212038\n",
      "Epoch 47/50, iter: 1500/3382, mean loss: 0.006581171658584104\n",
      "Epoch 47/50, iter: 1600/3382, mean loss: 0.04944319129387001\n",
      "Epoch 47/50, iter: 1700/3382, mean loss: 0.01754770814402825\n",
      "Epoch 47/50, iter: 1800/3382, mean loss: 0.008418584995181675\n",
      "Epoch 47/50, iter: 1900/3382, mean loss: 0.05813542145722913\n",
      "Epoch 47/50, iter: 2000/3382, mean loss: 0.006722305278675549\n",
      "Epoch 47/50, iter: 2100/3382, mean loss: 0.01531813155302057\n",
      "Epoch 47/50, iter: 2200/3382, mean loss: 0.028314001074908005\n",
      "Epoch 47/50, iter: 2300/3382, mean loss: 0.006330490294924012\n",
      "Epoch 47/50, iter: 2400/3382, mean loss: 0.0028679639196995056\n",
      "Epoch 47/50, iter: 2500/3382, mean loss: 0.024393588958773228\n",
      "Epoch 47/50, iter: 2600/3382, mean loss: 0.07944680762814378\n",
      "Epoch 47/50, iter: 2700/3382, mean loss: 0.010423153699005355\n",
      "Epoch 47/50, iter: 2800/3382, mean loss: 0.020248253712143907\n",
      "Epoch 47/50, iter: 2900/3382, mean loss: 0.01450904210414457\n",
      "Epoch 47/50, iter: 3000/3382, mean loss: 0.01466825182935839\n",
      "Epoch 47/50, iter: 3100/3382, mean loss: 0.007677604014681556\n",
      "Epoch 47/50, iter: 3200/3382, mean loss: 0.018963649993600916\n",
      "Epoch 47/50, iter: 3300/3382, mean loss: 0.002629676812126327\n",
      "Epoch 48/50, iter: 100/3382, mean loss: 0.011318480946978475\n",
      "Epoch 48/50, iter: 200/3382, mean loss: 0.017532172439666666\n",
      "Epoch 48/50, iter: 300/3382, mean loss: 0.00017704213262241807\n",
      "Epoch 48/50, iter: 400/3382, mean loss: 0.0005442635288820697\n",
      "Epoch 48/50, iter: 500/3382, mean loss: 0.0006831163871475354\n",
      "Epoch 48/50, iter: 600/3382, mean loss: 0.0028778247246870237\n",
      "Epoch 48/50, iter: 700/3382, mean loss: 0.0036810030202482835\n",
      "Epoch 48/50, iter: 800/3382, mean loss: 0.00013930817673930563\n",
      "Epoch 48/50, iter: 900/3382, mean loss: 0.000734420185554292\n",
      "Epoch 48/50, iter: 1000/3382, mean loss: 0.006121603956362059\n",
      "Epoch 48/50, iter: 1100/3382, mean loss: 0.025214430635708707\n",
      "Epoch 48/50, iter: 1200/3382, mean loss: 0.022898213843819695\n",
      "Epoch 48/50, iter: 1300/3382, mean loss: 0.028325400286343873\n",
      "Epoch 48/50, iter: 1400/3382, mean loss: 0.030907791409541367\n",
      "Epoch 48/50, iter: 1500/3382, mean loss: 0.017611597427314295\n",
      "Epoch 48/50, iter: 1600/3382, mean loss: 0.0071776610248911864\n",
      "Epoch 48/50, iter: 1700/3382, mean loss: 0.0250194453425879\n",
      "Epoch 48/50, iter: 1800/3382, mean loss: 0.02378593260789785\n",
      "Epoch 48/50, iter: 1900/3382, mean loss: 0.07123283298760107\n",
      "Epoch 48/50, iter: 2000/3382, mean loss: 0.017870066759494777\n",
      "Epoch 48/50, iter: 2100/3382, mean loss: 0.014391323276549102\n",
      "Epoch 48/50, iter: 2200/3382, mean loss: 0.03873028232616019\n",
      "Epoch 48/50, iter: 2300/3382, mean loss: 0.027804467246320783\n",
      "Epoch 48/50, iter: 2400/3382, mean loss: 0.0027381828321247424\n",
      "Epoch 48/50, iter: 2500/3382, mean loss: 0.0019825009648876345\n",
      "Epoch 48/50, iter: 2600/3382, mean loss: 0.05638455923822953\n",
      "Epoch 48/50, iter: 2700/3382, mean loss: 0.010376580418470099\n",
      "Epoch 48/50, iter: 2800/3382, mean loss: 0.014814722004969312\n",
      "Epoch 48/50, iter: 2900/3382, mean loss: 0.013124360696030095\n",
      "Epoch 48/50, iter: 3000/3382, mean loss: 0.024214794733986765\n",
      "Epoch 48/50, iter: 3100/3382, mean loss: 0.019665568748502872\n",
      "Epoch 48/50, iter: 3200/3382, mean loss: 0.005734205159428534\n",
      "Epoch 48/50, iter: 3300/3382, mean loss: 0.006691440887261848\n",
      "Epoch 49/50, iter: 100/3382, mean loss: 0.002733001218945006\n",
      "Epoch 49/50, iter: 200/3382, mean loss: 0.03368928493066704\n",
      "Epoch 49/50, iter: 300/3382, mean loss: 0.0015547579994671778\n",
      "Epoch 49/50, iter: 400/3382, mean loss: 0.006110274986337565\n",
      "Epoch 49/50, iter: 500/3382, mean loss: 0.0030451540875315077\n",
      "Epoch 49/50, iter: 600/3382, mean loss: 0.001654099221143781\n",
      "Epoch 49/50, iter: 700/3382, mean loss: 0.0017297675504352838\n",
      "Epoch 49/50, iter: 800/3382, mean loss: 0.005897308767936061\n",
      "Epoch 49/50, iter: 900/3382, mean loss: 0.000248660629714621\n",
      "Epoch 49/50, iter: 1000/3382, mean loss: 0.0025570386915233457\n",
      "Epoch 49/50, iter: 1100/3382, mean loss: 0.004644284881687888\n",
      "Epoch 49/50, iter: 1200/3382, mean loss: 0.040656555929376524\n",
      "Epoch 49/50, iter: 1300/3382, mean loss: 0.02207335952309343\n",
      "Epoch 49/50, iter: 1400/3382, mean loss: 0.016245911255703512\n",
      "Epoch 49/50, iter: 1500/3382, mean loss: 0.041135591076900936\n",
      "Epoch 49/50, iter: 1600/3382, mean loss: 0.04472582705410776\n",
      "Epoch 49/50, iter: 1700/3382, mean loss: 0.009698798709680717\n",
      "Epoch 49/50, iter: 1800/3382, mean loss: 0.022894986643940952\n",
      "Epoch 49/50, iter: 1900/3382, mean loss: 0.06646385674275092\n",
      "Epoch 49/50, iter: 2000/3382, mean loss: 0.005688331139840308\n",
      "Epoch 49/50, iter: 2100/3382, mean loss: 0.027932173945654563\n",
      "Epoch 49/50, iter: 2200/3382, mean loss: 0.016821122577934843\n",
      "Epoch 49/50, iter: 2300/3382, mean loss: 0.0025456695630060367\n",
      "Epoch 49/50, iter: 2400/3382, mean loss: 0.011338909011033316\n",
      "Epoch 49/50, iter: 2500/3382, mean loss: 0.0037847174518956805\n",
      "Epoch 49/50, iter: 2600/3382, mean loss: 0.056419132558621285\n",
      "Epoch 49/50, iter: 2700/3382, mean loss: 0.020823676213585676\n",
      "Epoch 49/50, iter: 2800/3382, mean loss: 0.022124065006123423\n",
      "Epoch 49/50, iter: 2900/3382, mean loss: 0.03264795915067559\n",
      "Epoch 49/50, iter: 3000/3382, mean loss: 0.007068473775136503\n",
      "Epoch 49/50, iter: 3100/3382, mean loss: 0.025248989208714007\n",
      "Epoch 49/50, iter: 3200/3382, mean loss: 0.0026148573195810343\n",
      "Epoch 49/50, iter: 3300/3382, mean loss: 0.01581844788506846\n",
      "Epoch 50/50, iter: 100/3382, mean loss: 0.026119722376079686\n",
      "Epoch 50/50, iter: 200/3382, mean loss: 0.006789509151129671\n",
      "Epoch 50/50, iter: 300/3382, mean loss: 0.010764960553787298\n",
      "Epoch 50/50, iter: 400/3382, mean loss: 0.00027366677783373204\n",
      "Epoch 50/50, iter: 500/3382, mean loss: 0.006642877086077696\n",
      "Epoch 50/50, iter: 600/3382, mean loss: 0.009261526324840546\n",
      "Epoch 50/50, iter: 700/3382, mean loss: 0.00042508052553529295\n",
      "Epoch 50/50, iter: 800/3382, mean loss: 0.0007029533419854772\n",
      "Epoch 50/50, iter: 900/3382, mean loss: 0.008807419072376844\n",
      "Epoch 50/50, iter: 1000/3382, mean loss: 0.0019922853786254534\n",
      "Epoch 50/50, iter: 1100/3382, mean loss: 0.02332634377880737\n",
      "Epoch 50/50, iter: 1200/3382, mean loss: 0.035292817272289556\n",
      "Epoch 50/50, iter: 1300/3382, mean loss: 0.02984230228648542\n",
      "Epoch 50/50, iter: 1400/3382, mean loss: 0.01653044877141184\n",
      "Epoch 50/50, iter: 1500/3382, mean loss: 0.015561627775416228\n",
      "Epoch 50/50, iter: 1600/3382, mean loss: 0.31746464741790653\n",
      "Epoch 50/50, iter: 1700/3382, mean loss: 0.01448680372857325\n",
      "Epoch 50/50, iter: 1800/3382, mean loss: 0.05975200269688198\n",
      "Epoch 50/50, iter: 1900/3382, mean loss: 0.0826425371890295\n",
      "Epoch 50/50, iter: 2000/3382, mean loss: 0.0034625278670471714\n",
      "Epoch 50/50, iter: 2100/3382, mean loss: 0.049098094122019056\n",
      "Epoch 50/50, iter: 2200/3382, mean loss: 0.007118510366039779\n",
      "Epoch 50/50, iter: 2300/3382, mean loss: 0.011547569925628132\n",
      "Epoch 50/50, iter: 2400/3382, mean loss: 0.0021928541889830555\n",
      "Epoch 50/50, iter: 2500/3382, mean loss: 0.002404326190730828\n",
      "Epoch 50/50, iter: 2600/3382, mean loss: 0.05691330853628546\n",
      "Epoch 50/50, iter: 2700/3382, mean loss: 0.005375955991585713\n",
      "Epoch 50/50, iter: 2800/3382, mean loss: 0.001950512709666583\n",
      "Epoch 50/50, iter: 2900/3382, mean loss: 0.030563926106668724\n",
      "Epoch 50/50, iter: 3000/3382, mean loss: 0.021238678756237094\n",
      "Epoch 50/50, iter: 3100/3382, mean loss: 0.012157261764915397\n",
      "Epoch 50/50, iter: 3200/3382, mean loss: 0.003484793890517075\n",
      "Epoch 50/50, iter: 3300/3382, mean loss: 0.01371725402094679\n"
     ]
    }
   ],
   "source": [
    "use_wandb = True\n",
    "\n",
    "lr = 0.0005\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "epochs_cnt = 50\n",
    "embeddings = \"random\"\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "task = \"text2company\" # \"text2sentiment\"\n",
    "use_company_info = True\n",
    "preprocessing = \"tutorial\"\n",
    "\n",
    "get_dataloaders = get_twit_company_dataloaders if task == \"text2company\" else\\\n",
    "get_twit_sentiment_dataloaders if not use_company_info else get_twit_company_sentiment_dataloaders\n",
    "\n",
    "dataset_train, dataloader_train, dataset_test, dataloader_test = get_twit_company_dataloaders(embedding_dim=embedding_size, embedding=embeddings, preprocessing=preprocessing)\n",
    "\n",
    "model = LSTMTwitClassifier(4, embedding_dim=embedding_size, hidden_dim=hidden_size, dropout=dropout, lstm_layers=lstm_layers)\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project=task + '_twit_classification', entity='ars860')\n",
    "\n",
    "    config = wandb.config\n",
    "    config.loss = \"BCE\"\n",
    "    config.optimizer = \"Adam\"\n",
    "    config.learning_rate = lr\n",
    "    config.hidden_size = hidden_size\n",
    "    config.embedding_size = embedding_size\n",
    "    config.embeddings = embeddings\n",
    "    config.epochs = epochs_cnt\n",
    "    config.dropout = dropout\n",
    "    config.lstm_layers = lstm_layers\n",
    "    config.stem = \"snowballstemmer\"\n",
    "    config.preprocessing = preprocessing\n",
    "\n",
    "    if task == \"text2sentiment\":\n",
    "        config.use_company_info = use_company_info\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def loss_on_test():\n",
    "    correct = 0\n",
    "    losses = np.zeros(len(dataloader_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (*args, target) in enumerate(dataloader_test):\n",
    "            prediction = model(*args)\n",
    "            prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "            losses[i] = F.binary_cross_entropy(prediction, target.view(-1))\n",
    "            if torch.argmax(prediction) == torch.argmax(target):\n",
    "                correct += 1\n",
    "\n",
    "            # predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "    model.train()\n",
    "    if use_wandb:\n",
    "        wandb.log({\"test_loss\": np.mean(losses), \"test_accuracy\": correct / len(dataloader_test)})\n",
    "\n",
    "losses = np.empty(100)\n",
    "model.train()\n",
    "for epoch in range(epochs_cnt):\n",
    "    epoch_loss = np.zeros(len(dataloader_train))\n",
    "\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        model.zero_grad()\n",
    "\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        loss = criterion(prediction, target.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        losses[i % 100] = loss\n",
    "        epoch_loss[i] = loss\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs_cnt}, iter: {i + 1}/{len(dataloader_train)}, mean loss: {np.mean(losses)}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"loss\": np.mean(losses)})\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "        loss_on_test()\n",
    "\n",
    "# [model.get_word_embedding(word) for word in \"hello_world\".split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on train\n",
      "Iter: 0/3382\n",
      "Iter: 100/3382\n",
      "Iter: 200/3382\n",
      "Iter: 300/3382\n",
      "Iter: 400/3382\n",
      "Iter: 500/3382\n",
      "Iter: 600/3382\n",
      "Iter: 700/3382\n",
      "Iter: 800/3382\n",
      "Iter: 900/3382\n",
      "Iter: 1000/3382\n",
      "Iter: 1100/3382\n",
      "Iter: 1200/3382\n",
      "Iter: 1300/3382\n",
      "Iter: 1400/3382\n",
      "Iter: 1500/3382\n",
      "Iter: 1600/3382\n",
      "Iter: 1700/3382\n",
      "Iter: 1800/3382\n",
      "Iter: 1900/3382\n",
      "Iter: 2000/3382\n",
      "Iter: 2100/3382\n",
      "Iter: 2200/3382\n",
      "Iter: 2300/3382\n",
      "Iter: 2400/3382\n",
      "Iter: 2500/3382\n",
      "Iter: 2600/3382\n",
      "Iter: 2700/3382\n",
      "Iter: 2800/3382\n",
      "Iter: 2900/3382\n",
      "Iter: 3000/3382\n",
      "Iter: 3100/3382\n",
      "Iter: 3200/3382\n",
      "Iter: 3300/3382\n",
      "Accuracy 0.9934949733885275\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 16272<br/>Program ended successfully."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "499b70be13bc4a998829e20fe0086e14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211020_160846-2o2x3xk4\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211020_160846-2o2x3xk4\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>0.01372</td></tr><tr><td>_runtime</td><td>1339</td></tr><tr><td>_timestamp</td><td>1634736665</td></tr><tr><td>_step</td><td>1749</td></tr><tr><td>epoch_loss</td><td>0.02678</td></tr><tr><td>test_loss</td><td>0.55504</td></tr><tr><td>test_accuracy</td><td>0.78402</td></tr><tr><td>train_accuracy</td><td>0.99349</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>▁▁▁▁▄█▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▇██▇▆▇▆▇▅▅▅▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂</td></tr><tr><td>test_loss</td><td>██▇▇▆▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇▇█▇▇▇█████████▇███████</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">easy-hill-34</strong>: <a href=\"https://wandb.ai/ars860/text2company_twit_classification/runs/2o2x3xk4\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification/runs/2o2x3xk4</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Testing on train\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_train)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_train)}\")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.run.summary.train_accuracy = correct / len(dataloader_train)\n",
    "    wandb.run.summary.classified_as = {\n",
    "        \"apple\": predictions_cnt[0],\n",
    "        \"google\": predictions_cnt[1],\n",
    "        \"microsoft\": predictions_cnt[2],\n",
    "        \"twitter\": predictions_cnt[3]\n",
    "    }\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test\n",
      "Iter: 0/338\n",
      "Iter: 100/338\n",
      "Iter: 200/338\n",
      "Iter: 300/338\n",
      "Accuracy 0.7840236686390533\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_test):\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}