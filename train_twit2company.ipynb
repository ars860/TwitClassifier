{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset import get_twit_company_dataloaders, split_sentence\n",
    "from model import LSTMTwitClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# text, label = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://t.co/48emAEID \n",
      "http://t.co/Izh7KaiU \n",
      "http://t.co/e5ClGzsI \n",
      "http://t.co/18xg3ivo! \n",
      "ĞŸĞ¾Ğ¸ÑĞº Ğ¾Ñ‚ \n",
      "ã‚µãƒ ã‚¹ãƒ³é›»å­ã®ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³æ–°æ©Ÿç¨®ã€Œã‚®ãƒ£ãƒ©ã‚¯ã‚·ãƒ¼ãƒ»ãƒã‚¯ã‚µã‚¹ã€ã€ã‚°ãƒ¼ã‚°ãƒ«ã®åŸºæœ¬ã‚½ãƒ•ãƒˆï¼ˆï¼¯ï¼³ï¼‰ã€Œã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã€æœ€æ–°ç‰ˆã‚’æ­è¼‰ã€‚ã€Œã‚¯ãƒ©ã‚¦ãƒ‰ã€æ´»ç”¨ã€éŸ³å£°èªè­˜ã‚„ã‚«ãƒ¡ãƒ©ã®æ©Ÿèƒ½ã‚‚å‘ä¸Šã•ã›ãŸæˆ¦ç•¥ãƒ¢ãƒ‡ãƒ« \n",
      "ĞĞ¾Ğ²Ğ¸Ñ‚Ğµ \n",
      "Ø§Ø¹Ø±Ù Ø§Ù„ÙƒØ«ÙŠØ± Ø¹Ù† Ù†Ø¸Ø§Ù… Ø§ÙŠØ³ÙƒØ±ÙŠÙ… Ø³Ø§Ù†Ø¯ÙˆÙŠØªØ´ http://t.co/Fzjd2Zx1 \n",
      "çœ‹è¦‹ \n",
      "Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙŠØ¯ .. Ùˆ Ø¬Ù‡Ø§Ø² Ø¬Ø¯ÙŠØ¯ Ø´ÙƒØ±Ø§Ù‹ Ø¬Ø²ÙŠÙ„Ø§Ù‹ \n",
      "Ø§ÙŠØ³ÙƒØ±ÙŠÙ… Ø³Ø§Ù†Ø¯ÙˆÙŠØ´ØŒ Ø¹Ø³Ù„ØŒ Ø²Ù†Ø¬Ø¨ÙŠÙ„ .. Ù…Ø´ÙƒÙ„Ø© Ù…Ù† ÙƒØ«Ø± Ø§Ù„Ù…Ø³Ù…ÙŠØ§Øª Ø§Ø­Ø³Ù‡Ù… Ù…Ø³ÙˆÙŠÙ† Ù…Ù‚Ø§Ø¯ÙŠØ± Ù…Ø¨ Ø§Ù†Ø¸Ù…Ø© !! ğŸ˜  \n",
      "Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¹Ø¬ÙŠØ¨   \n",
      "Ğ¯ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ÑÑĞµĞ½ :) \n",
      "ä»Šæ—¥ç™ºè¡¨ã ã£ãŸï¼¾ï¾›ï¼¾ã€€ \n",
      "ÙŠØ¨Ø¯Ùˆ Ø§Ù† Ø·ÙØ±Ø© Ø§Ù„Ø§Ø¬Ù‡Ø²Ø© Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø³ØªÙƒÙˆÙ† Ø¨Ù‚ÙŠØ§Ø¯Ø© Ù…ÙˆØªÙˆØ±ÙˆÙ„Ø§ ØŒØŒ Ù„Ø§Ø³ÙŠÙ… Ø¨Ø¹Ø¯ Ø§Ø³ØªØ­ÙˆØ§Ø° Ù‚ÙˆÙ‚Ù„ Ø¹Ù„ÙŠÙ‡Ø§.   \n",
      "é¡”èªè­˜ãƒ­ãƒƒã‚¯è§£é™¤å¤±æ•—ã—ã¦ã‚‹ãƒ»ãƒ»ãƒ»ãƒ‡ãƒ¢ã§å¤±æ•—ã—ã¡ã‚ƒã£ã¦ã„ã„ã®ã‹ï¼Ÿ \n",
      "ÎœÎµ ÏƒÏ…Î³Ï‡Î¹ÏƒÎµÏ‚ \n",
      "ãƒ‡ãƒ•ã‚©ã§ãƒ‡ãƒ¼ã‚¿é€šä¿¡åˆ¶å¾¡ï¼Ÿã€€\n",
      "http://t.co/gAPEyL5N \n",
      "http://t.co/J3p3KYHf \n",
      "http://t.co/h1IH7FN6 Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª ØªÙ‚ÙˆÙ… Ø¨ØªØ·ÙˆÙŠØ± ØªÙ‚Ù†ÙŠØ© ØªÙ…ÙƒÙ†Ùƒ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙŠØ¯Ùƒ ÙƒÙ‡Ø§ØªÙ  \n",
      "http://t.co/ONI0JX8B \n",
      "http://t.co/JVidt6U4 \n",
      "ĞĞ° ÑĞ°Ğ¹Ñ‚Ğµ \n",
      "â˜¼ \n",
      "ĞĞ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ñ‚Ğ²Ğ¸Ñ‚Ñ‚ĞµÑ€ÑĞ½Ğ¸Ğ½ ĞºĞ°Ğº Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ² Ñ‚Ğ¾Ğ»Ğ¿Ñƒ ÑÑ‚Ñ€ĞµĞ¼Ğ¸Ñ‚ÑŒÑÑ Ñ‚ÑƒÑ‚ Ğ¶Ğµ ĞºĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¿Ğ¾Ğ¿Ğ°ÑÑ‚ÑŒ Ğ² \n",
      "Ğ”Ğ¾Ğ±Ñ€Ğ¾Ğµ ÑƒÑ‚Ñ€Ğ¾ \n",
      "ã€\n",
      "ãªã«ã‚„ã‚‰ãƒ•ã‚©ãƒ­ãƒ¼åˆ¶é™ã«å¼•ã£æ›ã‹ã£ãŸã‚ˆã†ã§ã™â€¦ã‚‚ã£ã¨ãƒ•ã‚©ãƒ­ã‚¢ãƒ¼ã‚’å¢—ã‚„ã•ãªãã¡ã‚ƒâ™ªã€€\n",
      "ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ã‚’åˆ©ç”¨ã—ã¦æ„Ÿè¬ã®æ°—æŒã¡ã¨ã¨ã‚‚ã«ç´„ï¼’ï¼ï¼ï¼å††ãŒæŒ¯ã‚Šè¾¼ã¾ã‚Œç¶šã‘ã‚‹æ–¹æ³•â†’ï½ºï½ºâ†’ http://t.co/TyjUGsnQ â†ï½ºï½ºâ† :) \n",
      "Ø±Ù‚Ù… Ø§Ù„ÙÙ„Ùˆ ÙˆØ§Ù„ÙÙ„ÙˆØ±Ø² ÙˆØ§Ù„ØªÙˆÙŠØªØ§Øª  Ù„Ù„Ø¨ÙŠØ¹ Ù„Ø§Ø¹Ù„Ù‰ Ø³Ø¹Ø± \n",
      "Ù‚Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ù„Ø´Ø±ÙƒØ© \n",
      "Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¼ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ \n",
      "Ù†ÙØ³ÙŠ ÙŠÙˆÙ… ÙŠØ¹Ø¯ÙŠ Ø¹Ù„ÙŠ ØªÙˆÙŠØªØ± Ù…Ù† ØºÙŠØ± Ù…Ø´Ø§ÙƒÙ„ ÙÙ†ÙŠØ© \n",
      "ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼æ¤œç´¢ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-d394c1dc3791>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m         \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtxt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprediction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\acady\\learning\\sma\\twit_classifier\\model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;31m# embedded = self._get_sentence_embedding(sentence)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\acady\\learning\\sma\\twit_classifier\\model.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;31m# embedded = self._get_sentence_embedding(sentence)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\212.5284.44\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\212.5284.44\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "use_wandb = False\n",
    "\n",
    "lr = 0.0005\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "epochs_cnt = 50\n",
    "embeddings = \"word2vec\"\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "\n",
    "dataset_train, dataloader_train, dataset_test, dataloader_test = get_twit_company_dataloaders(embedding_dim=embedding_size, embedding=embeddings)\n",
    "\n",
    "model = LSTMTwitClassifier(4, embedding_dim=embedding_size, hidden_dim=hidden_size, dropout=dropout, lstm_layers=lstm_layers)\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project='twit_classification', entity='ars860')\n",
    "\n",
    "    config = wandb.config\n",
    "    config.loss = \"BCE\"\n",
    "    config.optimizer = \"Adam\"\n",
    "    config.learning_rate = lr\n",
    "    config.hidden_size = hidden_size\n",
    "    config.embedding_size = embedding_size\n",
    "    config.embeddings = embeddings\n",
    "    config.epochs = epochs_cnt\n",
    "    config.dropout = dropout\n",
    "    config.lstm_layers = lstm_layers\n",
    "    config.stem = \"snowballstemmer\"\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def loss_on_test():\n",
    "    correct = 0\n",
    "    losses = np.zeros(len(dataloader_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (txt, company) in enumerate(dataloader_test):\n",
    "            prediction = model(txt)\n",
    "            prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "            losses[i] = F.binary_cross_entropy(prediction, company.view(-1))\n",
    "            if torch.argmax(prediction) == torch.argmax(company):\n",
    "                correct += 1\n",
    "\n",
    "            # predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "    model.train()\n",
    "    if use_wandb:\n",
    "        wandb.log({\"test_loss\": np.mean(losses), \"test_accuracy\": correct / len(dataloader_test)})\n",
    "\n",
    "losses = np.empty(100)\n",
    "model.train()\n",
    "for epoch in range(epochs_cnt):\n",
    "    epoch_loss = np.zeros(len(dataloader_train))\n",
    "\n",
    "    for i, (txt, company) in enumerate(dataloader_train):\n",
    "        model.zero_grad()\n",
    "\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        loss = criterion(prediction, company.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        losses[i % 100] = loss\n",
    "        epoch_loss[i] = loss\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs_cnt}, iter: {i + 1}/{len(dataloader_train)}, mean loss: {np.mean(losses)}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"loss\": np.mean(losses)})\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "        loss_on_test()\n",
    "\n",
    "# [model.get_word_embedding(word) for word in \"hello_world\".split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on train\n",
      "Iter: 0/3382\n",
      "Iter: 100/3382\n",
      "Iter: 200/3382\n",
      "Iter: 300/3382\n",
      "Iter: 400/3382\n",
      "Iter: 500/3382\n",
      "Iter: 600/3382\n",
      "Iter: 700/3382\n",
      "Iter: 800/3382\n",
      "Iter: 900/3382\n",
      "Iter: 1000/3382\n",
      "Iter: 1100/3382\n",
      "Iter: 1200/3382\n",
      "Iter: 1300/3382\n",
      "Iter: 1400/3382\n",
      "Iter: 1500/3382\n",
      "Iter: 1600/3382\n",
      "Iter: 1700/3382\n",
      "Iter: 1800/3382\n",
      "Iter: 1900/3382\n",
      "Iter: 2000/3382\n",
      "Iter: 2100/3382\n",
      "Iter: 2200/3382\n",
      "Iter: 2300/3382\n",
      "Iter: 2400/3382\n",
      "Iter: 2500/3382\n",
      "Iter: 2600/3382\n",
      "Iter: 2700/3382\n",
      "Iter: 2800/3382\n",
      "Iter: 2900/3382\n",
      "Iter: 3000/3382\n",
      "Iter: 3100/3382\n",
      "Iter: 3200/3382\n",
      "Iter: 3300/3382\n",
      "Accuracy 0.9911295091661738\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 13152<br/>Program ended successfully."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2062f60bff854a4fba741f277f171156"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_002819-19ohh73m\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211010_002819-19ohh73m\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>0.00455</td></tr><tr><td>_runtime</td><td>1582</td></tr><tr><td>_timestamp</td><td>1633816481</td></tr><tr><td>_step</td><td>1749</td></tr><tr><td>epoch_loss</td><td>0.01621</td></tr><tr><td>test_loss</td><td>0.40269</td></tr><tr><td>test_accuracy</td><td>0.81065</td></tr><tr><td>train_accuracy</td><td>0.99113</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>â–â–â–â–â–…â–ˆâ–â–â–â–‚â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>_runtime</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch_loss</td><td>â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–â–â–â–â–â–â–â–ƒâ–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">devout-dream-31</strong>: <a href=\"https://wandb.ai/ars860/twit_classification/runs/19ohh73m\" target=\"_blank\">https://wandb.ai/ars860/twit_classification/runs/19ohh73m</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Testing on train\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (txt, company) in enumerate(dataloader_train):\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(company):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_train)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_train)}\")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.run.summary.train_accuracy = correct / len(dataloader_train)\n",
    "    wandb.run.summary.classified_as = {\n",
    "        \"apple\": predictions_cnt[0],\n",
    "        \"google\": predictions_cnt[1],\n",
    "        \"microsoft\": predictions_cnt[2],\n",
    "        \"twitter\": predictions_cnt[3]\n",
    "    }\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test\n",
      "Iter: 0/338\n",
      "Iter: 100/338\n",
      "Iter: 200/338\n",
      "Iter: 300/338\n",
      "Accuracy 0.8106508875739645\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (txt, company) in enumerate(dataloader_test):\n",
    "        prediction = model(txt)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(company):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}