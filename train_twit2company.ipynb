{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset import get_twit_company_dataloaders, get_twit_sentiment_dataloaders, get_twit_company_sentiment_dataloaders\n",
    "from model import LSTMTwitClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# text, label = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ignored due to unreadability: http://t.co/48emAEID \n",
      "Tweet ignored due to unreadability: http://t.co/Izh7KaiU \n",
      "Tweet ignored due to unreadability: http://t.co/e5ClGzsI \n",
      "Tweet ignored due to unreadability: http://t.co/18xg3ivo! \n",
      "Tweet ignored due to unreadability: Поиск от \n",
      "Tweet ignored due to unreadability: サムスン電子のスマートフォン新機種「ギャラクシー・ネクサス」、グーグルの基本ソフト（ＯＳ）「アンドロイド」最新版を搭載。「クラウド」活用、音声認識やカメラの機能も向上させた戦略モデル \n",
      "Tweet ignored due to unreadability: Новите \n",
      "Tweet ignored due to unreadability: اعرف الكثير عن نظام ايسكريم ساندويتش http://t.co/Fzjd2Zx1 \n",
      "Tweet ignored due to unreadability: 看見 \n",
      "Tweet ignored due to unreadability: نظام جديد .. و جهاز جديد شكراً جزيلاً \n",
      "Tweet ignored due to unreadability: ايسكريم ساندويش، عسل، زنجبيل .. مشكلة من كثر المسميات احسهم مسوين مقادير مب انظمة !! 😝  \n",
      "Tweet ignored due to unreadability: الجهاز الجديد عجيب   \n",
      "Tweet ignored due to unreadability: Я немного потрясен :) \n",
      "Tweet ignored due to unreadability: 今日発表だった＾ﾛ＾　 \n",
      "Tweet ignored due to unreadability: يبدو ان طفرة الاجهزة الالكترونية القادمة ستكون بقيادة موتورولا ،، لاسيم بعد استحواذ قوقل عليها.   \n",
      "Tweet ignored due to unreadability: 顔認識ロック解除失敗してる・・・デモで失敗しちゃっていいのか？ \n",
      "Tweet ignored due to unreadability: Με συγχισες \n",
      "Tweet ignored due to unreadability: デフォでデータ通信制御？　\n",
      "Tweet ignored due to unreadability: http://t.co/gAPEyL5N \n",
      "Tweet ignored due to unreadability: http://t.co/J3p3KYHf \n",
      "Tweet ignored due to unreadability: http://t.co/h1IH7FN6 مايكروسوفت تقوم بتطوير تقنية تمكنك من استخدام يدك كهاتف  \n",
      "Tweet ignored due to unreadability: http://t.co/ONI0JX8B \n",
      "Tweet ignored due to unreadability: http://t.co/JVidt6U4 \n",
      "Tweet ignored due to unreadability: На сайте \n",
      "Tweet ignored due to unreadability: ☼ \n",
      "Tweet ignored due to unreadability: Настоящий твиттерянин как только попадает в толпу стремиться тут же как можно быстрее попасть в \n",
      "Tweet ignored due to unreadability: Доброе утро \n",
      "Tweet ignored due to unreadability: 【\n",
      "Tweet ignored due to unreadability: なにやらフォロー制限に引っ掛かったようです…もっとフォロアーを増やさなくちゃ♪　\n",
      "Tweet ignored due to unreadability: ツイッターを利用して感謝の気持ちとともに約２０００円が振り込まれ続ける方法→ｺｺ→ http://t.co/TyjUGsnQ ←ｺｺ← :) \n",
      "Tweet ignored due to unreadability: رقم الفلو والفلورز والتويتات  للبيع لاعلى سعر \n",
      "Tweet ignored due to unreadability: http://t.co/48emAEID \n",
      "Tweet ignored due to unreadability: http://t.co/Izh7KaiU \n",
      "Tweet ignored due to unreadability: http://t.co/e5ClGzsI \n",
      "Tweet ignored due to unreadability: http://t.co/18xg3ivo! \n",
      "Tweet ignored due to unreadability: Поиск от \n",
      "Tweet ignored due to unreadability: サムスン電子のスマートフォン新機種「ギャラクシー・ネクサス」、グーグルの基本ソフト（ＯＳ）「アンドロイド」最新版を搭載。「クラウド」活用、音声認識やカメラの機能も向上させた戦略モデル \n",
      "Tweet ignored due to unreadability: Новите \n",
      "Tweet ignored due to unreadability: اعرف الكثير عن نظام ايسكريم ساندويتش http://t.co/Fzjd2Zx1 \n",
      "Tweet ignored due to unreadability: 看見 \n",
      "Tweet ignored due to unreadability: نظام جديد .. و جهاز جديد شكراً جزيلاً \n",
      "Tweet ignored due to unreadability: ايسكريم ساندويش، عسل، زنجبيل .. مشكلة من كثر المسميات احسهم مسوين مقادير مب انظمة !! 😝  \n",
      "Tweet ignored due to unreadability: الجهاز الجديد عجيب   \n",
      "Tweet ignored due to unreadability: Я немного потрясен :) \n",
      "Tweet ignored due to unreadability: 今日発表だった＾ﾛ＾　 \n",
      "Tweet ignored due to unreadability: يبدو ان طفرة الاجهزة الالكترونية القادمة ستكون بقيادة موتورولا ،، لاسيم بعد استحواذ قوقل عليها.   \n",
      "Tweet ignored due to unreadability: 顔認識ロック解除失敗してる・・・デモで失敗しちゃっていいのか？ \n",
      "Tweet ignored due to unreadability: Με συγχισες \n",
      "Tweet ignored due to unreadability: デフォでデータ通信制御？　\n",
      "Tweet ignored due to unreadability: http://t.co/gAPEyL5N \n",
      "Tweet ignored due to unreadability: http://t.co/J3p3KYHf \n",
      "Tweet ignored due to unreadability: http://t.co/h1IH7FN6 مايكروسوفت تقوم بتطوير تقنية تمكنك من استخدام يدك كهاتف  \n",
      "Tweet ignored due to unreadability: http://t.co/ONI0JX8B \n",
      "Tweet ignored due to unreadability: http://t.co/JVidt6U4 \n",
      "Tweet ignored due to unreadability: На сайте \n",
      "Tweet ignored due to unreadability: ☼ \n",
      "Tweet ignored due to unreadability: Настоящий твиттерянин как только попадает в толпу стремиться тут же как можно быстрее попасть в \n",
      "Tweet ignored due to unreadability: Доброе утро \n",
      "Tweet ignored due to unreadability: 【\n",
      "Tweet ignored due to unreadability: なにやらフォロー制限に引っ掛かったようです…もっとフォロアーを増やさなくちゃ♪　\n",
      "Tweet ignored due to unreadability: ツイッターを利用して感謝の気持ちとともに約２０００円が振り込まれ続ける方法→ｺｺ→ http://t.co/TyjUGsnQ ←ｺｺ← :) \n",
      "Tweet ignored due to unreadability: رقم الفلو والفلورز والتويتات  للبيع لاعلى سعر \n",
      "Tweet ignored due to unreadability: قال الرئيس التنفيذي لشركة \n",
      "Tweet ignored due to unreadability: Улучшим продукты компании \n",
      "Tweet ignored due to unreadability: نفسي يوم يعدي علي تويتر من غير مشاكل فنية \n",
      "Tweet ignored due to unreadability: ツイッター検索 \n",
      "Tweet ignored due to unreadability: قال الرئيس التنفيذي لشركة \n",
      "Tweet ignored due to unreadability: Улучшим продукты компании \n",
      "Tweet ignored due to unreadability: نفسي يوم يعدي علي تويتر من غير مشاكل فنية \n",
      "Tweet ignored due to unreadability: ツイッター検索 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ars86\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "wandb: Currently logged in as: ars860 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">polar-plasma-44</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/ars860/text2company_twit_classification\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification</a><br/>\n                Run page: <a href=\"https://wandb.ai/ars860/text2company_twit_classification/runs/2h497kle\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification/runs/2h497kle</a><br/>\n                Run data is saved locally in <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211029_145751-2h497kle</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, iter: 100/3382, mean loss: 0.4658906337618828\n",
      "Epoch 1/50, iter: 200/3382, mean loss: 0.03617534565069946\n",
      "Epoch 1/50, iter: 300/3382, mean loss: 0.012985336140809522\n",
      "Epoch 1/50, iter: 400/3382, mean loss: 0.006824473249580478\n",
      "Epoch 1/50, iter: 500/3382, mean loss: 0.019312472915462422\n",
      "Epoch 1/50, iter: 600/3382, mean loss: 0.00326221801680731\n",
      "Epoch 1/50, iter: 700/3382, mean loss: 0.00387435112590083\n",
      "Epoch 1/50, iter: 800/3382, mean loss: 0.0017567137000219191\n",
      "Epoch 1/50, iter: 900/3382, mean loss: 0.0021735671653800638\n",
      "Epoch 1/50, iter: 1000/3382, mean loss: 0.5437157147549203\n",
      "Epoch 1/50, iter: 1100/3382, mean loss: 0.3701799190044403\n",
      "Epoch 1/50, iter: 1200/3382, mean loss: 0.08033263166900724\n",
      "Epoch 1/50, iter: 1300/3382, mean loss: 0.03243333042977611\n",
      "Epoch 1/50, iter: 1400/3382, mean loss: 0.03636961721778789\n",
      "Epoch 1/50, iter: 1500/3382, mean loss: 0.02683529236841423\n",
      "Epoch 1/50, iter: 1600/3382, mean loss: 0.032955769646068805\n",
      "Epoch 1/50, iter: 1700/3382, mean loss: 0.01661048979349289\n",
      "Epoch 1/50, iter: 1800/3382, mean loss: 1.0197217930095848\n",
      "Epoch 1/50, iter: 1900/3382, mean loss: 0.21175258349627257\n",
      "Epoch 1/50, iter: 2000/3382, mean loss: 0.07161199995462084\n",
      "Epoch 1/50, iter: 2100/3382, mean loss: 0.05124043699775939\n",
      "Epoch 1/50, iter: 2200/3382, mean loss: 0.05165882244689783\n",
      "Epoch 1/50, iter: 2300/3382, mean loss: 0.020434514134394705\n",
      "Epoch 1/50, iter: 2400/3382, mean loss: 0.017970382335588512\n",
      "Epoch 1/50, iter: 2500/3382, mean loss: 0.031080895863078696\n",
      "Epoch 1/50, iter: 2600/3382, mean loss: 1.1193774350224612\n",
      "Epoch 1/50, iter: 2700/3382, mean loss: 0.20159607495879756\n",
      "Epoch 1/50, iter: 2800/3382, mean loss: 0.07386990324303042\n",
      "Epoch 1/50, iter: 2900/3382, mean loss: 0.05016742221014283\n",
      "Epoch 1/50, iter: 3000/3382, mean loss: 0.055877500565147786\n",
      "Epoch 1/50, iter: 3100/3382, mean loss: 0.040852666864639106\n",
      "Epoch 1/50, iter: 3200/3382, mean loss: 0.02980026028614702\n",
      "Epoch 1/50, iter: 3300/3382, mean loss: 0.024606648230096652\n",
      "Epoch 2/50, iter: 100/3382, mean loss: 0.9832062249490992\n",
      "Epoch 2/50, iter: 200/3382, mean loss: 0.05999133940320462\n",
      "Epoch 2/50, iter: 300/3382, mean loss: 0.049703522161580624\n",
      "Epoch 2/50, iter: 400/3382, mean loss: 0.02409039256584947\n",
      "Epoch 2/50, iter: 500/3382, mean loss: 0.03434873075773794\n",
      "Epoch 2/50, iter: 600/3382, mean loss: 0.010267554512975039\n",
      "Epoch 2/50, iter: 700/3382, mean loss: 0.009099840572125685\n",
      "Epoch 2/50, iter: 800/3382, mean loss: 0.004790927920221293\n",
      "Epoch 2/50, iter: 900/3382, mean loss: 0.0035765381751116363\n",
      "Epoch 2/50, iter: 1000/3382, mean loss: 0.4657619964255082\n",
      "Epoch 2/50, iter: 1100/3382, mean loss: 0.396519553810358\n",
      "Epoch 2/50, iter: 1200/3382, mean loss: 0.11448942556045949\n",
      "Epoch 2/50, iter: 1300/3382, mean loss: 0.07420648699189769\n",
      "Epoch 2/50, iter: 1400/3382, mean loss: 0.07161803755472647\n",
      "Epoch 2/50, iter: 1500/3382, mean loss: 0.04446835890354123\n",
      "Epoch 2/50, iter: 1600/3382, mean loss: 0.044654053341801045\n",
      "Epoch 2/50, iter: 1700/3382, mean loss: 0.022159982783196027\n",
      "Epoch 2/50, iter: 1800/3382, mean loss: 0.7710766320685798\n",
      "Epoch 2/50, iter: 1900/3382, mean loss: 0.263040963280946\n",
      "Epoch 2/50, iter: 2000/3382, mean loss: 0.11537750461953693\n",
      "Epoch 2/50, iter: 2100/3382, mean loss: 0.07927162807667627\n",
      "Epoch 2/50, iter: 2200/3382, mean loss: 0.06729158595000627\n",
      "Epoch 2/50, iter: 2300/3382, mean loss: 0.03360472640677472\n",
      "Epoch 2/50, iter: 2400/3382, mean loss: 0.022619066783663586\n",
      "Epoch 2/50, iter: 2500/3382, mean loss: 0.044655877159057125\n",
      "Epoch 2/50, iter: 2600/3382, mean loss: 0.999893889849227\n",
      "Epoch 2/50, iter: 2700/3382, mean loss: 0.20901628116611393\n",
      "Epoch 2/50, iter: 2800/3382, mean loss: 0.07759586967527866\n",
      "Epoch 2/50, iter: 2900/3382, mean loss: 0.051743202407087664\n",
      "Epoch 2/50, iter: 3000/3382, mean loss: 0.05099955809884705\n",
      "Epoch 2/50, iter: 3100/3382, mean loss: 0.042302846864331514\n",
      "Epoch 2/50, iter: 3200/3382, mean loss: 0.0214926722583823\n",
      "Epoch 2/50, iter: 3300/3382, mean loss: 0.02517645572661422\n",
      "Epoch 3/50, iter: 100/3382, mean loss: 0.8475490803178399\n",
      "Epoch 3/50, iter: 200/3382, mean loss: 0.047306205080240034\n",
      "Epoch 3/50, iter: 300/3382, mean loss: 0.016852707890502642\n",
      "Epoch 3/50, iter: 400/3382, mean loss: 0.014785261779907159\n",
      "Epoch 3/50, iter: 500/3382, mean loss: 0.03198773723670456\n",
      "Epoch 3/50, iter: 600/3382, mean loss: 0.008995774479699322\n",
      "Epoch 3/50, iter: 700/3382, mean loss: 0.006437306221287144\n",
      "Epoch 3/50, iter: 800/3382, mean loss: 0.009221816703047806\n",
      "Epoch 3/50, iter: 900/3382, mean loss: 0.0026480958367392305\n",
      "Epoch 3/50, iter: 1000/3382, mean loss: 0.43821895169727215\n",
      "Epoch 3/50, iter: 1100/3382, mean loss: 0.4895389088988304\n",
      "Epoch 3/50, iter: 1200/3382, mean loss: 0.1093430855521001\n",
      "Epoch 3/50, iter: 1300/3382, mean loss: 0.052307203951640985\n",
      "Epoch 3/50, iter: 1400/3382, mean loss: 0.033021272986952684\n",
      "Epoch 3/50, iter: 1500/3382, mean loss: 0.031286049541740794\n",
      "Epoch 3/50, iter: 1600/3382, mean loss: 0.03567020357735601\n",
      "Epoch 3/50, iter: 1700/3382, mean loss: 0.010091829309749301\n",
      "Epoch 3/50, iter: 1800/3382, mean loss: 0.7292587727759383\n",
      "Epoch 3/50, iter: 1900/3382, mean loss: 0.24444583408068865\n",
      "Epoch 3/50, iter: 2000/3382, mean loss: 0.06484759578364901\n",
      "Epoch 3/50, iter: 2100/3382, mean loss: 0.04811198683673865\n",
      "Epoch 3/50, iter: 2200/3382, mean loss: 0.049522762478809455\n",
      "Epoch 3/50, iter: 2300/3382, mean loss: 0.01882582914771774\n",
      "Epoch 3/50, iter: 2400/3382, mean loss: 0.018672806879367274\n",
      "Epoch 3/50, iter: 2500/3382, mean loss: 0.02830505681478826\n",
      "Epoch 3/50, iter: 2600/3382, mean loss: 0.8334933655514033\n",
      "Epoch 3/50, iter: 2700/3382, mean loss: 0.10092544153507334\n",
      "Epoch 3/50, iter: 2800/3382, mean loss: 0.04794758002964954\n",
      "Epoch 3/50, iter: 2900/3382, mean loss: 0.04031259328639862\n",
      "Epoch 3/50, iter: 3000/3382, mean loss: 0.037245082174076745\n",
      "Epoch 3/50, iter: 3100/3382, mean loss: 0.03991933841872651\n",
      "Epoch 3/50, iter: 3200/3382, mean loss: 0.018489899166088435\n",
      "Epoch 3/50, iter: 3300/3382, mean loss: 0.017809096494784172\n",
      "Epoch 4/50, iter: 100/3382, mean loss: 0.7818969058367656\n",
      "Epoch 4/50, iter: 200/3382, mean loss: 0.045648598894476894\n",
      "Epoch 4/50, iter: 300/3382, mean loss: 0.012838100082590245\n",
      "Epoch 4/50, iter: 400/3382, mean loss: 0.0044580646980466555\n",
      "Epoch 4/50, iter: 500/3382, mean loss: 0.05084263988497696\n",
      "Epoch 4/50, iter: 600/3382, mean loss: 0.016382479994481402\n",
      "Epoch 4/50, iter: 700/3382, mean loss: 0.004855965279984957\n",
      "Epoch 4/50, iter: 800/3382, mean loss: 0.010896338214461138\n",
      "Epoch 4/50, iter: 900/3382, mean loss: 0.004019292244074677\n",
      "Epoch 4/50, iter: 1000/3382, mean loss: 0.44639224210628525\n",
      "Epoch 4/50, iter: 1100/3382, mean loss: 0.4466555097233504\n",
      "Epoch 4/50, iter: 1200/3382, mean loss: 0.10193809934309683\n",
      "Epoch 4/50, iter: 1300/3382, mean loss: 0.0485817863511329\n",
      "Epoch 4/50, iter: 1400/3382, mean loss: 0.03712822800283902\n",
      "Epoch 4/50, iter: 1500/3382, mean loss: 0.03029405752522507\n",
      "Epoch 4/50, iter: 1600/3382, mean loss: 0.030221278986446123\n",
      "Epoch 4/50, iter: 1700/3382, mean loss: 0.0119112626555102\n",
      "Epoch 4/50, iter: 1800/3382, mean loss: 0.8214074898031504\n",
      "Epoch 4/50, iter: 1900/3382, mean loss: 0.2686301348078996\n",
      "Epoch 4/50, iter: 2000/3382, mean loss: 0.06931885144906119\n",
      "Epoch 4/50, iter: 2100/3382, mean loss: 0.043334066695751974\n",
      "Epoch 4/50, iter: 2200/3382, mean loss: 0.02957955246711208\n",
      "Epoch 4/50, iter: 2300/3382, mean loss: 0.018301499758817955\n",
      "Epoch 4/50, iter: 2400/3382, mean loss: 0.019250310569332213\n",
      "Epoch 4/50, iter: 2500/3382, mean loss: 0.02275845511156149\n",
      "Epoch 4/50, iter: 2600/3382, mean loss: 1.0657905643424055\n",
      "Epoch 4/50, iter: 2700/3382, mean loss: 0.12568066578591242\n",
      "Epoch 4/50, iter: 2800/3382, mean loss: 0.03992867899185512\n",
      "Epoch 4/50, iter: 2900/3382, mean loss: 0.026757200552965515\n",
      "Epoch 4/50, iter: 3000/3382, mean loss: 0.02955543871903501\n",
      "Epoch 4/50, iter: 3100/3382, mean loss: 0.020971778881867065\n",
      "Epoch 4/50, iter: 3200/3382, mean loss: 0.013735924176653497\n",
      "Epoch 4/50, iter: 3300/3382, mean loss: 0.01076032660839246\n",
      "Epoch 5/50, iter: 100/3382, mean loss: 0.7293718052736949\n",
      "Epoch 5/50, iter: 200/3382, mean loss: 0.02696738963073585\n",
      "Epoch 5/50, iter: 300/3382, mean loss: 0.007637639241438592\n",
      "Epoch 5/50, iter: 400/3382, mean loss: 0.0034867690408282217\n",
      "Epoch 5/50, iter: 500/3382, mean loss: 0.019433187597460346\n",
      "Epoch 5/50, iter: 600/3382, mean loss: 0.006850878601235308\n",
      "Epoch 5/50, iter: 700/3382, mean loss: 0.005600666860282218\n",
      "Epoch 5/50, iter: 800/3382, mean loss: 0.004910841246091877\n",
      "Epoch 5/50, iter: 900/3382, mean loss: 0.0013566110367719375\n",
      "Epoch 5/50, iter: 1000/3382, mean loss: 0.3813581845281442\n",
      "Epoch 5/50, iter: 1100/3382, mean loss: 0.2944726736214943\n",
      "Epoch 5/50, iter: 1200/3382, mean loss: 0.06367372448672541\n",
      "Epoch 5/50, iter: 1300/3382, mean loss: 0.028783665711962385\n",
      "Epoch 5/50, iter: 1400/3382, mean loss: 0.027427308399674076\n",
      "Epoch 5/50, iter: 1500/3382, mean loss: 0.031687099284936265\n",
      "Epoch 5/50, iter: 1600/3382, mean loss: 0.0240460100698715\n",
      "Epoch 5/50, iter: 1700/3382, mean loss: 0.009906426552634002\n",
      "Epoch 5/50, iter: 1800/3382, mean loss: 0.7068194230033851\n",
      "Epoch 5/50, iter: 1900/3382, mean loss: 0.42159128226339815\n",
      "Epoch 5/50, iter: 2000/3382, mean loss: 0.07116313290782272\n",
      "Epoch 5/50, iter: 2100/3382, mean loss: 0.045113205978268525\n",
      "Epoch 5/50, iter: 2200/3382, mean loss: 0.03238765130798129\n",
      "Epoch 5/50, iter: 2300/3382, mean loss: 0.016400871678742986\n",
      "Epoch 5/50, iter: 2400/3382, mean loss: 0.012261188130069059\n",
      "Epoch 5/50, iter: 2500/3382, mean loss: 0.019034566881136927\n",
      "Epoch 5/50, iter: 2600/3382, mean loss: 0.9904619696008922\n",
      "Epoch 5/50, iter: 2700/3382, mean loss: 0.15043789211078548\n",
      "Epoch 5/50, iter: 2800/3382, mean loss: 0.0422453032786143\n",
      "Epoch 5/50, iter: 2900/3382, mean loss: 0.0287887586202487\n",
      "Epoch 5/50, iter: 3000/3382, mean loss: 0.027576434010443338\n",
      "Epoch 5/50, iter: 3100/3382, mean loss: 0.02787497305880606\n",
      "Epoch 5/50, iter: 3200/3382, mean loss: 0.01490500941821665\n",
      "Epoch 5/50, iter: 3300/3382, mean loss: 0.010361091951752997\n",
      "Epoch 6/50, iter: 100/3382, mean loss: 0.6086683178332168\n",
      "Epoch 6/50, iter: 200/3382, mean loss: 0.039701634152734186\n",
      "Epoch 6/50, iter: 300/3382, mean loss: 0.013477847925169045\n",
      "Epoch 6/50, iter: 400/3382, mean loss: 0.008538127681331388\n",
      "Epoch 6/50, iter: 500/3382, mean loss: 0.031810505251014545\n",
      "Epoch 6/50, iter: 600/3382, mean loss: 0.009557944887574195\n",
      "Epoch 6/50, iter: 700/3382, mean loss: 0.00845370289258426\n",
      "Epoch 6/50, iter: 800/3382, mean loss: 0.00652332492189089\n",
      "Epoch 6/50, iter: 900/3382, mean loss: 0.0033850743886887358\n",
      "Epoch 6/50, iter: 1000/3382, mean loss: 0.4061410871561202\n",
      "Epoch 6/50, iter: 1100/3382, mean loss: 0.43850779773667453\n",
      "Epoch 6/50, iter: 1200/3382, mean loss: 0.09198532567341317\n",
      "Epoch 6/50, iter: 1300/3382, mean loss: 0.04703982881550473\n",
      "Epoch 6/50, iter: 1400/3382, mean loss: 0.02762600508176547\n",
      "Epoch 6/50, iter: 1500/3382, mean loss: 0.03160611347669146\n",
      "Epoch 6/50, iter: 1600/3382, mean loss: 0.03207847300344838\n",
      "Epoch 6/50, iter: 1700/3382, mean loss: 0.012375332537294526\n",
      "Epoch 6/50, iter: 1800/3382, mean loss: 0.6656948986070984\n",
      "Epoch 6/50, iter: 1900/3382, mean loss: 0.42423318143934013\n",
      "Epoch 6/50, iter: 2000/3382, mean loss: 0.10921892570215277\n",
      "Epoch 6/50, iter: 2100/3382, mean loss: 0.047324687867367175\n",
      "Epoch 6/50, iter: 2200/3382, mean loss: 0.04240150141387858\n",
      "Epoch 6/50, iter: 2300/3382, mean loss: 0.02443262438682723\n",
      "Epoch 6/50, iter: 2400/3382, mean loss: 0.015311623154093467\n",
      "Epoch 6/50, iter: 2500/3382, mean loss: 0.0253440615512136\n",
      "Epoch 6/50, iter: 2600/3382, mean loss: 0.875338024951052\n",
      "Epoch 6/50, iter: 2700/3382, mean loss: 0.16655871086521074\n",
      "Epoch 6/50, iter: 2800/3382, mean loss: 0.05127333840937354\n",
      "Epoch 6/50, iter: 2900/3382, mean loss: 0.038146475181238204\n",
      "Epoch 6/50, iter: 3000/3382, mean loss: 0.03250837103932099\n",
      "Epoch 6/50, iter: 3100/3382, mean loss: 0.025146910054559157\n",
      "Epoch 6/50, iter: 3200/3382, mean loss: 0.019180453110031977\n",
      "Epoch 6/50, iter: 3300/3382, mean loss: 0.014128900054495262\n",
      "Epoch 7/50, iter: 100/3382, mean loss: 0.6607482319697737\n",
      "Epoch 7/50, iter: 200/3382, mean loss: 0.03860311600583373\n",
      "Epoch 7/50, iter: 300/3382, mean loss: 0.01754853695369093\n",
      "Epoch 7/50, iter: 400/3382, mean loss: 0.010706499867701495\n",
      "Epoch 7/50, iter: 500/3382, mean loss: 0.042435056274407544\n",
      "Epoch 7/50, iter: 600/3382, mean loss: 0.008900039967620614\n",
      "Epoch 7/50, iter: 700/3382, mean loss: 0.0067286633296362195\n",
      "Epoch 7/50, iter: 800/3382, mean loss: 0.020359924842941836\n",
      "Epoch 7/50, iter: 900/3382, mean loss: 0.00722768466459911\n",
      "Epoch 7/50, iter: 1000/3382, mean loss: 0.2885913805477503\n",
      "Epoch 7/50, iter: 1100/3382, mean loss: 0.4375161020830274\n",
      "Epoch 7/50, iter: 1200/3382, mean loss: 0.1226846661226591\n",
      "Epoch 7/50, iter: 1300/3382, mean loss: 0.06234894067467394\n",
      "Epoch 7/50, iter: 1400/3382, mean loss: 0.03497786684587481\n",
      "Epoch 7/50, iter: 1500/3382, mean loss: 0.03929926159606111\n",
      "Epoch 7/50, iter: 1600/3382, mean loss: 0.035481253917969295\n",
      "Epoch 7/50, iter: 1700/3382, mean loss: 0.016452927510846392\n",
      "Epoch 7/50, iter: 1800/3382, mean loss: 0.6483047189515685\n",
      "Epoch 7/50, iter: 1900/3382, mean loss: 0.47324516929686067\n",
      "Epoch 7/50, iter: 2000/3382, mean loss: 0.17601845285855233\n",
      "Epoch 7/50, iter: 2100/3382, mean loss: 0.06341562121902826\n",
      "Epoch 7/50, iter: 2200/3382, mean loss: 0.05165096131706377\n",
      "Epoch 7/50, iter: 2300/3382, mean loss: 0.025144427317391093\n",
      "Epoch 7/50, iter: 2400/3382, mean loss: 0.015398586611590872\n",
      "Epoch 7/50, iter: 2500/3382, mean loss: 0.02790823539936355\n",
      "Epoch 7/50, iter: 2600/3382, mean loss: 0.9282004433691327\n",
      "Epoch 7/50, iter: 2700/3382, mean loss: 0.20720508416299707\n",
      "Epoch 7/50, iter: 2800/3382, mean loss: 0.06207196915856912\n",
      "Epoch 7/50, iter: 2900/3382, mean loss: 0.04272174580415594\n",
      "Epoch 7/50, iter: 3000/3382, mean loss: 0.03632159242489934\n",
      "Epoch 7/50, iter: 3100/3382, mean loss: 0.029921761573323238\n",
      "Epoch 7/50, iter: 3200/3382, mean loss: 0.01851689062207811\n",
      "Epoch 7/50, iter: 3300/3382, mean loss: 0.022758128227445412\n",
      "Epoch 8/50, iter: 100/3382, mean loss: 0.516677867854014\n",
      "Epoch 8/50, iter: 200/3382, mean loss: 0.03426713566310355\n",
      "Epoch 8/50, iter: 300/3382, mean loss: 0.01682244177805842\n",
      "Epoch 8/50, iter: 400/3382, mean loss: 0.00940846174262333\n",
      "Epoch 8/50, iter: 500/3382, mean loss: 0.03467897159905988\n",
      "Epoch 8/50, iter: 600/3382, mean loss: 0.00822182026655355\n",
      "Epoch 8/50, iter: 700/3382, mean loss: 0.0027795208527322756\n",
      "Epoch 8/50, iter: 800/3382, mean loss: 0.008375983730165898\n",
      "Epoch 8/50, iter: 900/3382, mean loss: 0.007422211191169481\n",
      "Epoch 8/50, iter: 1000/3382, mean loss: 0.24767443817844823\n",
      "Epoch 8/50, iter: 1100/3382, mean loss: 0.4312990623526275\n",
      "Epoch 8/50, iter: 1200/3382, mean loss: 0.1567566172860097\n",
      "Epoch 8/50, iter: 1300/3382, mean loss: 0.06563073477481339\n",
      "Epoch 8/50, iter: 1400/3382, mean loss: 0.04269347695619217\n",
      "Epoch 8/50, iter: 1500/3382, mean loss: 0.032378976371255704\n",
      "Epoch 8/50, iter: 1600/3382, mean loss: 0.04312813659679705\n",
      "Epoch 8/50, iter: 1700/3382, mean loss: 0.01783146788159229\n",
      "Epoch 8/50, iter: 1800/3382, mean loss: 0.5584653148446387\n",
      "Epoch 8/50, iter: 1900/3382, mean loss: 0.48333482034504416\n",
      "Epoch 8/50, iter: 2000/3382, mean loss: 0.23156428503803908\n",
      "Epoch 8/50, iter: 2100/3382, mean loss: 0.07828643725049915\n",
      "Epoch 8/50, iter: 2200/3382, mean loss: 0.045104501695168435\n",
      "Epoch 8/50, iter: 2300/3382, mean loss: 0.028619381913449614\n",
      "Epoch 8/50, iter: 2400/3382, mean loss: 0.023415838998953404\n",
      "Epoch 8/50, iter: 2500/3382, mean loss: 0.03305600901173875\n",
      "Epoch 8/50, iter: 2600/3382, mean loss: 0.7711648958427759\n",
      "Epoch 8/50, iter: 2700/3382, mean loss: 0.2809083180408925\n",
      "Epoch 8/50, iter: 2800/3382, mean loss: 0.14369444421725347\n",
      "Epoch 8/50, iter: 2900/3382, mean loss: 0.07643571360335046\n",
      "Epoch 8/50, iter: 3000/3382, mean loss: 0.05921689585316926\n",
      "Epoch 8/50, iter: 3100/3382, mean loss: 0.040522036292059055\n",
      "Epoch 8/50, iter: 3200/3382, mean loss: 0.03049734465142137\n",
      "Epoch 8/50, iter: 3300/3382, mean loss: 0.018343411919595383\n",
      "Epoch 9/50, iter: 100/3382, mean loss: 0.37369654085021464\n",
      "Epoch 9/50, iter: 200/3382, mean loss: 0.03346765854919795\n",
      "Epoch 9/50, iter: 300/3382, mean loss: 0.016279892094171373\n",
      "Epoch 9/50, iter: 400/3382, mean loss: 0.014129693659124315\n",
      "Epoch 9/50, iter: 500/3382, mean loss: 0.04257580759245684\n",
      "Epoch 9/50, iter: 600/3382, mean loss: 0.012945832940040418\n",
      "Epoch 9/50, iter: 700/3382, mean loss: 0.00644372321444962\n",
      "Epoch 9/50, iter: 800/3382, mean loss: 0.013034191119289744\n",
      "Epoch 9/50, iter: 900/3382, mean loss: 0.012995489491124772\n",
      "Epoch 9/50, iter: 1000/3382, mean loss: 0.1771186873264878\n",
      "Epoch 9/50, iter: 1100/3382, mean loss: 0.4628827954595909\n",
      "Epoch 9/50, iter: 1200/3382, mean loss: 0.19713441735540982\n",
      "Epoch 9/50, iter: 1300/3382, mean loss: 0.09305639149974013\n",
      "Epoch 9/50, iter: 1400/3382, mean loss: 0.0455654265332123\n",
      "Epoch 9/50, iter: 1500/3382, mean loss: 0.04467058168097992\n",
      "Epoch 9/50, iter: 1600/3382, mean loss: 0.047504711734600275\n",
      "Epoch 9/50, iter: 1700/3382, mean loss: 0.02291551249033546\n",
      "Epoch 9/50, iter: 1800/3382, mean loss: 0.47946515128021927\n",
      "Epoch 9/50, iter: 1900/3382, mean loss: 0.43790644228458403\n",
      "Epoch 9/50, iter: 2000/3382, mean loss: 0.29728051225654784\n",
      "Epoch 9/50, iter: 2100/3382, mean loss: 0.10751447072252632\n",
      "Epoch 9/50, iter: 2200/3382, mean loss: 0.05876344684700598\n",
      "Epoch 9/50, iter: 2300/3382, mean loss: 0.03393774937285343\n",
      "Epoch 9/50, iter: 2400/3382, mean loss: 0.023163694912727805\n",
      "Epoch 9/50, iter: 2500/3382, mean loss: 0.030656487923824898\n",
      "Epoch 9/50, iter: 2600/3382, mean loss: 0.7413843661062219\n",
      "Epoch 9/50, iter: 2700/3382, mean loss: 0.29251514536794276\n",
      "Epoch 9/50, iter: 2800/3382, mean loss: 0.15772227328270674\n",
      "Epoch 9/50, iter: 2900/3382, mean loss: 0.08139078685373534\n",
      "Epoch 9/50, iter: 3000/3382, mean loss: 0.0599663500214956\n",
      "Epoch 9/50, iter: 3100/3382, mean loss: 0.03995604811578232\n",
      "Epoch 9/50, iter: 3200/3382, mean loss: 0.036047894308048854\n",
      "Epoch 9/50, iter: 3300/3382, mean loss: 0.037095731892604816\n",
      "Epoch 10/50, iter: 100/3382, mean loss: 0.3169115519535262\n",
      "Epoch 10/50, iter: 200/3382, mean loss: 0.09219575256945972\n",
      "Epoch 10/50, iter: 300/3382, mean loss: 0.022505016432914998\n",
      "Epoch 10/50, iter: 400/3382, mean loss: 0.01544849146915567\n",
      "Epoch 10/50, iter: 500/3382, mean loss: 0.06015195334755845\n",
      "Epoch 10/50, iter: 600/3382, mean loss: 0.03851413710705856\n",
      "Epoch 10/50, iter: 700/3382, mean loss: 0.004719416066527629\n",
      "Epoch 10/50, iter: 800/3382, mean loss: 0.010816593512726626\n",
      "Epoch 10/50, iter: 900/3382, mean loss: 0.017582154327089938\n",
      "Epoch 10/50, iter: 1000/3382, mean loss: 0.1633028460805923\n",
      "Epoch 10/50, iter: 1100/3382, mean loss: 0.3468421629630029\n",
      "Epoch 10/50, iter: 1200/3382, mean loss: 0.20596884855011013\n",
      "Epoch 10/50, iter: 1300/3382, mean loss: 0.08427096893836278\n",
      "Epoch 10/50, iter: 1400/3382, mean loss: 0.04538979645927611\n",
      "Epoch 10/50, iter: 1500/3382, mean loss: 0.03619138761192062\n",
      "Epoch 10/50, iter: 1600/3382, mean loss: 0.05226642747961705\n",
      "Epoch 10/50, iter: 1700/3382, mean loss: 0.03308649780956898\n",
      "Epoch 10/50, iter: 1800/3382, mean loss: 0.4443290468222031\n",
      "Epoch 10/50, iter: 1900/3382, mean loss: 0.4009524348378182\n",
      "Epoch 10/50, iter: 2000/3382, mean loss: 0.2616713748546317\n",
      "Epoch 10/50, iter: 2100/3382, mean loss: 0.1125719568983186\n",
      "Epoch 10/50, iter: 2200/3382, mean loss: 0.08507589312117489\n",
      "Epoch 10/50, iter: 2300/3382, mean loss: 0.036965523222315826\n",
      "Epoch 10/50, iter: 2400/3382, mean loss: 0.033316082582823585\n",
      "Epoch 10/50, iter: 2500/3382, mean loss: 0.03714268751487907\n",
      "Epoch 10/50, iter: 2600/3382, mean loss: 0.6729799330662081\n",
      "Epoch 10/50, iter: 2700/3382, mean loss: 0.24996276820311322\n",
      "Epoch 10/50, iter: 2800/3382, mean loss: 0.17987578116706573\n",
      "Epoch 10/50, iter: 2900/3382, mean loss: 0.10187105323944706\n",
      "Epoch 10/50, iter: 3000/3382, mean loss: 0.08442605200834805\n",
      "Epoch 10/50, iter: 3100/3382, mean loss: 0.06399491809213942\n",
      "Epoch 10/50, iter: 3200/3382, mean loss: 0.042382527672334615\n",
      "Epoch 10/50, iter: 3300/3382, mean loss: 0.015329921017164452\n",
      "Epoch 11/50, iter: 100/3382, mean loss: 0.25443197646178306\n",
      "Epoch 11/50, iter: 200/3382, mean loss: 0.05947774053453031\n",
      "Epoch 11/50, iter: 300/3382, mean loss: 0.016939126354095606\n",
      "Epoch 11/50, iter: 400/3382, mean loss: 0.01414635494945287\n",
      "Epoch 11/50, iter: 500/3382, mean loss: 0.04010805465665271\n",
      "Epoch 11/50, iter: 600/3382, mean loss: 0.017601370573329403\n",
      "Epoch 11/50, iter: 700/3382, mean loss: 0.016703751396389636\n",
      "Epoch 11/50, iter: 800/3382, mean loss: 0.01861613558003114\n",
      "Epoch 11/50, iter: 900/3382, mean loss: 0.008608465508831244\n",
      "Epoch 11/50, iter: 1000/3382, mean loss: 0.13511017628137778\n",
      "Epoch 11/50, iter: 1100/3382, mean loss: 0.3194113628595369\n",
      "Epoch 11/50, iter: 1200/3382, mean loss: 0.2154216548608383\n",
      "Epoch 11/50, iter: 1300/3382, mean loss: 0.09434128151384356\n",
      "Epoch 11/50, iter: 1400/3382, mean loss: 0.05387209515436552\n",
      "Epoch 11/50, iter: 1500/3382, mean loss: 0.05138294032798513\n",
      "Epoch 11/50, iter: 1600/3382, mean loss: 0.04327155910296824\n",
      "Epoch 11/50, iter: 1700/3382, mean loss: 0.01637186701720907\n",
      "Epoch 11/50, iter: 1800/3382, mean loss: 0.38960252296631553\n",
      "Epoch 11/50, iter: 1900/3382, mean loss: 0.35780482400208713\n",
      "Epoch 11/50, iter: 2000/3382, mean loss: 0.2539459349086974\n",
      "Epoch 11/50, iter: 2100/3382, mean loss: 0.11688383610686287\n",
      "Epoch 11/50, iter: 2200/3382, mean loss: 0.09101103173947195\n",
      "Epoch 11/50, iter: 2300/3382, mean loss: 0.046761225843074496\n",
      "Epoch 11/50, iter: 2400/3382, mean loss: 0.04228904365994822\n",
      "Epoch 11/50, iter: 2500/3382, mean loss: 0.03154850133681975\n",
      "Epoch 11/50, iter: 2600/3382, mean loss: 0.5528218901814398\n",
      "Epoch 11/50, iter: 2700/3382, mean loss: 0.19866590731428005\n",
      "Epoch 11/50, iter: 2800/3382, mean loss: 0.15153005967120406\n",
      "Epoch 11/50, iter: 2900/3382, mean loss: 0.10963613535292098\n",
      "Epoch 11/50, iter: 3000/3382, mean loss: 0.07587014769806047\n",
      "Epoch 11/50, iter: 3100/3382, mean loss: 0.06669609661611503\n",
      "Epoch 11/50, iter: 3200/3382, mean loss: 0.03952266250260436\n",
      "Epoch 11/50, iter: 3300/3382, mean loss: 0.018949199387047883\n",
      "Epoch 12/50, iter: 100/3382, mean loss: 0.19647086943397882\n",
      "Epoch 12/50, iter: 200/3382, mean loss: 0.04891119739733767\n",
      "Epoch 12/50, iter: 300/3382, mean loss: 0.01961487553803636\n",
      "Epoch 12/50, iter: 400/3382, mean loss: 0.026761402134254694\n",
      "Epoch 12/50, iter: 500/3382, mean loss: 0.04043930248564607\n",
      "Epoch 12/50, iter: 600/3382, mean loss: 0.01728603037533276\n",
      "Epoch 12/50, iter: 700/3382, mean loss: 0.003957729835575208\n",
      "Epoch 12/50, iter: 800/3382, mean loss: 0.012515966672575587\n",
      "Epoch 12/50, iter: 900/3382, mean loss: 0.021644768485557506\n",
      "Epoch 12/50, iter: 1000/3382, mean loss: 0.13322574454850952\n",
      "Epoch 12/50, iter: 1100/3382, mean loss: 0.3234653327171691\n",
      "Epoch 12/50, iter: 1200/3382, mean loss: 0.17439642139826902\n",
      "Epoch 12/50, iter: 1300/3382, mean loss: 0.07391900858857298\n",
      "Epoch 12/50, iter: 1400/3382, mean loss: 0.08299573844131715\n",
      "Epoch 12/50, iter: 1500/3382, mean loss: 0.03147230999759358\n",
      "Epoch 12/50, iter: 1600/3382, mean loss: 0.04632309492099068\n",
      "Epoch 12/50, iter: 1700/3382, mean loss: 0.01739228644127081\n",
      "Epoch 12/50, iter: 1800/3382, mean loss: 0.3612705390038127\n",
      "Epoch 12/50, iter: 1900/3382, mean loss: 0.35171849589794874\n",
      "Epoch 12/50, iter: 2000/3382, mean loss: 0.19835856832331047\n",
      "Epoch 12/50, iter: 2100/3382, mean loss: 0.1291729610739276\n",
      "Epoch 12/50, iter: 2200/3382, mean loss: 0.08604176861234009\n",
      "Epoch 12/50, iter: 2300/3382, mean loss: 0.061102091621046385\n",
      "Epoch 12/50, iter: 2400/3382, mean loss: 0.03690763639162469\n",
      "Epoch 12/50, iter: 2500/3382, mean loss: 0.025562116050350595\n",
      "Epoch 12/50, iter: 2600/3382, mean loss: 0.5292016952711037\n",
      "Epoch 12/50, iter: 2700/3382, mean loss: 0.22676638118049597\n",
      "Epoch 12/50, iter: 2800/3382, mean loss: 0.13924654230911984\n",
      "Epoch 12/50, iter: 2900/3382, mean loss: 0.13090462943800957\n",
      "Epoch 12/50, iter: 3000/3382, mean loss: 0.09109040627990908\n",
      "Epoch 12/50, iter: 3100/3382, mean loss: 0.07396775022079055\n",
      "Epoch 12/50, iter: 3200/3382, mean loss: 0.03441960272606593\n",
      "Epoch 12/50, iter: 3300/3382, mean loss: 0.027078658480745615\n",
      "Epoch 13/50, iter: 100/3382, mean loss: 0.14484228012806852\n",
      "Epoch 13/50, iter: 200/3382, mean loss: 0.0491514188933661\n",
      "Epoch 13/50, iter: 300/3382, mean loss: 0.022387571368133196\n",
      "Epoch 13/50, iter: 400/3382, mean loss: 0.028312774587299715\n",
      "Epoch 13/50, iter: 500/3382, mean loss: 0.06050261716839486\n",
      "Epoch 13/50, iter: 600/3382, mean loss: 0.03452548566833571\n",
      "Epoch 13/50, iter: 700/3382, mean loss: 0.0055270906310016694\n",
      "Epoch 13/50, iter: 800/3382, mean loss: 0.02093531488391136\n",
      "Epoch 13/50, iter: 900/3382, mean loss: 0.05159245827333052\n",
      "Epoch 13/50, iter: 1000/3382, mean loss: 0.09927997237479402\n",
      "Epoch 13/50, iter: 1100/3382, mean loss: 0.272281061646936\n",
      "Epoch 13/50, iter: 1200/3382, mean loss: 0.1481460068616434\n",
      "Epoch 13/50, iter: 1300/3382, mean loss: 0.1208793118444737\n",
      "Epoch 13/50, iter: 1400/3382, mean loss: 0.07615915041682626\n",
      "Epoch 13/50, iter: 1500/3382, mean loss: 0.04227635633435796\n",
      "Epoch 13/50, iter: 1600/3382, mean loss: 0.04076722548093599\n",
      "Epoch 13/50, iter: 1700/3382, mean loss: 0.030193722394729436\n",
      "Epoch 13/50, iter: 1800/3382, mean loss: 0.2913618939387176\n",
      "Epoch 13/50, iter: 1900/3382, mean loss: 0.37751077560707924\n",
      "Epoch 13/50, iter: 2000/3382, mean loss: 0.21807373626274057\n",
      "Epoch 13/50, iter: 2100/3382, mean loss: 0.10285211428825278\n",
      "Epoch 13/50, iter: 2200/3382, mean loss: 0.08868101886218938\n",
      "Epoch 13/50, iter: 2300/3382, mean loss: 0.06536867194219667\n",
      "Epoch 13/50, iter: 2400/3382, mean loss: 0.042154748138200374\n",
      "Epoch 13/50, iter: 2500/3382, mean loss: 0.035317574024484204\n",
      "Epoch 13/50, iter: 2600/3382, mean loss: 0.4098241382564447\n",
      "Epoch 13/50, iter: 2700/3382, mean loss: 0.1868582223757403\n",
      "Epoch 13/50, iter: 2800/3382, mean loss: 0.12042546475975541\n",
      "Epoch 13/50, iter: 2900/3382, mean loss: 0.12059037887847808\n",
      "Epoch 13/50, iter: 3000/3382, mean loss: 0.10695002916778322\n",
      "Epoch 13/50, iter: 3100/3382, mean loss: 0.08181693398939388\n",
      "Epoch 13/50, iter: 3200/3382, mean loss: 0.05529384923675025\n",
      "Epoch 13/50, iter: 3300/3382, mean loss: 0.03171384501666125\n",
      "Epoch 14/50, iter: 100/3382, mean loss: 0.14960115320121986\n",
      "Epoch 14/50, iter: 200/3382, mean loss: 0.07130678838694848\n",
      "Epoch 14/50, iter: 300/3382, mean loss: 0.030086166546898312\n",
      "Epoch 14/50, iter: 400/3382, mean loss: 0.02393001905756023\n",
      "Epoch 14/50, iter: 500/3382, mean loss: 0.07946352356280556\n",
      "Epoch 14/50, iter: 600/3382, mean loss: 0.018644769451240675\n",
      "Epoch 14/50, iter: 700/3382, mean loss: 0.011261337329726189\n",
      "Epoch 14/50, iter: 800/3382, mean loss: 0.04943888716214943\n",
      "Epoch 14/50, iter: 900/3382, mean loss: 0.010540307558889097\n",
      "Epoch 14/50, iter: 1000/3382, mean loss: 0.11332730927958451\n",
      "Epoch 14/50, iter: 1100/3382, mean loss: 0.25207354907528495\n",
      "Epoch 14/50, iter: 1200/3382, mean loss: 0.18473007806621353\n",
      "Epoch 14/50, iter: 1300/3382, mean loss: 0.12539844284422544\n",
      "Epoch 14/50, iter: 1400/3382, mean loss: 0.14577761374313014\n",
      "Epoch 14/50, iter: 1500/3382, mean loss: 0.07407520897185833\n",
      "Epoch 14/50, iter: 1600/3382, mean loss: 0.059524558988512125\n",
      "Epoch 14/50, iter: 1700/3382, mean loss: 0.0343089820996002\n",
      "Epoch 14/50, iter: 1800/3382, mean loss: 0.25608941017489883\n",
      "Epoch 14/50, iter: 1900/3382, mean loss: 0.3409513349586632\n",
      "Epoch 14/50, iter: 2000/3382, mean loss: 0.23939728242345154\n",
      "Epoch 14/50, iter: 2100/3382, mean loss: 0.17873376850504427\n",
      "Epoch 14/50, iter: 2200/3382, mean loss: 0.13035825405553625\n",
      "Epoch 14/50, iter: 2300/3382, mean loss: 0.11767513368791697\n",
      "Epoch 14/50, iter: 2400/3382, mean loss: 0.06591312338130592\n",
      "Epoch 14/50, iter: 2500/3382, mean loss: 0.04567025870168436\n",
      "Epoch 14/50, iter: 2600/3382, mean loss: 0.3938984137953412\n",
      "Epoch 14/50, iter: 2700/3382, mean loss: 0.22591085118416232\n",
      "Epoch 14/50, iter: 2800/3382, mean loss: 0.1618763912410941\n",
      "Epoch 14/50, iter: 2900/3382, mean loss: 0.16399870977409592\n",
      "Epoch 14/50, iter: 3000/3382, mean loss: 0.12010979794365995\n",
      "Epoch 14/50, iter: 3100/3382, mean loss: 0.07433110405239632\n",
      "Epoch 14/50, iter: 3200/3382, mean loss: 0.07409716940141152\n",
      "Epoch 14/50, iter: 3300/3382, mean loss: 0.05032736901093699\n",
      "Epoch 15/50, iter: 100/3382, mean loss: 0.0894229949565397\n",
      "Epoch 15/50, iter: 200/3382, mean loss: 0.06416491240454889\n",
      "Epoch 15/50, iter: 300/3382, mean loss: 0.02801045655487542\n",
      "Epoch 15/50, iter: 400/3382, mean loss: 0.009472981264032114\n",
      "Epoch 15/50, iter: 500/3382, mean loss: 0.05620460652181009\n",
      "Epoch 15/50, iter: 600/3382, mean loss: 0.028479543743668217\n",
      "Epoch 15/50, iter: 700/3382, mean loss: 0.005149061078780761\n",
      "Epoch 15/50, iter: 800/3382, mean loss: 0.017298576245141247\n",
      "Epoch 15/50, iter: 900/3382, mean loss: 0.08485345409951414\n",
      "Epoch 15/50, iter: 1000/3382, mean loss: 0.10181650907136515\n",
      "Epoch 15/50, iter: 1100/3382, mean loss: 0.16285340894333786\n",
      "Epoch 15/50, iter: 1200/3382, mean loss: 0.13702574006048962\n",
      "Epoch 15/50, iter: 1300/3382, mean loss: 0.1074206890436892\n",
      "Epoch 15/50, iter: 1400/3382, mean loss: 0.10255197796646826\n",
      "Epoch 15/50, iter: 1500/3382, mean loss: 0.06498127465755033\n",
      "Epoch 15/50, iter: 1600/3382, mean loss: 0.07909820840817589\n",
      "Epoch 15/50, iter: 1700/3382, mean loss: 0.0318605438765259\n",
      "Epoch 15/50, iter: 1800/3382, mean loss: 0.24141317184333388\n",
      "Epoch 15/50, iter: 1900/3382, mean loss: 0.347798966091359\n",
      "Epoch 15/50, iter: 2000/3382, mean loss: 0.2725817719695624\n",
      "Epoch 15/50, iter: 2100/3382, mean loss: 0.14766812144895083\n",
      "Epoch 15/50, iter: 2200/3382, mean loss: 0.1261406897084089\n",
      "Epoch 15/50, iter: 2300/3382, mean loss: 0.09995218411233509\n",
      "Epoch 15/50, iter: 2400/3382, mean loss: 0.09488334638161178\n",
      "Epoch 15/50, iter: 2500/3382, mean loss: 0.08411404711499927\n",
      "Epoch 15/50, iter: 2600/3382, mean loss: 0.30832665834208456\n",
      "Epoch 15/50, iter: 2700/3382, mean loss: 0.16752528893994167\n",
      "Epoch 15/50, iter: 2800/3382, mean loss: 0.13476144074855256\n",
      "Epoch 15/50, iter: 2900/3382, mean loss: 0.1647711827403873\n",
      "Epoch 15/50, iter: 3000/3382, mean loss: 0.11939400256451335\n",
      "Epoch 15/50, iter: 3100/3382, mean loss: 0.11405601593434767\n",
      "Epoch 15/50, iter: 3200/3382, mean loss: 0.0807439839948347\n",
      "Epoch 15/50, iter: 3300/3382, mean loss: 0.05305340151045357\n",
      "Epoch 16/50, iter: 100/3382, mean loss: 0.0982317085946488\n",
      "Epoch 16/50, iter: 200/3382, mean loss: 0.07063634055551801\n",
      "Epoch 16/50, iter: 300/3382, mean loss: 0.017981813517380943\n",
      "Epoch 16/50, iter: 400/3382, mean loss: 0.008675744652506125\n",
      "Epoch 16/50, iter: 500/3382, mean loss: 0.03322705656098236\n",
      "Epoch 16/50, iter: 600/3382, mean loss: 0.014917194120815366\n",
      "Epoch 16/50, iter: 700/3382, mean loss: 0.012264477020120807\n",
      "Epoch 16/50, iter: 800/3382, mean loss: 0.04254516093107355\n",
      "Epoch 16/50, iter: 900/3382, mean loss: 0.027016581523866278\n",
      "Epoch 16/50, iter: 1000/3382, mean loss: 0.10103553162095409\n",
      "Epoch 16/50, iter: 1100/3382, mean loss: 0.14348778153362218\n",
      "Epoch 16/50, iter: 1200/3382, mean loss: 0.11751204989504913\n",
      "Epoch 16/50, iter: 1300/3382, mean loss: 0.13694932539885485\n",
      "Epoch 16/50, iter: 1400/3382, mean loss: 0.061743892381891784\n",
      "Epoch 16/50, iter: 1500/3382, mean loss: 0.06603161678853901\n",
      "Epoch 16/50, iter: 1600/3382, mean loss: 0.06922762807243807\n",
      "Epoch 16/50, iter: 1700/3382, mean loss: 0.04253028875283107\n",
      "Epoch 16/50, iter: 1800/3382, mean loss: 0.19505049731928595\n",
      "Epoch 16/50, iter: 1900/3382, mean loss: 0.26194506388215816\n",
      "Epoch 16/50, iter: 2000/3382, mean loss: 0.2046304389933357\n",
      "Epoch 16/50, iter: 2100/3382, mean loss: 0.09174015023629181\n",
      "Epoch 16/50, iter: 2200/3382, mean loss: 0.1417994490293495\n",
      "Epoch 16/50, iter: 2300/3382, mean loss: 0.08246435245988323\n",
      "Epoch 16/50, iter: 2400/3382, mean loss: 0.04622432644046512\n",
      "Epoch 16/50, iter: 2500/3382, mean loss: 0.06710426451532613\n",
      "Epoch 16/50, iter: 2600/3382, mean loss: 0.23762856851128164\n",
      "Epoch 16/50, iter: 2700/3382, mean loss: 0.12930198068148457\n",
      "Epoch 16/50, iter: 2800/3382, mean loss: 0.11304682974787283\n",
      "Epoch 16/50, iter: 2900/3382, mean loss: 0.10376910331662657\n",
      "Epoch 16/50, iter: 3000/3382, mean loss: 0.1287085728918555\n",
      "Epoch 16/50, iter: 3100/3382, mean loss: 0.09619088977367937\n",
      "Epoch 16/50, iter: 3200/3382, mean loss: 0.07700885708074566\n",
      "Epoch 16/50, iter: 3300/3382, mean loss: 0.029037351997686756\n",
      "Epoch 17/50, iter: 100/3382, mean loss: 0.0545930517854049\n",
      "Epoch 17/50, iter: 200/3382, mean loss: 0.050995572375171605\n",
      "Epoch 17/50, iter: 300/3382, mean loss: 0.015466208813029568\n",
      "Epoch 17/50, iter: 400/3382, mean loss: 0.010706458354541155\n",
      "Epoch 17/50, iter: 500/3382, mean loss: 0.0364480400246481\n",
      "Epoch 17/50, iter: 600/3382, mean loss: 0.015656255821607203\n",
      "Epoch 17/50, iter: 700/3382, mean loss: 0.003923793393528357\n",
      "Epoch 17/50, iter: 800/3382, mean loss: 0.006046253844104541\n",
      "Epoch 17/50, iter: 900/3382, mean loss: 0.024741451332094898\n",
      "Epoch 17/50, iter: 1000/3382, mean loss: 0.077460077382243\n",
      "Epoch 17/50, iter: 1100/3382, mean loss: 0.1528599613321421\n",
      "Epoch 17/50, iter: 1200/3382, mean loss: 0.11600529667484807\n",
      "Epoch 17/50, iter: 1300/3382, mean loss: 0.08311431622707233\n",
      "Epoch 17/50, iter: 1400/3382, mean loss: 0.06881807857596187\n",
      "Epoch 17/50, iter: 1500/3382, mean loss: 0.04798169331197243\n",
      "Epoch 17/50, iter: 1600/3382, mean loss: 0.05776553335033583\n",
      "Epoch 17/50, iter: 1700/3382, mean loss: 0.04803638316360263\n",
      "Epoch 17/50, iter: 1800/3382, mean loss: 0.20216379735474305\n",
      "Epoch 17/50, iter: 1900/3382, mean loss: 0.22800618958286578\n",
      "Epoch 17/50, iter: 2000/3382, mean loss: 0.14316045466897775\n",
      "Epoch 17/50, iter: 2100/3382, mean loss: 0.07940379491978092\n",
      "Epoch 17/50, iter: 2200/3382, mean loss: 0.15390714617540652\n",
      "Epoch 17/50, iter: 2300/3382, mean loss: 0.0699204904850194\n",
      "Epoch 17/50, iter: 2400/3382, mean loss: 0.056743063825424545\n",
      "Epoch 17/50, iter: 2500/3382, mean loss: 0.05982583681531878\n",
      "Epoch 17/50, iter: 2600/3382, mean loss: 0.21663816244636108\n",
      "Epoch 17/50, iter: 2700/3382, mean loss: 0.11741069180352497\n",
      "Epoch 17/50, iter: 2800/3382, mean loss: 0.07881003034973219\n",
      "Epoch 17/50, iter: 2900/3382, mean loss: 0.07029618658183608\n",
      "Epoch 17/50, iter: 3000/3382, mean loss: 0.08618414037988259\n",
      "Epoch 17/50, iter: 3100/3382, mean loss: 0.09588833741149756\n",
      "Epoch 17/50, iter: 3200/3382, mean loss: 0.05636318059424184\n",
      "Epoch 17/50, iter: 3300/3382, mean loss: 0.031880188814540134\n",
      "Epoch 18/50, iter: 100/3382, mean loss: 0.16783541577120956\n",
      "Epoch 18/50, iter: 200/3382, mean loss: 0.05285008202115264\n",
      "Epoch 18/50, iter: 300/3382, mean loss: 0.005113161173151184\n",
      "Epoch 18/50, iter: 400/3382, mean loss: 0.00976525453549698\n",
      "Epoch 18/50, iter: 500/3382, mean loss: 0.023581720060084167\n",
      "Epoch 18/50, iter: 600/3382, mean loss: 0.014454712147898476\n",
      "Epoch 18/50, iter: 700/3382, mean loss: 0.005402406767826733\n",
      "Epoch 18/50, iter: 800/3382, mean loss: 0.005104481167109611\n",
      "Epoch 18/50, iter: 900/3382, mean loss: 0.025617279811028765\n",
      "Epoch 18/50, iter: 1000/3382, mean loss: 0.06484991549387889\n",
      "Epoch 18/50, iter: 1100/3382, mean loss: 0.1155833451728904\n",
      "Epoch 18/50, iter: 1200/3382, mean loss: 0.05495915806648554\n",
      "Epoch 18/50, iter: 1300/3382, mean loss: 0.07761324965286803\n",
      "Epoch 18/50, iter: 1400/3382, mean loss: 0.054410204189040315\n",
      "Epoch 18/50, iter: 1500/3382, mean loss: 0.043193889594414114\n",
      "Epoch 18/50, iter: 1600/3382, mean loss: 0.06915681720187429\n",
      "Epoch 18/50, iter: 1700/3382, mean loss: 0.03556444376087668\n",
      "Epoch 18/50, iter: 1800/3382, mean loss: 0.1448174745433316\n",
      "Epoch 18/50, iter: 1900/3382, mean loss: 0.20499257176801622\n",
      "Epoch 18/50, iter: 2000/3382, mean loss: 0.11407563668108196\n",
      "Epoch 18/50, iter: 2100/3382, mean loss: 0.08942736427488854\n",
      "Epoch 18/50, iter: 2200/3382, mean loss: 0.08050846385404384\n",
      "Epoch 18/50, iter: 2300/3382, mean loss: 0.05360199985881536\n",
      "Epoch 18/50, iter: 2400/3382, mean loss: 0.04941748037447155\n",
      "Epoch 18/50, iter: 2500/3382, mean loss: 0.041394681427132124\n",
      "Epoch 18/50, iter: 2600/3382, mean loss: 0.18807753005803535\n",
      "Epoch 18/50, iter: 2700/3382, mean loss: 0.07398371495869469\n",
      "Epoch 18/50, iter: 2800/3382, mean loss: 0.06976386339083547\n",
      "Epoch 18/50, iter: 2900/3382, mean loss: 0.061088833319506645\n",
      "Epoch 18/50, iter: 3000/3382, mean loss: 0.08446529471865802\n",
      "Epoch 18/50, iter: 3100/3382, mean loss: 0.0646697648086797\n",
      "Epoch 18/50, iter: 3200/3382, mean loss: 0.06733518025734611\n",
      "Epoch 18/50, iter: 3300/3382, mean loss: 0.04159995040995369\n",
      "Epoch 19/50, iter: 100/3382, mean loss: 0.09035335487919866\n",
      "Epoch 19/50, iter: 200/3382, mean loss: 0.06037710181230267\n",
      "Epoch 19/50, iter: 300/3382, mean loss: 0.02162091813655593\n",
      "Epoch 19/50, iter: 400/3382, mean loss: 0.0034497440306138927\n",
      "Epoch 19/50, iter: 500/3382, mean loss: 0.01709884701182915\n",
      "Epoch 19/50, iter: 600/3382, mean loss: 0.013369910615842428\n",
      "Epoch 19/50, iter: 700/3382, mean loss: 0.001812176955479714\n",
      "Epoch 19/50, iter: 800/3382, mean loss: 0.00806397414007197\n",
      "Epoch 19/50, iter: 900/3382, mean loss: 0.021128197440381698\n",
      "Epoch 19/50, iter: 1000/3382, mean loss: 0.04393553131238122\n",
      "Epoch 19/50, iter: 1100/3382, mean loss: 0.08773006794106095\n",
      "Epoch 19/50, iter: 1200/3382, mean loss: 0.06558622274991763\n",
      "Epoch 19/50, iter: 1300/3382, mean loss: 0.0416146465172892\n",
      "Epoch 19/50, iter: 1400/3382, mean loss: 0.11523392502354796\n",
      "Epoch 19/50, iter: 1500/3382, mean loss: 0.06490404372290896\n",
      "Epoch 19/50, iter: 1600/3382, mean loss: 0.06207935267205155\n",
      "Epoch 19/50, iter: 1700/3382, mean loss: 0.029070110500457852\n",
      "Epoch 19/50, iter: 1800/3382, mean loss: 0.14214813947041563\n",
      "Epoch 19/50, iter: 1900/3382, mean loss: 0.1593219204147499\n",
      "Epoch 19/50, iter: 2000/3382, mean loss: 0.14215158716280712\n",
      "Epoch 19/50, iter: 2100/3382, mean loss: 0.06367832922186607\n",
      "Epoch 19/50, iter: 2200/3382, mean loss: 0.11544536861038068\n",
      "Epoch 19/50, iter: 2300/3382, mean loss: 0.08089209426870184\n",
      "Epoch 19/50, iter: 2400/3382, mean loss: 0.0509628218532157\n",
      "Epoch 19/50, iter: 2500/3382, mean loss: 0.08298614397235723\n",
      "Epoch 19/50, iter: 2600/3382, mean loss: 0.13552571640768293\n",
      "Epoch 19/50, iter: 2700/3382, mean loss: 0.041537261697126265\n",
      "Epoch 19/50, iter: 2800/3382, mean loss: 0.062363614470186804\n",
      "Epoch 19/50, iter: 2900/3382, mean loss: 0.06921478160264996\n",
      "Epoch 19/50, iter: 3000/3382, mean loss: 0.08329778393806464\n",
      "Epoch 19/50, iter: 3100/3382, mean loss: 0.055128212219119635\n",
      "Epoch 19/50, iter: 3200/3382, mean loss: 0.05757895148053478\n",
      "Epoch 19/50, iter: 3300/3382, mean loss: 0.03734087775344221\n",
      "Epoch 20/50, iter: 100/3382, mean loss: 0.06679808636880238\n",
      "Epoch 20/50, iter: 200/3382, mean loss: 0.04640705921188768\n",
      "Epoch 20/50, iter: 300/3382, mean loss: 0.004626913405733362\n",
      "Epoch 20/50, iter: 400/3382, mean loss: 0.006617013407103833\n",
      "Epoch 20/50, iter: 500/3382, mean loss: 0.0202793517673301\n",
      "Epoch 20/50, iter: 600/3382, mean loss: 0.006276929606574591\n",
      "Epoch 20/50, iter: 700/3382, mean loss: 0.0017904621144686672\n",
      "Epoch 20/50, iter: 800/3382, mean loss: 0.020868257254122648\n",
      "Epoch 20/50, iter: 900/3382, mean loss: 0.008843610925899697\n",
      "Epoch 20/50, iter: 1000/3382, mean loss: 0.05260513672578984\n",
      "Epoch 20/50, iter: 1100/3382, mean loss: 0.05917467616710837\n",
      "Epoch 20/50, iter: 1200/3382, mean loss: 0.07306799935133312\n",
      "Epoch 20/50, iter: 1300/3382, mean loss: 0.06894863124693301\n",
      "Epoch 20/50, iter: 1400/3382, mean loss: 0.05558809248149402\n",
      "Epoch 20/50, iter: 1500/3382, mean loss: 0.039339078994284835\n",
      "Epoch 20/50, iter: 1600/3382, mean loss: 0.03513010891876988\n",
      "Epoch 20/50, iter: 1700/3382, mean loss: 0.021038874974700333\n",
      "Epoch 20/50, iter: 1800/3382, mean loss: 0.07528814720752748\n",
      "Epoch 20/50, iter: 1900/3382, mean loss: 0.1442802416478935\n",
      "Epoch 20/50, iter: 2000/3382, mean loss: 0.11510122100669833\n",
      "Epoch 20/50, iter: 2100/3382, mean loss: 0.07909176990363448\n",
      "Epoch 20/50, iter: 2200/3382, mean loss: 0.08124964316416027\n",
      "Epoch 20/50, iter: 2300/3382, mean loss: 0.07837454418696552\n",
      "Epoch 20/50, iter: 2400/3382, mean loss: 0.04735716360301467\n",
      "Epoch 20/50, iter: 2500/3382, mean loss: 0.04726706972322063\n",
      "Epoch 20/50, iter: 2600/3382, mean loss: 0.1400441861209538\n",
      "Epoch 20/50, iter: 2700/3382, mean loss: 0.04972155667535844\n",
      "Epoch 20/50, iter: 2800/3382, mean loss: 0.051677346197520964\n",
      "Epoch 20/50, iter: 2900/3382, mean loss: 0.07931526850587602\n",
      "Epoch 20/50, iter: 3000/3382, mean loss: 0.056674628601574566\n",
      "Epoch 20/50, iter: 3100/3382, mean loss: 0.04589030796070801\n",
      "Epoch 20/50, iter: 3200/3382, mean loss: 0.062265942762404054\n",
      "Epoch 20/50, iter: 3300/3382, mean loss: 0.035642343173720406\n",
      "Epoch 21/50, iter: 100/3382, mean loss: 0.04706714046756009\n",
      "Epoch 21/50, iter: 200/3382, mean loss: 0.049895480094985276\n",
      "Epoch 21/50, iter: 300/3382, mean loss: 0.0037814329159409966\n",
      "Epoch 21/50, iter: 400/3382, mean loss: 0.003926260576607526\n",
      "Epoch 21/50, iter: 500/3382, mean loss: 0.008431018361790877\n",
      "Epoch 21/50, iter: 600/3382, mean loss: 0.014225180138569939\n",
      "Epoch 21/50, iter: 700/3382, mean loss: 0.031590831848032824\n",
      "Epoch 21/50, iter: 800/3382, mean loss: 0.007161247029855211\n",
      "Epoch 21/50, iter: 900/3382, mean loss: 0.005274846341139216\n",
      "Epoch 21/50, iter: 1000/3382, mean loss: 0.015221813797167947\n",
      "Epoch 21/50, iter: 1100/3382, mean loss: 0.05395702461337354\n",
      "Epoch 21/50, iter: 1200/3382, mean loss: 0.05067932723634417\n",
      "Epoch 21/50, iter: 1300/3382, mean loss: 0.04520359559134022\n",
      "Epoch 21/50, iter: 1400/3382, mean loss: 0.04354190513818921\n",
      "Epoch 21/50, iter: 1500/3382, mean loss: 0.047480675200054064\n",
      "Epoch 21/50, iter: 1600/3382, mean loss: 0.054766610915632584\n",
      "Epoch 21/50, iter: 1700/3382, mean loss: 0.021110200739906163\n",
      "Epoch 21/50, iter: 1800/3382, mean loss: 0.10115662208075171\n",
      "Epoch 21/50, iter: 1900/3382, mean loss: 0.14136204501929797\n",
      "Epoch 21/50, iter: 2000/3382, mean loss: 0.06414252845753253\n",
      "Epoch 21/50, iter: 2100/3382, mean loss: 0.08724386626554406\n",
      "Epoch 21/50, iter: 2200/3382, mean loss: 0.05407116509648631\n",
      "Epoch 21/50, iter: 2300/3382, mean loss: 0.04832387399209722\n",
      "Epoch 21/50, iter: 2400/3382, mean loss: 0.024733220454432967\n",
      "Epoch 21/50, iter: 2500/3382, mean loss: 0.0315952103414719\n",
      "Epoch 21/50, iter: 2600/3382, mean loss: 0.1587299818617794\n",
      "Epoch 21/50, iter: 2700/3382, mean loss: 0.04799034672303492\n",
      "Epoch 21/50, iter: 2800/3382, mean loss: 0.03525766243345231\n",
      "Epoch 21/50, iter: 2900/3382, mean loss: 0.058320714068340745\n",
      "Epoch 21/50, iter: 3000/3382, mean loss: 0.08252207734179137\n",
      "Epoch 21/50, iter: 3100/3382, mean loss: 0.03078296528647172\n",
      "Epoch 21/50, iter: 3200/3382, mean loss: 0.040305261416942885\n",
      "Epoch 21/50, iter: 3300/3382, mean loss: 0.02276820392803856\n",
      "Epoch 22/50, iter: 100/3382, mean loss: 0.05265405609737275\n",
      "Epoch 22/50, iter: 200/3382, mean loss: 0.06172838708725528\n",
      "Epoch 22/50, iter: 300/3382, mean loss: 0.011475936429998158\n",
      "Epoch 22/50, iter: 400/3382, mean loss: 0.008372942144447464\n",
      "Epoch 22/50, iter: 500/3382, mean loss: 0.014573183990951507\n",
      "Epoch 22/50, iter: 600/3382, mean loss: 0.0073510325752055294\n",
      "Epoch 22/50, iter: 700/3382, mean loss: 0.007272731701788473\n",
      "Epoch 22/50, iter: 800/3382, mean loss: 0.0018936529324389895\n",
      "Epoch 22/50, iter: 900/3382, mean loss: 0.01454917881224592\n",
      "Epoch 22/50, iter: 1000/3382, mean loss: 0.034845382590029776\n",
      "Epoch 22/50, iter: 1100/3382, mean loss: 0.039443008320380384\n",
      "Epoch 22/50, iter: 1200/3382, mean loss: 0.07753099351847823\n",
      "Epoch 22/50, iter: 1300/3382, mean loss: 0.034597242987146115\n",
      "Epoch 22/50, iter: 1400/3382, mean loss: 0.03558019828980868\n",
      "Epoch 22/50, iter: 1500/3382, mean loss: 0.03590719357271205\n",
      "Epoch 22/50, iter: 1600/3382, mean loss: 0.03615821801971283\n",
      "Epoch 22/50, iter: 1700/3382, mean loss: 0.03473766262902437\n",
      "Epoch 22/50, iter: 1800/3382, mean loss: 0.06406491919889355\n",
      "Epoch 22/50, iter: 1900/3382, mean loss: 0.08754821641125432\n",
      "Epoch 22/50, iter: 2000/3382, mean loss: 0.055463310030402224\n",
      "Epoch 22/50, iter: 2100/3382, mean loss: 0.05412224064149143\n",
      "Epoch 22/50, iter: 2200/3382, mean loss: 0.049808761288675216\n",
      "Epoch 22/50, iter: 2300/3382, mean loss: 0.024608607144450616\n",
      "Epoch 22/50, iter: 2400/3382, mean loss: 0.028861411801965744\n",
      "Epoch 22/50, iter: 2500/3382, mean loss: 0.03754807248054405\n",
      "Epoch 22/50, iter: 2600/3382, mean loss: 0.1135050922656228\n",
      "Epoch 22/50, iter: 2700/3382, mean loss: 0.08910569877283855\n",
      "Epoch 22/50, iter: 2800/3382, mean loss: 0.04369318297316226\n",
      "Epoch 22/50, iter: 2900/3382, mean loss: 0.038817799614056486\n",
      "Epoch 22/50, iter: 3000/3382, mean loss: 0.03962892224681013\n",
      "Epoch 22/50, iter: 3100/3382, mean loss: 0.05637311913072509\n",
      "Epoch 22/50, iter: 3200/3382, mean loss: 0.03086672503191867\n",
      "Epoch 22/50, iter: 3300/3382, mean loss: 0.04375242285479913\n",
      "Epoch 23/50, iter: 100/3382, mean loss: 0.045006857170671426\n",
      "Epoch 23/50, iter: 200/3382, mean loss: 0.05328713303187801\n",
      "Epoch 23/50, iter: 300/3382, mean loss: 0.0060127068749105915\n",
      "Epoch 23/50, iter: 400/3382, mean loss: 0.06927746145907246\n",
      "Epoch 23/50, iter: 500/3382, mean loss: 0.029584037754242443\n",
      "Epoch 23/50, iter: 600/3382, mean loss: 0.005703271180111962\n",
      "Epoch 23/50, iter: 700/3382, mean loss: 0.02625884886680691\n",
      "Epoch 23/50, iter: 800/3382, mean loss: 0.01184453417222418\n",
      "Epoch 23/50, iter: 900/3382, mean loss: 0.00629640458445941\n",
      "Epoch 23/50, iter: 1000/3382, mean loss: 0.04101658282307593\n",
      "Epoch 23/50, iter: 1100/3382, mean loss: 0.0911703060065713\n",
      "Epoch 23/50, iter: 1200/3382, mean loss: 0.07137359652796263\n",
      "Epoch 23/50, iter: 1300/3382, mean loss: 0.07817852898337492\n",
      "Epoch 23/50, iter: 1400/3382, mean loss: 0.08635169089473958\n",
      "Epoch 23/50, iter: 1500/3382, mean loss: 0.05687761369845194\n",
      "Epoch 23/50, iter: 1600/3382, mean loss: 0.09888296184384679\n",
      "Epoch 23/50, iter: 1700/3382, mean loss: 0.025131261765510546\n",
      "Epoch 23/50, iter: 1800/3382, mean loss: 0.15330962293355044\n",
      "Epoch 23/50, iter: 1900/3382, mean loss: 0.13174456625674225\n",
      "Epoch 23/50, iter: 2000/3382, mean loss: 0.07759198861093865\n",
      "Epoch 23/50, iter: 2100/3382, mean loss: 0.06357832892221722\n",
      "Epoch 23/50, iter: 2200/3382, mean loss: 0.10229759762525191\n",
      "Epoch 23/50, iter: 2300/3382, mean loss: 0.041791150080606486\n",
      "Epoch 23/50, iter: 2400/3382, mean loss: 0.03681695707150709\n",
      "Epoch 23/50, iter: 2500/3382, mean loss: 0.023113135738268512\n",
      "Epoch 23/50, iter: 2600/3382, mean loss: 0.08381147952884134\n",
      "Epoch 23/50, iter: 2700/3382, mean loss: 0.04409212085036188\n",
      "Epoch 23/50, iter: 2800/3382, mean loss: 0.03289037494639757\n",
      "Epoch 23/50, iter: 2900/3382, mean loss: 0.05378854817538695\n",
      "Epoch 23/50, iter: 3000/3382, mean loss: 0.04458299430764612\n",
      "Epoch 23/50, iter: 3100/3382, mean loss: 0.04174127741835932\n",
      "Epoch 23/50, iter: 3200/3382, mean loss: 0.04672846819734673\n",
      "Epoch 23/50, iter: 3300/3382, mean loss: 0.010571412233043703\n",
      "Epoch 24/50, iter: 100/3382, mean loss: 0.037964818453086906\n",
      "Epoch 24/50, iter: 200/3382, mean loss: 0.03155221282768366\n",
      "Epoch 24/50, iter: 300/3382, mean loss: 0.0012302764737186678\n",
      "Epoch 24/50, iter: 400/3382, mean loss: 0.01079837946257843\n",
      "Epoch 24/50, iter: 500/3382, mean loss: 0.04488826666630562\n",
      "Epoch 24/50, iter: 600/3382, mean loss: 0.016334614041534044\n",
      "Epoch 24/50, iter: 700/3382, mean loss: 0.0108590077722641\n",
      "Epoch 24/50, iter: 800/3382, mean loss: 0.005184099839554044\n",
      "Epoch 24/50, iter: 900/3382, mean loss: 0.0043923082101768075\n",
      "Epoch 24/50, iter: 1000/3382, mean loss: 0.03139018264543381\n",
      "Epoch 24/50, iter: 1100/3382, mean loss: 0.07220149968177428\n",
      "Epoch 24/50, iter: 1200/3382, mean loss: 0.042061389812955666\n",
      "Epoch 24/50, iter: 1300/3382, mean loss: 0.04235197041905714\n",
      "Epoch 24/50, iter: 1400/3382, mean loss: 0.036713235436337116\n",
      "Epoch 24/50, iter: 1500/3382, mean loss: 0.05457977199390715\n",
      "Epoch 24/50, iter: 1600/3382, mean loss: 0.050168151409856775\n",
      "Epoch 24/50, iter: 1700/3382, mean loss: 0.008738414140188625\n",
      "Epoch 24/50, iter: 1800/3382, mean loss: 0.06829526865823084\n",
      "Epoch 24/50, iter: 1900/3382, mean loss: 0.06958797989834921\n",
      "Epoch 24/50, iter: 2000/3382, mean loss: 0.02823362900071061\n",
      "Epoch 24/50, iter: 2100/3382, mean loss: 0.08175585759751357\n",
      "Epoch 24/50, iter: 2200/3382, mean loss: 0.07201336058307561\n",
      "Epoch 24/50, iter: 2300/3382, mean loss: 0.029813776834595275\n",
      "Epoch 24/50, iter: 2400/3382, mean loss: 0.022481390587875013\n",
      "Epoch 24/50, iter: 2500/3382, mean loss: 0.03113656756844023\n",
      "Epoch 24/50, iter: 2600/3382, mean loss: 0.14928851468816673\n",
      "Epoch 24/50, iter: 2700/3382, mean loss: 0.02515166094775978\n",
      "Epoch 24/50, iter: 2800/3382, mean loss: 0.043565458791704544\n",
      "Epoch 24/50, iter: 2900/3382, mean loss: 0.02491465314986133\n",
      "Epoch 24/50, iter: 3000/3382, mean loss: 0.022747636289877277\n",
      "Epoch 24/50, iter: 3100/3382, mean loss: 0.026529243219738242\n",
      "Epoch 24/50, iter: 3200/3382, mean loss: 0.02955935072086575\n",
      "Epoch 24/50, iter: 3300/3382, mean loss: 0.016600214167754784\n",
      "Epoch 25/50, iter: 100/3382, mean loss: 0.018465514682963473\n",
      "Epoch 25/50, iter: 200/3382, mean loss: 0.015077702941727295\n",
      "Epoch 25/50, iter: 300/3382, mean loss: 0.003186457067383799\n",
      "Epoch 25/50, iter: 400/3382, mean loss: 0.018035356884310298\n",
      "Epoch 25/50, iter: 500/3382, mean loss: 0.009890721442593566\n",
      "Epoch 25/50, iter: 600/3382, mean loss: 0.0067645439839551\n",
      "Epoch 25/50, iter: 700/3382, mean loss: 0.00036912446987713565\n",
      "Epoch 25/50, iter: 800/3382, mean loss: 0.00034926710550191585\n",
      "Epoch 25/50, iter: 900/3382, mean loss: 0.006402980228932051\n",
      "Epoch 25/50, iter: 1000/3382, mean loss: 0.0070067011723766726\n",
      "Epoch 25/50, iter: 1100/3382, mean loss: 0.033938471103368784\n",
      "Epoch 25/50, iter: 1200/3382, mean loss: 0.049310419732180505\n",
      "Epoch 25/50, iter: 1300/3382, mean loss: 0.02883572891854449\n",
      "Epoch 25/50, iter: 1400/3382, mean loss: 0.026856987814458506\n",
      "Epoch 25/50, iter: 1500/3382, mean loss: 0.026875058246683813\n",
      "Epoch 25/50, iter: 1600/3382, mean loss: 0.03842631363947152\n",
      "Epoch 25/50, iter: 1700/3382, mean loss: 0.032989675968189046\n",
      "Epoch 25/50, iter: 1800/3382, mean loss: 0.05244493717091874\n",
      "Epoch 25/50, iter: 1900/3382, mean loss: 0.0923225521203284\n",
      "Epoch 25/50, iter: 2000/3382, mean loss: 0.03611800818222605\n",
      "Epoch 25/50, iter: 2100/3382, mean loss: 0.07386090327910778\n",
      "Epoch 25/50, iter: 2200/3382, mean loss: 0.0779630107240726\n",
      "Epoch 25/50, iter: 2300/3382, mean loss: 0.08877015207863125\n",
      "Epoch 25/50, iter: 2400/3382, mean loss: 0.03743667217224875\n",
      "Epoch 25/50, iter: 2500/3382, mean loss: 0.020793278707258195\n",
      "Epoch 25/50, iter: 2600/3382, mean loss: 0.07945703743563598\n",
      "Epoch 25/50, iter: 2700/3382, mean loss: 0.03063158848778784\n",
      "Epoch 25/50, iter: 2800/3382, mean loss: 0.04422379738984517\n",
      "Epoch 25/50, iter: 2900/3382, mean loss: 0.028114777858693856\n",
      "Epoch 25/50, iter: 3000/3382, mean loss: 0.02270515120827298\n",
      "Epoch 25/50, iter: 3100/3382, mean loss: 0.023532782423388382\n",
      "Epoch 25/50, iter: 3200/3382, mean loss: 0.03169415831018256\n",
      "Epoch 25/50, iter: 3300/3382, mean loss: 0.013827631321543734\n",
      "Epoch 26/50, iter: 100/3382, mean loss: 0.03868066631656273\n",
      "Epoch 26/50, iter: 200/3382, mean loss: 0.027365076619916485\n",
      "Epoch 26/50, iter: 300/3382, mean loss: 0.0019951730201652395\n",
      "Epoch 26/50, iter: 400/3382, mean loss: 0.004781950419351873\n",
      "Epoch 26/50, iter: 500/3382, mean loss: 0.01475937090670449\n",
      "Epoch 26/50, iter: 600/3382, mean loss: 0.003145264641573604\n",
      "Epoch 26/50, iter: 700/3382, mean loss: 0.00185813793253935\n",
      "Epoch 26/50, iter: 800/3382, mean loss: 0.00824533111310206\n",
      "Epoch 26/50, iter: 900/3382, mean loss: 0.0036917799831023145\n",
      "Epoch 26/50, iter: 1000/3382, mean loss: 0.038147384805831096\n",
      "Epoch 26/50, iter: 1100/3382, mean loss: 0.040536769949660684\n",
      "Epoch 26/50, iter: 1200/3382, mean loss: 0.058456448343776016\n",
      "Epoch 26/50, iter: 1300/3382, mean loss: 0.025148053359142324\n",
      "Epoch 26/50, iter: 1400/3382, mean loss: 0.03247583370294518\n",
      "Epoch 26/50, iter: 1500/3382, mean loss: 0.04337683600792367\n",
      "Epoch 26/50, iter: 1600/3382, mean loss: 0.03810872206656924\n",
      "Epoch 26/50, iter: 1700/3382, mean loss: 0.017849085947107816\n",
      "Epoch 26/50, iter: 1800/3382, mean loss: 0.058754918419185315\n",
      "Epoch 26/50, iter: 1900/3382, mean loss: 0.08900985390754848\n",
      "Epoch 26/50, iter: 2000/3382, mean loss: 0.03949681634204182\n",
      "Epoch 26/50, iter: 2100/3382, mean loss: 0.029307963240973435\n",
      "Epoch 26/50, iter: 2200/3382, mean loss: 0.04932018199232317\n",
      "Epoch 26/50, iter: 2300/3382, mean loss: 0.028703138906493172\n",
      "Epoch 26/50, iter: 2400/3382, mean loss: 0.041526498457221804\n",
      "Epoch 26/50, iter: 2500/3382, mean loss: 0.015150347188396154\n",
      "Epoch 26/50, iter: 2600/3382, mean loss: 0.1301057226291359\n",
      "Epoch 26/50, iter: 2700/3382, mean loss: 0.02349135910635482\n",
      "Epoch 26/50, iter: 2800/3382, mean loss: 0.02194890619686504\n",
      "Epoch 26/50, iter: 2900/3382, mean loss: 0.037247746560889326\n",
      "Epoch 26/50, iter: 3000/3382, mean loss: 0.027345176970095652\n",
      "Epoch 26/50, iter: 3100/3382, mean loss: 0.022992006530528533\n",
      "Epoch 26/50, iter: 3200/3382, mean loss: 0.03415305706473376\n",
      "Epoch 26/50, iter: 3300/3382, mean loss: 0.024418713815386538\n",
      "Epoch 27/50, iter: 100/3382, mean loss: 0.01888337277436488\n",
      "Epoch 27/50, iter: 200/3382, mean loss: 0.022437583690911752\n",
      "Epoch 27/50, iter: 300/3382, mean loss: 0.004482146466065231\n",
      "Epoch 27/50, iter: 400/3382, mean loss: 0.0018389924707542704\n",
      "Epoch 27/50, iter: 500/3382, mean loss: 0.005614937873814547\n",
      "Epoch 27/50, iter: 600/3382, mean loss: 0.007178898493036598\n",
      "Epoch 27/50, iter: 700/3382, mean loss: 0.003101948716728913\n",
      "Epoch 27/50, iter: 800/3382, mean loss: 0.003257635407930195\n",
      "Epoch 27/50, iter: 900/3382, mean loss: 0.003191094502965974\n",
      "Epoch 27/50, iter: 1000/3382, mean loss: 0.05252249050711981\n",
      "Epoch 27/50, iter: 1100/3382, mean loss: 0.029333282511349593\n",
      "Epoch 27/50, iter: 1200/3382, mean loss: 0.032956911504467355\n",
      "Epoch 27/50, iter: 1300/3382, mean loss: 0.01986977639086426\n",
      "Epoch 27/50, iter: 1400/3382, mean loss: 0.02564772982641081\n",
      "Epoch 27/50, iter: 1500/3382, mean loss: 0.021354149682094706\n",
      "Epoch 27/50, iter: 1600/3382, mean loss: 0.03467985684736668\n",
      "Epoch 27/50, iter: 1700/3382, mean loss: 0.012891505773745244\n",
      "Epoch 27/50, iter: 1800/3382, mean loss: 0.04512340845280132\n",
      "Epoch 27/50, iter: 1900/3382, mean loss: 0.08918063698632267\n",
      "Epoch 27/50, iter: 2000/3382, mean loss: 0.021263830595480614\n",
      "Epoch 27/50, iter: 2100/3382, mean loss: 0.049500702388630774\n",
      "Epoch 27/50, iter: 2200/3382, mean loss: 0.030739302726011105\n",
      "Epoch 27/50, iter: 2300/3382, mean loss: 0.03316919644476922\n",
      "Epoch 27/50, iter: 2400/3382, mean loss: 0.023600938467211775\n",
      "Epoch 27/50, iter: 2500/3382, mean loss: 0.03148238034306701\n",
      "Epoch 27/50, iter: 2600/3382, mean loss: 0.07207553232857322\n",
      "Epoch 27/50, iter: 2700/3382, mean loss: 0.061549830882750595\n",
      "Epoch 27/50, iter: 2800/3382, mean loss: 0.026392832427250212\n",
      "Epoch 27/50, iter: 2900/3382, mean loss: 0.01764762629529134\n",
      "Epoch 27/50, iter: 3000/3382, mean loss: 0.03694966627594809\n",
      "Epoch 27/50, iter: 3100/3382, mean loss: 0.013393999340218414\n",
      "Epoch 27/50, iter: 3200/3382, mean loss: 0.020164264962887195\n",
      "Epoch 27/50, iter: 3300/3382, mean loss: 0.01336220367865323\n",
      "Epoch 28/50, iter: 100/3382, mean loss: 0.018407890657904637\n",
      "Epoch 28/50, iter: 200/3382, mean loss: 0.022129740337014495\n",
      "Epoch 28/50, iter: 300/3382, mean loss: 0.01167639522740938\n",
      "Epoch 28/50, iter: 400/3382, mean loss: 0.0025574996155835095\n",
      "Epoch 28/50, iter: 500/3382, mean loss: 0.010843589800369528\n",
      "Epoch 28/50, iter: 600/3382, mean loss: 0.013998072102216702\n",
      "Epoch 28/50, iter: 700/3382, mean loss: 0.00022843448077612295\n",
      "Epoch 28/50, iter: 800/3382, mean loss: 0.0005488728833205059\n",
      "Epoch 28/50, iter: 900/3382, mean loss: 0.00046716136315762215\n",
      "Epoch 28/50, iter: 1000/3382, mean loss: 0.012006497560868787\n",
      "Epoch 28/50, iter: 1100/3382, mean loss: 0.03044756140696421\n",
      "Epoch 28/50, iter: 1200/3382, mean loss: 0.04389179242967046\n",
      "Epoch 28/50, iter: 1300/3382, mean loss: 0.03207511562486911\n",
      "Epoch 28/50, iter: 1400/3382, mean loss: 0.017240959566824258\n",
      "Epoch 28/50, iter: 1500/3382, mean loss: 0.027461840051875654\n",
      "Epoch 28/50, iter: 1600/3382, mean loss: 0.013126808200426722\n",
      "Epoch 28/50, iter: 1700/3382, mean loss: 0.022733636553369616\n",
      "Epoch 28/50, iter: 1800/3382, mean loss: 0.08266799120407946\n",
      "Epoch 28/50, iter: 1900/3382, mean loss: 0.06578515552404723\n",
      "Epoch 28/50, iter: 2000/3382, mean loss: 0.03463244316015576\n",
      "Epoch 28/50, iter: 2100/3382, mean loss: 0.024405059285086707\n",
      "Epoch 28/50, iter: 2200/3382, mean loss: 0.09290476318383696\n",
      "Epoch 28/50, iter: 2300/3382, mean loss: 0.03899837688027048\n",
      "Epoch 28/50, iter: 2400/3382, mean loss: 0.024632825176097058\n",
      "Epoch 28/50, iter: 2500/3382, mean loss: 0.0120902710498423\n",
      "Epoch 28/50, iter: 2600/3382, mean loss: 0.10654513531845432\n",
      "Epoch 28/50, iter: 2700/3382, mean loss: 0.08675118387581747\n",
      "Epoch 28/50, iter: 2800/3382, mean loss: 0.029660228083221156\n",
      "Epoch 28/50, iter: 2900/3382, mean loss: 0.009996774136321917\n",
      "Epoch 28/50, iter: 3000/3382, mean loss: 0.015920203466435582\n",
      "Epoch 28/50, iter: 3100/3382, mean loss: 0.02527063670187637\n",
      "Epoch 28/50, iter: 3200/3382, mean loss: 0.028227976503083774\n",
      "Epoch 28/50, iter: 3300/3382, mean loss: 0.031930986028754764\n",
      "Epoch 29/50, iter: 100/3382, mean loss: 0.015256966824409836\n",
      "Epoch 29/50, iter: 200/3382, mean loss: 0.02826374113603414\n",
      "Epoch 29/50, iter: 300/3382, mean loss: 0.0014229232347324227\n",
      "Epoch 29/50, iter: 400/3382, mean loss: 0.0007634657540726409\n",
      "Epoch 29/50, iter: 500/3382, mean loss: 0.003558709756584939\n",
      "Epoch 29/50, iter: 600/3382, mean loss: 0.0017960112558121821\n",
      "Epoch 29/50, iter: 700/3382, mean loss: 0.00010636726285358834\n",
      "Epoch 29/50, iter: 800/3382, mean loss: 0.00294280256196938\n",
      "Epoch 29/50, iter: 900/3382, mean loss: 0.006552706366907622\n",
      "Epoch 29/50, iter: 1000/3382, mean loss: 0.0038143512928464317\n",
      "Epoch 29/50, iter: 1100/3382, mean loss: 0.04022918953680037\n",
      "Epoch 29/50, iter: 1200/3382, mean loss: 0.038473059591089154\n",
      "Epoch 29/50, iter: 1300/3382, mean loss: 0.047614801890579234\n",
      "Epoch 29/50, iter: 1400/3382, mean loss: 0.037439221179303636\n",
      "Epoch 29/50, iter: 1500/3382, mean loss: 0.018849299150918916\n",
      "Epoch 29/50, iter: 1600/3382, mean loss: 0.09901758682649224\n",
      "Epoch 29/50, iter: 1700/3382, mean loss: 0.003622873943335989\n",
      "Epoch 29/50, iter: 1800/3382, mean loss: 0.036878337431489924\n",
      "Epoch 29/50, iter: 1900/3382, mean loss: 0.08380398205523747\n",
      "Epoch 29/50, iter: 2000/3382, mean loss: 0.013051388104209423\n",
      "Epoch 29/50, iter: 2100/3382, mean loss: 0.0366561966713158\n",
      "Epoch 29/50, iter: 2200/3382, mean loss: 0.03975447425138199\n",
      "Epoch 29/50, iter: 2300/3382, mean loss: 0.055387806768051245\n",
      "Epoch 29/50, iter: 2400/3382, mean loss: 0.04371077480512511\n",
      "Epoch 29/50, iter: 2500/3382, mean loss: 0.019960794340301433\n",
      "Epoch 29/50, iter: 2600/3382, mean loss: 0.05186947250040937\n",
      "Epoch 29/50, iter: 2700/3382, mean loss: 0.03664167968638139\n",
      "Epoch 29/50, iter: 2800/3382, mean loss: 0.025424090945863682\n",
      "Epoch 29/50, iter: 2900/3382, mean loss: 0.029417241621544365\n",
      "Epoch 29/50, iter: 3000/3382, mean loss: 0.028714442131337704\n",
      "Epoch 29/50, iter: 3100/3382, mean loss: 0.03814597449903772\n",
      "Epoch 29/50, iter: 3200/3382, mean loss: 0.010430945226692571\n",
      "Epoch 29/50, iter: 3300/3382, mean loss: 0.021294679272914615\n",
      "Epoch 30/50, iter: 100/3382, mean loss: 0.013152250525176434\n",
      "Epoch 30/50, iter: 200/3382, mean loss: 0.01364414207206238\n",
      "Epoch 30/50, iter: 300/3382, mean loss: 0.0003872839655796412\n",
      "Epoch 30/50, iter: 400/3382, mean loss: 0.0011255038562254427\n",
      "Epoch 30/50, iter: 500/3382, mean loss: 0.012731665867411089\n",
      "Epoch 30/50, iter: 600/3382, mean loss: 0.0042124867175085965\n",
      "Epoch 30/50, iter: 700/3382, mean loss: 0.00010552823251710919\n",
      "Epoch 30/50, iter: 800/3382, mean loss: 0.00038393339112346325\n",
      "Epoch 30/50, iter: 900/3382, mean loss: 0.06169541467572912\n",
      "Epoch 30/50, iter: 1000/3382, mean loss: 0.0035538268163506003\n",
      "Epoch 30/50, iter: 1100/3382, mean loss: 0.020705789303823465\n",
      "Epoch 30/50, iter: 1200/3382, mean loss: 0.032113527934844795\n",
      "Epoch 30/50, iter: 1300/3382, mean loss: 0.029727382784696877\n",
      "Epoch 30/50, iter: 1400/3382, mean loss: 0.012797372699406572\n",
      "Epoch 30/50, iter: 1500/3382, mean loss: 0.009207835578072832\n",
      "Epoch 30/50, iter: 1600/3382, mean loss: 0.056548827635626006\n",
      "Epoch 30/50, iter: 1700/3382, mean loss: 0.008185246724960536\n",
      "Epoch 30/50, iter: 1800/3382, mean loss: 0.042482788278456134\n",
      "Epoch 30/50, iter: 1900/3382, mean loss: 0.10489691044762114\n",
      "Epoch 30/50, iter: 2000/3382, mean loss: 0.027484818895957944\n",
      "Epoch 30/50, iter: 2100/3382, mean loss: 0.019548808028275317\n",
      "Epoch 30/50, iter: 2200/3382, mean loss: 0.053177232959701184\n",
      "Epoch 30/50, iter: 2300/3382, mean loss: 0.015100929124469076\n",
      "Epoch 30/50, iter: 2400/3382, mean loss: 0.021725425432432246\n",
      "Epoch 30/50, iter: 2500/3382, mean loss: 0.020238290440227614\n",
      "Epoch 30/50, iter: 2600/3382, mean loss: 0.0598291416535227\n",
      "Epoch 30/50, iter: 2700/3382, mean loss: 0.044856121278636786\n",
      "Epoch 30/50, iter: 2800/3382, mean loss: 0.016383524813805082\n",
      "Epoch 30/50, iter: 2900/3382, mean loss: 0.030999417921925777\n",
      "Epoch 30/50, iter: 3000/3382, mean loss: 0.013309067116056355\n",
      "Epoch 30/50, iter: 3100/3382, mean loss: 0.026836496058977168\n",
      "Epoch 30/50, iter: 3200/3382, mean loss: 0.0343763929693586\n",
      "Epoch 30/50, iter: 3300/3382, mean loss: 0.011955313095931643\n",
      "Epoch 31/50, iter: 100/3382, mean loss: 0.006237337285819997\n",
      "Epoch 31/50, iter: 200/3382, mean loss: 0.035965928304957054\n",
      "Epoch 31/50, iter: 300/3382, mean loss: 0.0017109919016311892\n",
      "Epoch 31/50, iter: 400/3382, mean loss: 0.0003242823220063684\n",
      "Epoch 31/50, iter: 500/3382, mean loss: 0.008259351761311748\n",
      "Epoch 31/50, iter: 600/3382, mean loss: 0.03433633657655673\n",
      "Epoch 31/50, iter: 700/3382, mean loss: 0.0008876433481909984\n",
      "Epoch 31/50, iter: 800/3382, mean loss: 0.003778529059262681\n",
      "Epoch 31/50, iter: 900/3382, mean loss: 0.00015768010911877185\n",
      "Epoch 31/50, iter: 1000/3382, mean loss: 0.0062739834844850505\n",
      "Epoch 31/50, iter: 1100/3382, mean loss: 0.03134296825551488\n",
      "Epoch 31/50, iter: 1200/3382, mean loss: 0.017944292629799036\n",
      "Epoch 31/50, iter: 1300/3382, mean loss: 0.029297641618747008\n",
      "Epoch 31/50, iter: 1400/3382, mean loss: 0.0388445965665084\n",
      "Epoch 31/50, iter: 1500/3382, mean loss: 0.012052766423881636\n",
      "Epoch 31/50, iter: 1600/3382, mean loss: 0.05140805877472708\n",
      "Epoch 31/50, iter: 1700/3382, mean loss: 0.015978221241027837\n",
      "Epoch 31/50, iter: 1800/3382, mean loss: 0.04277582429123697\n",
      "Epoch 31/50, iter: 1900/3382, mean loss: 0.07365135539372382\n",
      "Epoch 31/50, iter: 2000/3382, mean loss: 0.03527453903031472\n",
      "Epoch 31/50, iter: 2100/3382, mean loss: 0.036605174981912715\n",
      "Epoch 31/50, iter: 2200/3382, mean loss: 0.10583866865525245\n",
      "Epoch 31/50, iter: 2300/3382, mean loss: 0.03944348235024378\n",
      "Epoch 31/50, iter: 2400/3382, mean loss: 0.03460333053567997\n",
      "Epoch 31/50, iter: 2500/3382, mean loss: 0.011829186973211314\n",
      "Epoch 31/50, iter: 2600/3382, mean loss: 0.05029470295231363\n",
      "Epoch 31/50, iter: 2700/3382, mean loss: 0.027197245656091874\n",
      "Epoch 31/50, iter: 2800/3382, mean loss: 0.024710974921999095\n",
      "Epoch 31/50, iter: 2900/3382, mean loss: 0.03128750295955321\n",
      "Epoch 31/50, iter: 3000/3382, mean loss: 0.02803611568698404\n",
      "Epoch 31/50, iter: 3100/3382, mean loss: 0.009432719972659029\n",
      "Epoch 31/50, iter: 3200/3382, mean loss: 0.014456411009552852\n",
      "Epoch 31/50, iter: 3300/3382, mean loss: 0.007462933054808687\n",
      "Epoch 32/50, iter: 100/3382, mean loss: 0.020868051621899683\n",
      "Epoch 32/50, iter: 200/3382, mean loss: 0.01348739446833811\n",
      "Epoch 32/50, iter: 300/3382, mean loss: 0.002104958357917468\n",
      "Epoch 32/50, iter: 400/3382, mean loss: 0.002213555739353552\n",
      "Epoch 32/50, iter: 500/3382, mean loss: 0.017769139592652507\n",
      "Epoch 32/50, iter: 600/3382, mean loss: 0.002601922099942051\n",
      "Epoch 32/50, iter: 700/3382, mean loss: 0.0013826857077259547\n",
      "Epoch 32/50, iter: 800/3382, mean loss: 0.0019253998323512534\n",
      "Epoch 32/50, iter: 900/3382, mean loss: 0.0008570490130936647\n",
      "Epoch 32/50, iter: 1000/3382, mean loss: 0.013563556715099274\n",
      "Epoch 32/50, iter: 1100/3382, mean loss: 0.028185758062674787\n",
      "Epoch 32/50, iter: 1200/3382, mean loss: 0.026766336935457248\n",
      "Epoch 32/50, iter: 1300/3382, mean loss: 0.016717748258597176\n",
      "Epoch 32/50, iter: 1400/3382, mean loss: 0.01942241561266183\n",
      "Epoch 32/50, iter: 1500/3382, mean loss: 0.011521066773402281\n",
      "Epoch 32/50, iter: 1600/3382, mean loss: 0.029115201355218973\n",
      "Epoch 32/50, iter: 1700/3382, mean loss: 0.004648034204533218\n",
      "Epoch 32/50, iter: 1800/3382, mean loss: 0.03244865772444292\n",
      "Epoch 32/50, iter: 1900/3382, mean loss: 0.06973867426800873\n",
      "Epoch 32/50, iter: 2000/3382, mean loss: 0.050700712931036805\n",
      "Epoch 32/50, iter: 2100/3382, mean loss: 0.035130898491272544\n",
      "Epoch 32/50, iter: 2200/3382, mean loss: 0.037005116993149303\n",
      "Epoch 32/50, iter: 2300/3382, mean loss: 0.029283023558562035\n",
      "Epoch 32/50, iter: 2400/3382, mean loss: 0.043890433764273734\n",
      "Epoch 32/50, iter: 2500/3382, mean loss: 0.010044250487340313\n",
      "Epoch 32/50, iter: 2600/3382, mean loss: 0.04929252906843892\n",
      "Epoch 32/50, iter: 2700/3382, mean loss: 0.014328990696647708\n",
      "Epoch 32/50, iter: 2800/3382, mean loss: 0.018211035947766022\n",
      "Epoch 32/50, iter: 2900/3382, mean loss: 0.01329799930358604\n",
      "Epoch 32/50, iter: 3000/3382, mean loss: 0.0296781539001039\n",
      "Epoch 32/50, iter: 3100/3382, mean loss: 0.027976428929461436\n",
      "Epoch 32/50, iter: 3200/3382, mean loss: 0.0029762607916021012\n",
      "Epoch 32/50, iter: 3300/3382, mean loss: 0.004807281210952467\n",
      "Epoch 33/50, iter: 100/3382, mean loss: 0.017194778861848902\n",
      "Epoch 33/50, iter: 200/3382, mean loss: 0.02664361246294238\n",
      "Epoch 33/50, iter: 300/3382, mean loss: 0.0024203082034651756\n",
      "Epoch 33/50, iter: 400/3382, mean loss: 0.001526880268690114\n",
      "Epoch 33/50, iter: 500/3382, mean loss: 0.003211356273392596\n",
      "Epoch 33/50, iter: 600/3382, mean loss: 0.008741770000900928\n",
      "Epoch 33/50, iter: 700/3382, mean loss: 0.0016001197515604915\n",
      "Epoch 33/50, iter: 800/3382, mean loss: 0.0002628023060845308\n",
      "Epoch 33/50, iter: 900/3382, mean loss: 0.0222257470608535\n",
      "Epoch 33/50, iter: 1000/3382, mean loss: 0.030230102965532524\n",
      "Epoch 33/50, iter: 1100/3382, mean loss: 0.011573239177787685\n",
      "Epoch 33/50, iter: 1200/3382, mean loss: 0.0348651341824165\n",
      "Epoch 33/50, iter: 1300/3382, mean loss: 0.022174440029848662\n",
      "Epoch 33/50, iter: 1400/3382, mean loss: 0.016258407605184502\n",
      "Epoch 33/50, iter: 1500/3382, mean loss: 0.017811679786752847\n",
      "Epoch 33/50, iter: 1600/3382, mean loss: 0.013402578448897522\n",
      "Epoch 33/50, iter: 1700/3382, mean loss: 0.006453014079643254\n",
      "Epoch 33/50, iter: 1800/3382, mean loss: 0.07008804871851158\n",
      "Epoch 33/50, iter: 1900/3382, mean loss: 0.06957333233375201\n",
      "Epoch 33/50, iter: 2000/3382, mean loss: 0.02495533398819646\n",
      "Epoch 33/50, iter: 2100/3382, mean loss: 0.02559842430480341\n",
      "Epoch 33/50, iter: 2200/3382, mean loss: 0.03274605069278589\n",
      "Epoch 33/50, iter: 2300/3382, mean loss: 0.0481689655812054\n",
      "Epoch 33/50, iter: 2400/3382, mean loss: 0.013186200995092037\n",
      "Epoch 33/50, iter: 2500/3382, mean loss: 0.015307393378964277\n",
      "Epoch 33/50, iter: 2600/3382, mean loss: 0.046236904207479765\n",
      "Epoch 33/50, iter: 2700/3382, mean loss: 0.022776739967819423\n",
      "Epoch 33/50, iter: 2800/3382, mean loss: 0.02317001987842019\n",
      "Epoch 33/50, iter: 2900/3382, mean loss: 0.006504098632321202\n",
      "Epoch 33/50, iter: 3000/3382, mean loss: 0.017675992535166357\n",
      "Epoch 33/50, iter: 3100/3382, mean loss: 0.015745411306116282\n",
      "Epoch 33/50, iter: 3200/3382, mean loss: 0.012686711480751782\n",
      "Epoch 33/50, iter: 3300/3382, mean loss: 0.010452037647737668\n",
      "Epoch 34/50, iter: 100/3382, mean loss: 0.009656551345631748\n",
      "Epoch 34/50, iter: 200/3382, mean loss: 0.028883862730558006\n",
      "Epoch 34/50, iter: 300/3382, mean loss: 0.0005861594809359616\n",
      "Epoch 34/50, iter: 400/3382, mean loss: 0.0047349348959913225\n",
      "Epoch 34/50, iter: 500/3382, mean loss: 0.010643322504771789\n",
      "Epoch 34/50, iter: 600/3382, mean loss: 0.0030499724704212026\n",
      "Epoch 34/50, iter: 700/3382, mean loss: 8.45512058776876e-05\n",
      "Epoch 34/50, iter: 800/3382, mean loss: 0.00150872456253925\n",
      "Epoch 34/50, iter: 900/3382, mean loss: 0.02264819658797677\n",
      "Epoch 34/50, iter: 1000/3382, mean loss: 0.003518311314766862\n",
      "Epoch 34/50, iter: 1100/3382, mean loss: 0.020158300692901497\n",
      "Epoch 34/50, iter: 1200/3382, mean loss: 0.050814809751284\n",
      "Epoch 34/50, iter: 1300/3382, mean loss: 0.02172367961604305\n",
      "Epoch 34/50, iter: 1400/3382, mean loss: 0.02254722013971108\n",
      "Epoch 34/50, iter: 1500/3382, mean loss: 0.019224000951001338\n",
      "Epoch 34/50, iter: 1600/3382, mean loss: 0.01165529000003037\n",
      "Epoch 34/50, iter: 1700/3382, mean loss: 0.0037007821958980358\n",
      "Epoch 34/50, iter: 1800/3382, mean loss: 0.08656531900407603\n",
      "Epoch 34/50, iter: 1900/3382, mean loss: 0.06990005325916904\n",
      "Epoch 34/50, iter: 2000/3382, mean loss: 0.01803463951798886\n",
      "Epoch 34/50, iter: 2100/3382, mean loss: 0.04410434495896283\n",
      "Epoch 34/50, iter: 2200/3382, mean loss: 0.04155712008706722\n",
      "Epoch 34/50, iter: 2300/3382, mean loss: 0.0430155431136528\n",
      "Epoch 34/50, iter: 2400/3382, mean loss: 0.011592611416463044\n",
      "Epoch 34/50, iter: 2500/3382, mean loss: 0.007133207583917951\n",
      "Epoch 34/50, iter: 2600/3382, mean loss: 0.06799830853602334\n",
      "Epoch 34/50, iter: 2700/3382, mean loss: 0.03741471611440488\n",
      "Epoch 34/50, iter: 2800/3382, mean loss: 0.014754670145277657\n",
      "Epoch 34/50, iter: 2900/3382, mean loss: 0.06257474037930613\n",
      "Epoch 34/50, iter: 3000/3382, mean loss: 0.01858301246816783\n",
      "Epoch 34/50, iter: 3100/3382, mean loss: 0.06360412784117017\n",
      "Epoch 34/50, iter: 3200/3382, mean loss: 0.025812490461031318\n",
      "Epoch 34/50, iter: 3300/3382, mean loss: 0.0289962282514999\n",
      "Epoch 35/50, iter: 100/3382, mean loss: 0.04689545329135026\n",
      "Epoch 35/50, iter: 200/3382, mean loss: 0.03688952661534547\n",
      "Epoch 35/50, iter: 300/3382, mean loss: 0.0020578880314237225\n",
      "Epoch 35/50, iter: 400/3382, mean loss: 0.00044345160669887916\n",
      "Epoch 35/50, iter: 500/3382, mean loss: 0.004910903776820312\n",
      "Epoch 35/50, iter: 600/3382, mean loss: 0.0019452025359368008\n",
      "Epoch 35/50, iter: 700/3382, mean loss: 0.0006278188535435447\n",
      "Epoch 35/50, iter: 800/3382, mean loss: 0.0014141068078704676\n",
      "Epoch 35/50, iter: 900/3382, mean loss: 0.0009306563957377634\n",
      "Epoch 35/50, iter: 1000/3382, mean loss: 0.03521296780772015\n",
      "Epoch 35/50, iter: 1100/3382, mean loss: 0.013492362188468547\n",
      "Epoch 35/50, iter: 1200/3382, mean loss: 0.05872825927550902\n",
      "Epoch 35/50, iter: 1300/3382, mean loss: 0.031313313829823386\n",
      "Epoch 35/50, iter: 1400/3382, mean loss: 0.026388116736409232\n",
      "Epoch 35/50, iter: 1500/3382, mean loss: 0.023698426689865854\n",
      "Epoch 35/50, iter: 1600/3382, mean loss: 0.00979006717304113\n",
      "Epoch 35/50, iter: 1700/3382, mean loss: 0.026081874657231517\n",
      "Epoch 35/50, iter: 1800/3382, mean loss: 0.025164582505051953\n",
      "Epoch 35/50, iter: 1900/3382, mean loss: 0.06191769967134292\n",
      "Epoch 35/50, iter: 2000/3382, mean loss: 0.027273375961437408\n",
      "Epoch 35/50, iter: 2100/3382, mean loss: 0.014091390934304187\n",
      "Epoch 35/50, iter: 2200/3382, mean loss: 0.042859667089887594\n",
      "Epoch 35/50, iter: 2300/3382, mean loss: 0.013617278604402046\n",
      "Epoch 35/50, iter: 2400/3382, mean loss: 0.014796061093840933\n",
      "Epoch 35/50, iter: 2500/3382, mean loss: 0.017849958457080924\n",
      "Epoch 35/50, iter: 2600/3382, mean loss: 0.02682131366164796\n",
      "Epoch 35/50, iter: 2700/3382, mean loss: 0.03026695851214196\n",
      "Epoch 35/50, iter: 2800/3382, mean loss: 0.014609698242004612\n",
      "Epoch 35/50, iter: 2900/3382, mean loss: 0.005016662188331189\n",
      "Epoch 35/50, iter: 3000/3382, mean loss: 0.04050420028142785\n",
      "Epoch 35/50, iter: 3100/3382, mean loss: 0.039976646702968494\n",
      "Epoch 35/50, iter: 3200/3382, mean loss: 0.008322033474690968\n",
      "Epoch 35/50, iter: 3300/3382, mean loss: 0.006783511076716664\n",
      "Epoch 36/50, iter: 100/3382, mean loss: 0.010597490175932265\n",
      "Epoch 36/50, iter: 200/3382, mean loss: 0.021365020785588627\n",
      "Epoch 36/50, iter: 300/3382, mean loss: 0.00038309935459718503\n",
      "Epoch 36/50, iter: 400/3382, mean loss: 0.001236228563720232\n",
      "Epoch 36/50, iter: 500/3382, mean loss: 0.0027336154094937727\n",
      "Epoch 36/50, iter: 600/3382, mean loss: 0.004344594855679027\n",
      "Epoch 36/50, iter: 700/3382, mean loss: 0.0003563468696311745\n",
      "Epoch 36/50, iter: 800/3382, mean loss: 0.000565700330369765\n",
      "Epoch 36/50, iter: 900/3382, mean loss: 0.002111094260606059\n",
      "Epoch 36/50, iter: 1000/3382, mean loss: 0.01326772528732441\n",
      "Epoch 36/50, iter: 1100/3382, mean loss: 0.016238934078371087\n",
      "Epoch 36/50, iter: 1200/3382, mean loss: 0.02431406897988545\n",
      "Epoch 36/50, iter: 1300/3382, mean loss: 0.036607695060679006\n",
      "Epoch 36/50, iter: 1400/3382, mean loss: 0.014175129831601296\n",
      "Epoch 36/50, iter: 1500/3382, mean loss: 0.005172610178798606\n",
      "Epoch 36/50, iter: 1600/3382, mean loss: 0.014675599841854278\n",
      "Epoch 36/50, iter: 1700/3382, mean loss: 0.01995487851727706\n",
      "Epoch 36/50, iter: 1800/3382, mean loss: 0.02275653343348935\n",
      "Epoch 36/50, iter: 1900/3382, mean loss: 0.03569021284993586\n",
      "Epoch 36/50, iter: 2000/3382, mean loss: 0.014525323878737879\n",
      "Epoch 36/50, iter: 2100/3382, mean loss: 0.032154560656466484\n",
      "Epoch 36/50, iter: 2200/3382, mean loss: 0.05073433050177876\n",
      "Epoch 36/50, iter: 2300/3382, mean loss: 0.022300568768982957\n",
      "Epoch 36/50, iter: 2400/3382, mean loss: 0.011723038014256665\n",
      "Epoch 36/50, iter: 2500/3382, mean loss: 0.02851468220600374\n",
      "Epoch 36/50, iter: 2600/3382, mean loss: 0.061704232182816024\n",
      "Epoch 36/50, iter: 2700/3382, mean loss: 0.009555888367091328\n",
      "Epoch 36/50, iter: 2800/3382, mean loss: 0.006226254799648814\n",
      "Epoch 36/50, iter: 2900/3382, mean loss: 0.02329648680105052\n",
      "Epoch 36/50, iter: 3000/3382, mean loss: 0.049503653907115745\n",
      "Epoch 36/50, iter: 3100/3382, mean loss: 0.02786536045410305\n",
      "Epoch 36/50, iter: 3200/3382, mean loss: 0.010480818694002388\n",
      "Epoch 36/50, iter: 3300/3382, mean loss: 0.010878803391910736\n",
      "Epoch 37/50, iter: 100/3382, mean loss: 0.032973648128919494\n",
      "Epoch 37/50, iter: 200/3382, mean loss: 0.019413739289037793\n",
      "Epoch 37/50, iter: 300/3382, mean loss: 7.467150305245695e-05\n",
      "Epoch 37/50, iter: 400/3382, mean loss: 0.0004887340474560276\n",
      "Epoch 37/50, iter: 500/3382, mean loss: 0.002405971660039157\n",
      "Epoch 37/50, iter: 600/3382, mean loss: 0.019126974643689395\n",
      "Epoch 37/50, iter: 700/3382, mean loss: 0.0015105177169649764\n",
      "Epoch 37/50, iter: 800/3382, mean loss: 0.00048244653031744635\n",
      "Epoch 37/50, iter: 900/3382, mean loss: 0.0003133944850567616\n",
      "Epoch 37/50, iter: 1000/3382, mean loss: 0.0057903227827905464\n",
      "Epoch 37/50, iter: 1100/3382, mean loss: 0.014269563826059652\n",
      "Epoch 37/50, iter: 1200/3382, mean loss: 0.032187253856544695\n",
      "Epoch 37/50, iter: 1300/3382, mean loss: 0.03253650207327155\n",
      "Epoch 37/50, iter: 1400/3382, mean loss: 0.013170675522744233\n",
      "Epoch 37/50, iter: 1500/3382, mean loss: 0.020583871914655952\n",
      "Epoch 37/50, iter: 1600/3382, mean loss: 0.007809529538314947\n",
      "Epoch 37/50, iter: 1700/3382, mean loss: 0.009739196718763062\n",
      "Epoch 37/50, iter: 1800/3382, mean loss: 0.03895870929330407\n",
      "Epoch 37/50, iter: 1900/3382, mean loss: 0.08723740374096266\n",
      "Epoch 37/50, iter: 2000/3382, mean loss: 0.009368247629587571\n",
      "Epoch 37/50, iter: 2100/3382, mean loss: 0.04300254462830928\n",
      "Epoch 37/50, iter: 2200/3382, mean loss: 0.03964814774461725\n",
      "Epoch 37/50, iter: 2300/3382, mean loss: 0.054032277209279084\n",
      "Epoch 37/50, iter: 2400/3382, mean loss: 0.00716851864721292\n",
      "Epoch 37/50, iter: 2500/3382, mean loss: 0.021305629945833893\n",
      "Epoch 37/50, iter: 2600/3382, mean loss: 0.043126314762395736\n",
      "Epoch 37/50, iter: 2700/3382, mean loss: 0.006060323472694833\n",
      "Epoch 37/50, iter: 2800/3382, mean loss: 0.005579964578345908\n",
      "Epoch 37/50, iter: 2900/3382, mean loss: 0.014643395846628736\n",
      "Epoch 37/50, iter: 3000/3382, mean loss: 0.0069974824706887165\n",
      "Epoch 37/50, iter: 3100/3382, mean loss: 0.05829999889148216\n",
      "Epoch 37/50, iter: 3200/3382, mean loss: 0.024575729937719722\n",
      "Epoch 37/50, iter: 3300/3382, mean loss: 0.04295302684605772\n",
      "Epoch 38/50, iter: 100/3382, mean loss: 0.010689966462486069\n",
      "Epoch 38/50, iter: 200/3382, mean loss: 0.03303738298275693\n",
      "Epoch 38/50, iter: 300/3382, mean loss: 0.0003343333631658041\n",
      "Epoch 38/50, iter: 400/3382, mean loss: 0.008649719869953679\n",
      "Epoch 38/50, iter: 500/3382, mean loss: 0.008370057387545274\n",
      "Epoch 38/50, iter: 600/3382, mean loss: 0.0009241952581421842\n",
      "Epoch 38/50, iter: 700/3382, mean loss: 0.0057239398493302215\n",
      "Epoch 38/50, iter: 800/3382, mean loss: 0.00017091364733001768\n",
      "Epoch 38/50, iter: 900/3382, mean loss: 0.0025413173331714843\n",
      "Epoch 38/50, iter: 1000/3382, mean loss: 0.003341302903490586\n",
      "Epoch 38/50, iter: 1100/3382, mean loss: 0.028427989052212013\n",
      "Epoch 38/50, iter: 1200/3382, mean loss: 0.026206151578043978\n",
      "Epoch 38/50, iter: 1300/3382, mean loss: 0.020094951114930596\n",
      "Epoch 38/50, iter: 1400/3382, mean loss: 0.028996712366110452\n",
      "Epoch 38/50, iter: 1500/3382, mean loss: 0.025692986958302234\n",
      "Epoch 38/50, iter: 1600/3382, mean loss: 0.007327488690546815\n",
      "Epoch 38/50, iter: 1700/3382, mean loss: 0.0049003333968798655\n",
      "Epoch 38/50, iter: 1800/3382, mean loss: 0.04865789746695676\n",
      "Epoch 38/50, iter: 1900/3382, mean loss: 0.06152815634735475\n",
      "Epoch 38/50, iter: 2000/3382, mean loss: 0.005922296556158919\n",
      "Epoch 38/50, iter: 2100/3382, mean loss: 0.052932130042357244\n",
      "Epoch 38/50, iter: 2200/3382, mean loss: 0.05629136890953472\n",
      "Epoch 38/50, iter: 2300/3382, mean loss: 0.029369809180598345\n",
      "Epoch 38/50, iter: 2400/3382, mean loss: 0.019610714386352725\n",
      "Epoch 38/50, iter: 2500/3382, mean loss: 0.008897608912700576\n",
      "Epoch 38/50, iter: 2600/3382, mean loss: 0.07592147686777771\n",
      "Epoch 38/50, iter: 2700/3382, mean loss: 0.012130144087423104\n",
      "Epoch 38/50, iter: 2800/3382, mean loss: 0.013697964375916954\n",
      "Epoch 38/50, iter: 2900/3382, mean loss: 0.05952192726714536\n",
      "Epoch 38/50, iter: 3000/3382, mean loss: 0.004932828279609999\n",
      "Epoch 38/50, iter: 3100/3382, mean loss: 0.022934026726808058\n",
      "Epoch 38/50, iter: 3200/3382, mean loss: 0.01104798709816599\n",
      "Epoch 38/50, iter: 3300/3382, mean loss: 0.011518626321799062\n",
      "Epoch 39/50, iter: 100/3382, mean loss: 0.0486922249061071\n",
      "Epoch 39/50, iter: 200/3382, mean loss: 0.02680106635296802\n",
      "Epoch 39/50, iter: 300/3382, mean loss: 0.02097146349272695\n",
      "Epoch 39/50, iter: 400/3382, mean loss: 0.0025819300867027904\n",
      "Epoch 39/50, iter: 500/3382, mean loss: 0.0029253981626349555\n",
      "Epoch 39/50, iter: 600/3382, mean loss: 0.00040107824509636456\n",
      "Epoch 39/50, iter: 700/3382, mean loss: 0.0005820819878679018\n",
      "Epoch 39/50, iter: 800/3382, mean loss: 0.02063949680406214\n",
      "Epoch 39/50, iter: 900/3382, mean loss: 0.0008504299174474994\n",
      "Epoch 39/50, iter: 1000/3382, mean loss: 0.009517424390576217\n",
      "Epoch 39/50, iter: 1100/3382, mean loss: 0.023844231454544628\n",
      "Epoch 39/50, iter: 1200/3382, mean loss: 0.024035156344057496\n",
      "Epoch 39/50, iter: 1300/3382, mean loss: 0.018291184204193876\n",
      "Epoch 39/50, iter: 1400/3382, mean loss: 0.013124507202248736\n",
      "Epoch 39/50, iter: 1500/3382, mean loss: 0.009952706516381013\n",
      "Epoch 39/50, iter: 1600/3382, mean loss: 0.029505463918898477\n",
      "Epoch 39/50, iter: 1700/3382, mean loss: 0.04152346017290832\n",
      "Epoch 39/50, iter: 1800/3382, mean loss: 0.025846976856886705\n",
      "Epoch 39/50, iter: 1900/3382, mean loss: 0.03771344859812796\n",
      "Epoch 39/50, iter: 2000/3382, mean loss: 0.004415859891854197\n",
      "Epoch 39/50, iter: 2100/3382, mean loss: 0.005547534283752817\n",
      "Epoch 39/50, iter: 2200/3382, mean loss: 0.04899459317421481\n",
      "Epoch 39/50, iter: 2300/3382, mean loss: 0.011500921586078015\n",
      "Epoch 39/50, iter: 2400/3382, mean loss: 0.022122946270235744\n",
      "Epoch 39/50, iter: 2500/3382, mean loss: 0.008226509178379153\n",
      "Epoch 39/50, iter: 2600/3382, mean loss: 0.06805587093696211\n",
      "Epoch 39/50, iter: 2700/3382, mean loss: 0.015055774731192422\n",
      "Epoch 39/50, iter: 2800/3382, mean loss: 0.003541600422186022\n",
      "Epoch 39/50, iter: 2900/3382, mean loss: 0.01482187312837489\n",
      "Epoch 39/50, iter: 3000/3382, mean loss: 0.01601915803658038\n",
      "Epoch 39/50, iter: 3100/3382, mean loss: 0.010695558634970155\n",
      "Epoch 39/50, iter: 3200/3382, mean loss: 0.030792075862132756\n",
      "Epoch 39/50, iter: 3300/3382, mean loss: 0.0036065863014784227\n",
      "Epoch 40/50, iter: 100/3382, mean loss: 0.009365269797074447\n",
      "Epoch 40/50, iter: 200/3382, mean loss: 0.03090523273595771\n",
      "Epoch 40/50, iter: 300/3382, mean loss: 0.003116427902613772\n",
      "Epoch 40/50, iter: 400/3382, mean loss: 0.00011691814258121269\n",
      "Epoch 40/50, iter: 500/3382, mean loss: 0.0029893623862592023\n",
      "Epoch 40/50, iter: 600/3382, mean loss: 0.0017181685125388668\n",
      "Epoch 40/50, iter: 700/3382, mean loss: 0.0005800449304085831\n",
      "Epoch 40/50, iter: 800/3382, mean loss: 0.013073644786428175\n",
      "Epoch 40/50, iter: 900/3382, mean loss: 0.0007218388532692899\n",
      "Epoch 40/50, iter: 1000/3382, mean loss: 0.008656686032304961\n",
      "Epoch 40/50, iter: 1100/3382, mean loss: 0.02113963380720193\n",
      "Epoch 40/50, iter: 1200/3382, mean loss: 0.024402813555783744\n",
      "Epoch 40/50, iter: 1300/3382, mean loss: 0.009241549633459521\n",
      "Epoch 40/50, iter: 1400/3382, mean loss: 0.018959074517297905\n",
      "Epoch 40/50, iter: 1500/3382, mean loss: 0.008257672862139742\n",
      "Epoch 40/50, iter: 1600/3382, mean loss: 0.012188633255775407\n",
      "Epoch 40/50, iter: 1700/3382, mean loss: 0.007283359203088757\n",
      "Epoch 40/50, iter: 1800/3382, mean loss: 0.05302313925821693\n",
      "Epoch 40/50, iter: 1900/3382, mean loss: 0.06500554007677209\n",
      "Epoch 40/50, iter: 2000/3382, mean loss: 0.019674540123663355\n",
      "Epoch 40/50, iter: 2100/3382, mean loss: 0.05126363484056355\n",
      "Epoch 40/50, iter: 2200/3382, mean loss: 0.011580429620718462\n",
      "Epoch 40/50, iter: 2300/3382, mean loss: 0.04443936697147539\n",
      "Epoch 40/50, iter: 2400/3382, mean loss: 0.00327171643664272\n",
      "Epoch 40/50, iter: 2500/3382, mean loss: 0.016658216872122152\n",
      "Epoch 40/50, iter: 2600/3382, mean loss: 0.16068971183954162\n",
      "Epoch 40/50, iter: 2700/3382, mean loss: 0.0166840837158146\n",
      "Epoch 40/50, iter: 2800/3382, mean loss: 0.014468269270617925\n",
      "Epoch 40/50, iter: 2900/3382, mean loss: 0.011041509501741053\n",
      "Epoch 40/50, iter: 3000/3382, mean loss: 0.019586896050650573\n",
      "Epoch 40/50, iter: 3100/3382, mean loss: 0.02573756873362683\n",
      "Epoch 40/50, iter: 3200/3382, mean loss: 0.0043135589214652725\n",
      "Epoch 40/50, iter: 3300/3382, mean loss: 0.010808117800601097\n",
      "Epoch 41/50, iter: 100/3382, mean loss: 0.008027462334216367\n",
      "Epoch 41/50, iter: 200/3382, mean loss: 0.013011667240748998\n",
      "Epoch 41/50, iter: 300/3382, mean loss: 0.004210370347645878\n",
      "Epoch 41/50, iter: 400/3382, mean loss: 8.668088891639059e-05\n",
      "Epoch 41/50, iter: 500/3382, mean loss: 0.015249913283371051\n",
      "Epoch 41/50, iter: 600/3382, mean loss: 0.01069888953449567\n",
      "Epoch 41/50, iter: 700/3382, mean loss: 0.002252187966901218\n",
      "Epoch 41/50, iter: 800/3382, mean loss: 0.001168416898620741\n",
      "Epoch 41/50, iter: 900/3382, mean loss: 0.0020262264137006626\n",
      "Epoch 41/50, iter: 1000/3382, mean loss: 0.0035140567052504325\n",
      "Epoch 41/50, iter: 1100/3382, mean loss: 0.020100751034351595\n",
      "Epoch 41/50, iter: 1200/3382, mean loss: 0.041941083854399965\n",
      "Epoch 41/50, iter: 1300/3382, mean loss: 0.014926256518907267\n",
      "Epoch 41/50, iter: 1400/3382, mean loss: 0.013050798911987833\n",
      "Epoch 41/50, iter: 1500/3382, mean loss: 0.011271277802947033\n",
      "Epoch 41/50, iter: 1600/3382, mean loss: 0.008367891709674566\n",
      "Epoch 41/50, iter: 1700/3382, mean loss: 0.010300404077242753\n",
      "Epoch 41/50, iter: 1800/3382, mean loss: 0.052250447493037804\n",
      "Epoch 41/50, iter: 1900/3382, mean loss: 0.07457452439052706\n",
      "Epoch 41/50, iter: 2000/3382, mean loss: 0.0018540310336774013\n",
      "Epoch 41/50, iter: 2100/3382, mean loss: 0.06327430199304192\n",
      "Epoch 41/50, iter: 2200/3382, mean loss: 0.017860192983627173\n",
      "Epoch 41/50, iter: 2300/3382, mean loss: 0.005969933073341167\n",
      "Epoch 41/50, iter: 2400/3382, mean loss: 0.012102925218390403\n",
      "Epoch 41/50, iter: 2500/3382, mean loss: 0.028912571032964428\n",
      "Epoch 41/50, iter: 2600/3382, mean loss: 0.08691237932760189\n",
      "Epoch 41/50, iter: 2700/3382, mean loss: 0.012909209643903807\n",
      "Epoch 41/50, iter: 2800/3382, mean loss: 0.004865117233658793\n",
      "Epoch 41/50, iter: 2900/3382, mean loss: 0.006484718095452599\n",
      "Epoch 41/50, iter: 3000/3382, mean loss: 0.020423432846709454\n",
      "Epoch 41/50, iter: 3100/3382, mean loss: 0.006928509634496791\n",
      "Epoch 41/50, iter: 3200/3382, mean loss: 0.004951020613255466\n",
      "Epoch 41/50, iter: 3300/3382, mean loss: 0.01792694302306046\n",
      "Epoch 42/50, iter: 100/3382, mean loss: 0.02387486602121079\n",
      "Epoch 42/50, iter: 200/3382, mean loss: 0.015423443112939203\n",
      "Epoch 42/50, iter: 300/3382, mean loss: 0.0005497453660595042\n",
      "Epoch 42/50, iter: 400/3382, mean loss: 0.002744188281137383\n",
      "Epoch 42/50, iter: 500/3382, mean loss: 0.0010271349611531732\n",
      "Epoch 42/50, iter: 600/3382, mean loss: 0.0014748821909209653\n",
      "Epoch 42/50, iter: 700/3382, mean loss: 0.019417790931224914\n",
      "Epoch 42/50, iter: 800/3382, mean loss: 0.0006993114503372766\n",
      "Epoch 42/50, iter: 900/3382, mean loss: 0.0016553939099183523\n",
      "Epoch 42/50, iter: 1000/3382, mean loss: 0.004054260297239551\n",
      "Epoch 42/50, iter: 1100/3382, mean loss: 0.014426094197025634\n",
      "Epoch 42/50, iter: 1200/3382, mean loss: 0.023847088323130164\n",
      "Epoch 42/50, iter: 1300/3382, mean loss: 0.03149983587686542\n",
      "Epoch 42/50, iter: 1400/3382, mean loss: 0.02088729236809005\n",
      "Epoch 42/50, iter: 1500/3382, mean loss: 0.03717599411284447\n",
      "Epoch 42/50, iter: 1600/3382, mean loss: 0.007388028094097336\n",
      "Epoch 42/50, iter: 1700/3382, mean loss: 0.006736152140358626\n",
      "Epoch 42/50, iter: 1800/3382, mean loss: 0.10611416859834456\n",
      "Epoch 42/50, iter: 1900/3382, mean loss: 0.08309772480052637\n",
      "Epoch 42/50, iter: 2000/3382, mean loss: 0.008805264509845472\n",
      "Epoch 42/50, iter: 2100/3382, mean loss: 0.01601080842169253\n",
      "Epoch 42/50, iter: 2200/3382, mean loss: 0.026038340508657852\n",
      "Epoch 42/50, iter: 2300/3382, mean loss: 0.015078814774133953\n",
      "Epoch 42/50, iter: 2400/3382, mean loss: 0.014297281546137342\n",
      "Epoch 42/50, iter: 2500/3382, mean loss: 0.008716785343328936\n",
      "Epoch 42/50, iter: 2600/3382, mean loss: 0.07789536846252208\n",
      "Epoch 42/50, iter: 2700/3382, mean loss: 0.00978400214695899\n",
      "Epoch 42/50, iter: 2800/3382, mean loss: 0.002411830486114468\n",
      "Epoch 42/50, iter: 2900/3382, mean loss: 0.011200479811935544\n",
      "Epoch 42/50, iter: 3000/3382, mean loss: 0.009118819564434055\n",
      "Epoch 42/50, iter: 3100/3382, mean loss: 0.0516811158810863\n",
      "Epoch 42/50, iter: 3200/3382, mean loss: 0.010258575885411928\n",
      "Epoch 42/50, iter: 3300/3382, mean loss: 0.012440156876509291\n",
      "Epoch 43/50, iter: 100/3382, mean loss: 0.013164203646761798\n",
      "Epoch 43/50, iter: 200/3382, mean loss: 0.011270631273696452\n",
      "Epoch 43/50, iter: 300/3382, mean loss: 0.001922966879134691\n",
      "Epoch 43/50, iter: 400/3382, mean loss: 0.0024292184446132125\n",
      "Epoch 43/50, iter: 500/3382, mean loss: 0.0035151296501031125\n",
      "Epoch 43/50, iter: 600/3382, mean loss: 0.0029251269161876792\n",
      "Epoch 43/50, iter: 700/3382, mean loss: 0.007143276375920493\n",
      "Epoch 43/50, iter: 800/3382, mean loss: 0.0025364702604425914\n",
      "Epoch 43/50, iter: 900/3382, mean loss: 0.0013452011521514961\n",
      "Epoch 43/50, iter: 1000/3382, mean loss: 0.005205052857614127\n",
      "Epoch 43/50, iter: 1100/3382, mean loss: 0.005886686240413006\n",
      "Epoch 43/50, iter: 1200/3382, mean loss: 0.04930840205963314\n",
      "Epoch 43/50, iter: 1300/3382, mean loss: 0.02498086843330018\n",
      "Epoch 43/50, iter: 1400/3382, mean loss: 0.0212774581005619\n",
      "Epoch 43/50, iter: 1500/3382, mean loss: 0.00796872610545151\n",
      "Epoch 43/50, iter: 1600/3382, mean loss: 0.010971719049660074\n",
      "Epoch 43/50, iter: 1700/3382, mean loss: 0.024975951152802017\n",
      "Epoch 43/50, iter: 1800/3382, mean loss: 0.041020870501614334\n",
      "Epoch 43/50, iter: 1900/3382, mean loss: 0.06147079489199374\n",
      "Epoch 43/50, iter: 2000/3382, mean loss: 0.005605312301988157\n",
      "Epoch 43/50, iter: 2100/3382, mean loss: 0.02665059592055755\n",
      "Epoch 43/50, iter: 2200/3382, mean loss: 0.024494450857223456\n",
      "Epoch 43/50, iter: 2300/3382, mean loss: 0.00661716416340905\n",
      "Epoch 43/50, iter: 2400/3382, mean loss: 0.019563457271576823\n",
      "Epoch 43/50, iter: 2500/3382, mean loss: 0.014214745835670044\n",
      "Epoch 43/50, iter: 2600/3382, mean loss: 0.054528918065890115\n",
      "Epoch 43/50, iter: 2700/3382, mean loss: 0.022915404716060125\n",
      "Epoch 43/50, iter: 2800/3382, mean loss: 0.019742822326827607\n",
      "Epoch 43/50, iter: 2900/3382, mean loss: 0.014618771609392027\n",
      "Epoch 43/50, iter: 3000/3382, mean loss: 0.008821994710750972\n",
      "Epoch 43/50, iter: 3100/3382, mean loss: 0.0123636314099803\n",
      "Epoch 43/50, iter: 3200/3382, mean loss: 0.008457780122172487\n",
      "Epoch 43/50, iter: 3300/3382, mean loss: 0.028124023539961306\n",
      "Epoch 44/50, iter: 100/3382, mean loss: 0.00685725455415735\n",
      "Epoch 44/50, iter: 200/3382, mean loss: 0.03612543937117017\n",
      "Epoch 44/50, iter: 300/3382, mean loss: 0.002672710456237297\n",
      "Epoch 44/50, iter: 400/3382, mean loss: 6.831358658303088e-05\n",
      "Epoch 44/50, iter: 500/3382, mean loss: 0.006829356059150733\n",
      "Epoch 44/50, iter: 600/3382, mean loss: 0.001340548116969451\n",
      "Epoch 44/50, iter: 700/3382, mean loss: 0.00010300870879017765\n",
      "Epoch 44/50, iter: 800/3382, mean loss: 0.00026521896231322727\n",
      "Epoch 44/50, iter: 900/3382, mean loss: 0.0017942447813053875\n",
      "Epoch 44/50, iter: 1000/3382, mean loss: 0.011238827535705589\n",
      "Epoch 44/50, iter: 1100/3382, mean loss: 0.013179363646334749\n",
      "Epoch 44/50, iter: 1200/3382, mean loss: 0.01944499373882973\n",
      "Epoch 44/50, iter: 1300/3382, mean loss: 0.006178537511190498\n",
      "Epoch 44/50, iter: 1400/3382, mean loss: 0.01564677795715962\n",
      "Epoch 44/50, iter: 1500/3382, mean loss: 0.021024723257306876\n",
      "Epoch 44/50, iter: 1600/3382, mean loss: 0.02035512679730285\n",
      "Epoch 44/50, iter: 1700/3382, mean loss: 0.04260552848023899\n",
      "Epoch 44/50, iter: 1800/3382, mean loss: 0.04218717027721379\n",
      "Epoch 44/50, iter: 1900/3382, mean loss: 0.07185704878738364\n",
      "Epoch 44/50, iter: 2000/3382, mean loss: 0.015786453144650672\n",
      "Epoch 44/50, iter: 2100/3382, mean loss: 0.0173989600762064\n",
      "Epoch 44/50, iter: 2200/3382, mean loss: 0.05318625069497987\n",
      "Epoch 44/50, iter: 2300/3382, mean loss: 0.005715775332307942\n",
      "Epoch 44/50, iter: 2400/3382, mean loss: 0.02858959745482469\n",
      "Epoch 44/50, iter: 2500/3382, mean loss: 0.014955376850643312\n",
      "Epoch 44/50, iter: 2600/3382, mean loss: 0.06230688263137701\n",
      "Epoch 44/50, iter: 2700/3382, mean loss: 0.010008559439428879\n",
      "Epoch 44/50, iter: 2800/3382, mean loss: 0.002986307140609554\n",
      "Epoch 44/50, iter: 2900/3382, mean loss: 0.017452589660513704\n",
      "Epoch 44/50, iter: 3000/3382, mean loss: 0.03248636729292514\n",
      "Epoch 44/50, iter: 3100/3382, mean loss: 0.021049511780783625\n",
      "Epoch 44/50, iter: 3200/3382, mean loss: 0.02821501358277821\n",
      "Epoch 44/50, iter: 3300/3382, mean loss: 0.006291551001026967\n",
      "Epoch 45/50, iter: 100/3382, mean loss: 0.013151796294333913\n",
      "Epoch 45/50, iter: 200/3382, mean loss: 0.013152763917718637\n",
      "Epoch 45/50, iter: 300/3382, mean loss: 0.0006959287452784935\n",
      "Epoch 45/50, iter: 400/3382, mean loss: 0.0002554025937551074\n",
      "Epoch 45/50, iter: 500/3382, mean loss: 0.0012982023476667238\n",
      "Epoch 45/50, iter: 600/3382, mean loss: 0.00029457912659619723\n",
      "Epoch 45/50, iter: 700/3382, mean loss: 0.001013732703573673\n",
      "Epoch 45/50, iter: 800/3382, mean loss: 0.00010345711030076643\n",
      "Epoch 45/50, iter: 900/3382, mean loss: 0.0005746334816284104\n",
      "Epoch 45/50, iter: 1000/3382, mean loss: 0.010272043174890904\n",
      "Epoch 45/50, iter: 1100/3382, mean loss: 0.04263244249141735\n",
      "Epoch 45/50, iter: 1200/3382, mean loss: 0.05070500749633876\n",
      "Epoch 45/50, iter: 1300/3382, mean loss: 0.022824612375964046\n",
      "Epoch 45/50, iter: 1400/3382, mean loss: 0.01871479777138866\n",
      "Epoch 45/50, iter: 1500/3382, mean loss: 0.03759724010117686\n",
      "Epoch 45/50, iter: 1600/3382, mean loss: 0.028325270461344268\n",
      "Epoch 45/50, iter: 1700/3382, mean loss: 0.008500166539996882\n",
      "Epoch 45/50, iter: 1800/3382, mean loss: 0.017468893748348792\n",
      "Epoch 45/50, iter: 1900/3382, mean loss: 0.07365235112118175\n",
      "Epoch 45/50, iter: 2000/3382, mean loss: 0.013319669037443447\n",
      "Epoch 45/50, iter: 2100/3382, mean loss: 0.034142599028611824\n",
      "Epoch 45/50, iter: 2200/3382, mean loss: 0.02900547071842528\n",
      "Epoch 45/50, iter: 2300/3382, mean loss: 0.026490553809135554\n",
      "Epoch 45/50, iter: 2400/3382, mean loss: 0.005772996450129284\n",
      "Epoch 45/50, iter: 2500/3382, mean loss: 0.006214561955336251\n",
      "Epoch 45/50, iter: 2600/3382, mean loss: 0.0593012970633173\n",
      "Epoch 45/50, iter: 2700/3382, mean loss: 0.00940309302347039\n",
      "Epoch 45/50, iter: 2800/3382, mean loss: 0.006673468498985286\n",
      "Epoch 45/50, iter: 2900/3382, mean loss: 0.010799557889190438\n",
      "Epoch 45/50, iter: 3000/3382, mean loss: 0.009205118431957687\n",
      "Epoch 45/50, iter: 3100/3382, mean loss: 0.00642586815570759\n",
      "Epoch 45/50, iter: 3200/3382, mean loss: 0.011930774260602704\n",
      "Epoch 45/50, iter: 3300/3382, mean loss: 0.007337031745065765\n",
      "Epoch 46/50, iter: 100/3382, mean loss: 0.015377219904987704\n",
      "Epoch 46/50, iter: 200/3382, mean loss: 0.02732503631387697\n",
      "Epoch 46/50, iter: 300/3382, mean loss: 0.0015638242743334985\n",
      "Epoch 46/50, iter: 400/3382, mean loss: 0.0004003314663012247\n",
      "Epoch 46/50, iter: 500/3382, mean loss: 0.0018494736862956175\n",
      "Epoch 46/50, iter: 600/3382, mean loss: 0.001224167629947921\n",
      "Epoch 46/50, iter: 700/3382, mean loss: 1.038614913529301e-05\n",
      "Epoch 46/50, iter: 800/3382, mean loss: 0.0006910130974641859\n",
      "Epoch 46/50, iter: 900/3382, mean loss: 0.00015010101528979193\n",
      "Epoch 46/50, iter: 1000/3382, mean loss: 0.00936275096928302\n",
      "Epoch 46/50, iter: 1100/3382, mean loss: 0.013573857493400076\n",
      "Epoch 46/50, iter: 1200/3382, mean loss: 0.017864712178383684\n",
      "Epoch 46/50, iter: 1300/3382, mean loss: 0.023753301881966386\n",
      "Epoch 46/50, iter: 1400/3382, mean loss: 0.0027949713538411203\n",
      "Epoch 46/50, iter: 1500/3382, mean loss: 0.008875013437139465\n",
      "Epoch 46/50, iter: 1600/3382, mean loss: 0.010348107826073089\n",
      "Epoch 46/50, iter: 1700/3382, mean loss: 0.021860213237079158\n",
      "Epoch 46/50, iter: 1800/3382, mean loss: 0.014548804687802352\n",
      "Epoch 46/50, iter: 1900/3382, mean loss: 0.02653132844035273\n",
      "Epoch 46/50, iter: 2000/3382, mean loss: 0.005073107155526913\n",
      "Epoch 46/50, iter: 2100/3382, mean loss: 0.02567627207908082\n",
      "Epoch 46/50, iter: 2200/3382, mean loss: 0.023438565252071088\n",
      "Epoch 46/50, iter: 2300/3382, mean loss: 0.00425565509391344\n",
      "Epoch 46/50, iter: 2400/3382, mean loss: 0.021677796513990443\n",
      "Epoch 46/50, iter: 2500/3382, mean loss: 0.006894513097943822\n",
      "Epoch 46/50, iter: 2600/3382, mean loss: 0.06391656728565209\n",
      "Epoch 46/50, iter: 2700/3382, mean loss: 0.012613797962183888\n",
      "Epoch 46/50, iter: 2800/3382, mean loss: 0.0206092342647489\n",
      "Epoch 46/50, iter: 2900/3382, mean loss: 0.003231188491123369\n",
      "Epoch 46/50, iter: 3000/3382, mean loss: 0.02244611384072783\n",
      "Epoch 46/50, iter: 3100/3382, mean loss: 0.0077853366648431436\n",
      "Epoch 46/50, iter: 3200/3382, mean loss: 0.024935642045045475\n",
      "Epoch 46/50, iter: 3300/3382, mean loss: 0.004043461476911432\n",
      "Epoch 47/50, iter: 100/3382, mean loss: 0.004288255640563925\n",
      "Epoch 47/50, iter: 200/3382, mean loss: 0.02769080494646058\n",
      "Epoch 47/50, iter: 300/3382, mean loss: 9.543312315013708e-05\n",
      "Epoch 47/50, iter: 400/3382, mean loss: 1.964465272372706e-05\n",
      "Epoch 47/50, iter: 500/3382, mean loss: 0.001714949706717981\n",
      "Epoch 47/50, iter: 600/3382, mean loss: 0.0004928493747831198\n",
      "Epoch 47/50, iter: 700/3382, mean loss: 4.039019785540887e-05\n",
      "Epoch 47/50, iter: 800/3382, mean loss: 0.002253211339131056\n",
      "Epoch 47/50, iter: 900/3382, mean loss: 5.3964759288476216e-05\n",
      "Epoch 47/50, iter: 1000/3382, mean loss: 0.0020255386431970025\n",
      "Epoch 47/50, iter: 1100/3382, mean loss: 0.0272479099217286\n",
      "Epoch 47/50, iter: 1200/3382, mean loss: 0.030855363932405063\n",
      "Epoch 47/50, iter: 1300/3382, mean loss: 0.010492053480505525\n",
      "Epoch 47/50, iter: 1400/3382, mean loss: 0.016903473594051695\n",
      "Epoch 47/50, iter: 1500/3382, mean loss: 0.008861605337563212\n",
      "Epoch 47/50, iter: 1600/3382, mean loss: 0.020341533391748108\n",
      "Epoch 47/50, iter: 1700/3382, mean loss: 0.028023456526809872\n",
      "Epoch 47/50, iter: 1800/3382, mean loss: 0.019534978648689787\n",
      "Epoch 47/50, iter: 1900/3382, mean loss: 0.07680396636712285\n",
      "Epoch 47/50, iter: 2000/3382, mean loss: 0.00993195008945527\n",
      "Epoch 47/50, iter: 2100/3382, mean loss: 0.027557055986245763\n",
      "Epoch 47/50, iter: 2200/3382, mean loss: 0.013156664186909488\n",
      "Epoch 47/50, iter: 2300/3382, mean loss: 0.004209120066075264\n",
      "Epoch 47/50, iter: 2400/3382, mean loss: 0.03026609246235509\n",
      "Epoch 47/50, iter: 2500/3382, mean loss: 0.017961797211848526\n",
      "Epoch 47/50, iter: 2600/3382, mean loss: 0.08329565125199281\n",
      "Epoch 47/50, iter: 2700/3382, mean loss: 0.009536342161601255\n",
      "Epoch 47/50, iter: 2800/3382, mean loss: 0.0056871296907276304\n",
      "Epoch 47/50, iter: 2900/3382, mean loss: 0.004649963975013698\n",
      "Epoch 47/50, iter: 3000/3382, mean loss: 0.0014722360021504244\n",
      "Epoch 47/50, iter: 3100/3382, mean loss: 0.01015902195146122\n",
      "Epoch 47/50, iter: 3200/3382, mean loss: 0.028855002144285925\n",
      "Epoch 47/50, iter: 3300/3382, mean loss: 0.00442769966112639\n",
      "Epoch 48/50, iter: 100/3382, mean loss: 0.006317335587596169\n",
      "Epoch 48/50, iter: 200/3382, mean loss: 0.05289197059697433\n",
      "Epoch 48/50, iter: 300/3382, mean loss: 0.0008468711628053071\n",
      "Epoch 48/50, iter: 400/3382, mean loss: 0.0015380129347063586\n",
      "Epoch 48/50, iter: 500/3382, mean loss: 0.003426924881431539\n",
      "Epoch 48/50, iter: 600/3382, mean loss: 0.0013907318417351888\n",
      "Epoch 48/50, iter: 700/3382, mean loss: 0.0008121583852997816\n",
      "Epoch 48/50, iter: 800/3382, mean loss: 0.00012878204240806212\n",
      "Epoch 48/50, iter: 900/3382, mean loss: 0.002369996015820739\n",
      "Epoch 48/50, iter: 1000/3382, mean loss: 0.006447792361046325\n",
      "Epoch 48/50, iter: 1100/3382, mean loss: 0.024527662401399013\n",
      "Epoch 48/50, iter: 1200/3382, mean loss: 0.03031647666086492\n",
      "Epoch 48/50, iter: 1300/3382, mean loss: 0.0339696425065031\n",
      "Epoch 48/50, iter: 1400/3382, mean loss: 0.03488730269500202\n",
      "Epoch 48/50, iter: 1500/3382, mean loss: 0.011207873660922872\n",
      "Epoch 48/50, iter: 1600/3382, mean loss: 0.014102136027775493\n",
      "Epoch 48/50, iter: 1700/3382, mean loss: 0.004062413631683164\n",
      "Epoch 48/50, iter: 1800/3382, mean loss: 0.019134069261749112\n",
      "Epoch 48/50, iter: 1900/3382, mean loss: 0.060904784533146065\n",
      "Epoch 48/50, iter: 2000/3382, mean loss: 0.010435607746862132\n",
      "Epoch 48/50, iter: 2100/3382, mean loss: 0.01217054410492903\n",
      "Epoch 48/50, iter: 2200/3382, mean loss: 0.016305583470582512\n",
      "Epoch 48/50, iter: 2300/3382, mean loss: 0.025934876209603493\n",
      "Epoch 48/50, iter: 2400/3382, mean loss: 0.004864982873076649\n",
      "Epoch 48/50, iter: 2500/3382, mean loss: 0.01375961853920554\n",
      "Epoch 48/50, iter: 2600/3382, mean loss: 0.054265721852658225\n",
      "Epoch 48/50, iter: 2700/3382, mean loss: 0.003432053803304491\n",
      "Epoch 48/50, iter: 2800/3382, mean loss: 0.018784433318503452\n",
      "Epoch 48/50, iter: 2900/3382, mean loss: 0.03656920219567358\n",
      "Epoch 48/50, iter: 3000/3382, mean loss: 0.013429110763666827\n",
      "Epoch 48/50, iter: 3100/3382, mean loss: 0.005890923036986315\n",
      "Epoch 48/50, iter: 3200/3382, mean loss: 0.002789199816384986\n",
      "Epoch 48/50, iter: 3300/3382, mean loss: 0.014670592778392723\n",
      "Epoch 49/50, iter: 100/3382, mean loss: 0.008601714618260417\n",
      "Epoch 49/50, iter: 200/3382, mean loss: 0.011176995475252376\n",
      "Epoch 49/50, iter: 300/3382, mean loss: 0.00032847578445117877\n",
      "Epoch 49/50, iter: 400/3382, mean loss: 0.00023695300336886048\n",
      "Epoch 49/50, iter: 500/3382, mean loss: 0.003735900450061429\n",
      "Epoch 49/50, iter: 600/3382, mean loss: 0.016018943407158412\n",
      "Epoch 49/50, iter: 700/3382, mean loss: 0.001367731997395083\n",
      "Epoch 49/50, iter: 800/3382, mean loss: 0.00047730725402342247\n",
      "Epoch 49/50, iter: 900/3382, mean loss: 0.04629110533653051\n",
      "Epoch 49/50, iter: 1000/3382, mean loss: 0.007706184992866731\n",
      "Epoch 49/50, iter: 1100/3382, mean loss: 0.03996007157242367\n",
      "Epoch 49/50, iter: 1200/3382, mean loss: 0.03270083083482436\n",
      "Epoch 49/50, iter: 1300/3382, mean loss: 0.03520224013555822\n",
      "Epoch 49/50, iter: 1400/3382, mean loss: 0.05339536005262648\n",
      "Epoch 49/50, iter: 1500/3382, mean loss: 0.029833883488447482\n",
      "Epoch 49/50, iter: 1600/3382, mean loss: 0.015947231040223074\n",
      "Epoch 49/50, iter: 1700/3382, mean loss: 0.04068380596781157\n",
      "Epoch 49/50, iter: 1800/3382, mean loss: 0.02607936454301452\n",
      "Epoch 49/50, iter: 1900/3382, mean loss: 0.09546058787363783\n",
      "Epoch 49/50, iter: 2000/3382, mean loss: 0.01234210444316627\n",
      "Epoch 49/50, iter: 2100/3382, mean loss: 0.06073963318996878\n",
      "Epoch 49/50, iter: 2200/3382, mean loss: 0.05778744533319099\n",
      "Epoch 49/50, iter: 2300/3382, mean loss: 0.00804607979974385\n",
      "Epoch 49/50, iter: 2400/3382, mean loss: 0.025461597584876827\n",
      "Epoch 49/50, iter: 2500/3382, mean loss: 0.0051942037650517395\n",
      "Epoch 49/50, iter: 2600/3382, mean loss: 0.030008567471509977\n",
      "Epoch 49/50, iter: 2700/3382, mean loss: 0.0053766090729314795\n",
      "Epoch 49/50, iter: 2800/3382, mean loss: 0.028714577615754102\n",
      "Epoch 49/50, iter: 2900/3382, mean loss: 0.012628612325859266\n",
      "Epoch 49/50, iter: 3000/3382, mean loss: 0.01674615668217559\n",
      "Epoch 49/50, iter: 3100/3382, mean loss: 0.009704021164892005\n",
      "Epoch 49/50, iter: 3200/3382, mean loss: 0.005604147070460002\n",
      "Epoch 49/50, iter: 3300/3382, mean loss: 0.008350398210614927\n",
      "Epoch 50/50, iter: 100/3382, mean loss: 0.014628193058834036\n",
      "Epoch 50/50, iter: 200/3382, mean loss: 0.01473858086419984\n",
      "Epoch 50/50, iter: 300/3382, mean loss: 0.001388365272965011\n",
      "Epoch 50/50, iter: 400/3382, mean loss: 0.0032039359821600753\n",
      "Epoch 50/50, iter: 500/3382, mean loss: 0.0020670155311861295\n",
      "Epoch 50/50, iter: 600/3382, mean loss: 0.009635588783811037\n",
      "Epoch 50/50, iter: 700/3382, mean loss: 0.0005792590564453449\n",
      "Epoch 50/50, iter: 800/3382, mean loss: 0.00014438306949994485\n",
      "Epoch 50/50, iter: 900/3382, mean loss: 6.1005874446813377e-05\n",
      "Epoch 50/50, iter: 1000/3382, mean loss: 0.0023986283773532336\n",
      "Epoch 50/50, iter: 1100/3382, mean loss: 0.01177236011565803\n",
      "Epoch 50/50, iter: 1200/3382, mean loss: 0.023602703690069903\n",
      "Epoch 50/50, iter: 1300/3382, mean loss: 0.03198108892997368\n",
      "Epoch 50/50, iter: 1400/3382, mean loss: 0.06188960242465747\n",
      "Epoch 50/50, iter: 1500/3382, mean loss: 0.0053688583132486655\n",
      "Epoch 50/50, iter: 1600/3382, mean loss: 0.008798304260907983\n",
      "Epoch 50/50, iter: 1700/3382, mean loss: 0.011627681683905813\n",
      "Epoch 50/50, iter: 1800/3382, mean loss: 0.02239286275921291\n",
      "Epoch 50/50, iter: 1900/3382, mean loss: 0.0981044840144467\n",
      "Epoch 50/50, iter: 2000/3382, mean loss: 0.015260458880342895\n",
      "Epoch 50/50, iter: 2100/3382, mean loss: 0.02909446904451521\n",
      "Epoch 50/50, iter: 2200/3382, mean loss: 0.032312693231805766\n",
      "Epoch 50/50, iter: 2300/3382, mean loss: 0.012206489905814024\n",
      "Epoch 50/50, iter: 2400/3382, mean loss: 0.006519881985582927\n",
      "Epoch 50/50, iter: 2500/3382, mean loss: 0.05107164683223885\n",
      "Epoch 50/50, iter: 2600/3382, mean loss: 0.06542095457188896\n",
      "Epoch 50/50, iter: 2700/3382, mean loss: 0.02581211361716605\n",
      "Epoch 50/50, iter: 2800/3382, mean loss: 0.011278485175303422\n",
      "Epoch 50/50, iter: 2900/3382, mean loss: 0.012495864662357227\n",
      "Epoch 50/50, iter: 3000/3382, mean loss: 0.008314313750730839\n",
      "Epoch 50/50, iter: 3100/3382, mean loss: 0.038548409216201056\n",
      "Epoch 50/50, iter: 3200/3382, mean loss: 0.00275770540836298\n",
      "Epoch 50/50, iter: 3300/3382, mean loss: 0.011700329448891046\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "use_wandb = True\n",
    "\n",
    "lr = 0.0005\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "epochs_cnt = 50\n",
    "embeddings = \"random\"\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "task = \"text2company\" # \"text2sentiment\"  #\n",
    "use_company_info = True\n",
    "preprocessing = \"simple\"\n",
    "use_stop_words = False\n",
    "\n",
    "get_dataloaders = get_twit_company_dataloaders if task == \"text2company\" else \\\n",
    "    get_twit_sentiment_dataloaders if not use_company_info else get_twit_company_sentiment_dataloaders\n",
    "\n",
    "dataset_train, dataloader_train, dataset_test, dataloader_test = get_dataloaders(embedding_dim=embedding_size,\n",
    "                                                                                 embedding=embeddings,\n",
    "                                                                                 preprocessing=preprocessing,\n",
    "                                                                                 use_stop_words=use_stop_words)\n",
    "\n",
    "model = LSTMTwitClassifier(4, embedding_dim=embedding_size, hidden_dim=hidden_size, dropout=dropout,\n",
    "                           lstm_layers=lstm_layers,\n",
    "                           additional_one_hot_arg=use_company_info and task == \"text2sentiment\")\n",
    "model = model.to(device)\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project=task + '_twit_classification', entity='ars860')\n",
    "\n",
    "    config = wandb.config\n",
    "    config.loss = \"BCE\"\n",
    "    config.optimizer = \"Adam\"\n",
    "    config.learning_rate = lr\n",
    "    config.hidden_size = hidden_size\n",
    "    config.embedding_size = embedding_size\n",
    "    config.embeddings = embeddings\n",
    "    config.epochs = epochs_cnt\n",
    "    config.dropout = dropout\n",
    "    config.lstm_layers = lstm_layers\n",
    "    config.stem = \"snowballstemmer\"\n",
    "    config.preprocessing = preprocessing\n",
    "    config.use_stop_words = use_stop_words\n",
    "\n",
    "    if task == \"text2sentiment\":\n",
    "        config.use_company_info = use_company_info\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def loss_on_test():\n",
    "    correct = 0\n",
    "    losses = np.zeros(len(dataloader_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (*args, target) in enumerate(dataloader_test):\n",
    "            args = [arg.to(device) for arg in args]\n",
    "            target = target.to(device)\n",
    "\n",
    "            prediction = model(*args)\n",
    "            prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "            losses[i] = F.binary_cross_entropy(prediction, target.view(-1))\n",
    "            if torch.argmax(prediction) == torch.argmax(target):\n",
    "                correct += 1\n",
    "\n",
    "            # predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "    model.train()\n",
    "    if use_wandb:\n",
    "        wandb.log({\"test_loss\": np.mean(losses), \"test_accuracy\": correct / len(dataloader_test)})\n",
    "\n",
    "\n",
    "losses = np.empty(100)\n",
    "model.train()\n",
    "for epoch in range(epochs_cnt):\n",
    "    epoch_loss = np.zeros(len(dataloader_train))\n",
    "\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        args = [arg.to(device) for arg in args]\n",
    "        target = target.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        loss = criterion(prediction, target.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.detach().item()\n",
    "        losses[i % 100] = loss\n",
    "        epoch_loss[i] = loss\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs_cnt}, iter: {i + 1}/{len(dataloader_train)}, mean loss: {np.mean(losses)}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"loss\": np.mean(losses)})\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": np.mean(epoch_loss)})\n",
    "        loss_on_test()\n",
    "\n",
    "# [model.get_word_embedding(word) for word in \"hello_world\".split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on train\n",
      "Iter: 0/3382\n",
      "Iter: 100/3382\n",
      "Iter: 200/3382\n",
      "Iter: 300/3382\n",
      "Iter: 400/3382\n",
      "Iter: 500/3382\n",
      "Iter: 600/3382\n",
      "Iter: 700/3382\n",
      "Iter: 800/3382\n",
      "Iter: 900/3382\n",
      "Iter: 1000/3382\n",
      "Iter: 1100/3382\n",
      "Iter: 1200/3382\n",
      "Iter: 1300/3382\n",
      "Iter: 1400/3382\n",
      "Iter: 1500/3382\n",
      "Iter: 1600/3382\n",
      "Iter: 1700/3382\n",
      "Iter: 1800/3382\n",
      "Iter: 1900/3382\n",
      "Iter: 2000/3382\n",
      "Iter: 2100/3382\n",
      "Iter: 2200/3382\n",
      "Iter: 2300/3382\n",
      "Iter: 2400/3382\n",
      "Iter: 2500/3382\n",
      "Iter: 2600/3382\n",
      "Iter: 2700/3382\n",
      "Iter: 2800/3382\n",
      "Iter: 2900/3382\n",
      "Iter: 3000/3382\n",
      "Iter: 3100/3382\n",
      "Iter: 3200/3382\n",
      "Iter: 3300/3382\n",
      "Accuracy 0.994086339444116\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 3396<br/>Program ended successfully."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f597e03f83c4bb09139677a23589f0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211029_145751-2h497kle\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>E:\\acady\\learning\\sma\\twit_classifier\\wandb\\run-20211029_145751-2h497kle\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>0.0117</td></tr><tr><td>_runtime</td><td>977</td></tr><tr><td>_timestamp</td><td>1635509649</td></tr><tr><td>_step</td><td>1749</td></tr><tr><td>epoch_loss</td><td>0.02102</td></tr><tr><td>test_loss</td><td>3.10946</td></tr><tr><td>test_accuracy</td><td>0.27219</td></tr><tr><td>train_accuracy</td><td>0.99409</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>loss</td><td>▁▁▁▁▄█▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▇█▇▇▇▇▇▇▆▆▆▆▅▄▄▃▃▂▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▇▅█▅█▇▄▄▄▃▃▂▂▁▁▁▂▂▁▃▂▃▄▅▃▄▅▃▅▄▅▆▄▅▇▅▅█▇█</td></tr><tr><td>test_accuracy</td><td>▅▅▄▅▅▅▆▆▄▅▅▄▅▂▄▆▃▄▄▄▃▃▄▁▂▁▃▄▁▁▅▄▄▆▃▃▄▅██</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">polar-plasma-44</strong>: <a href=\"https://wandb.ai/ars860/text2company_twit_classification/runs/2h497kle\" target=\"_blank\">https://wandb.ai/ars860/text2company_twit_classification/runs/2h497kle</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Testing on train\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_train):\n",
    "        args = [arg.to(device) for arg in args]\n",
    "        target = target.to(device)\n",
    "\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_train)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_train)}\")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.run.summary.train_accuracy = correct / len(dataloader_train)\n",
    "    wandb.run.summary.classified_as = {\n",
    "        \"apple\": predictions_cnt[0],\n",
    "        \"google\": predictions_cnt[1],\n",
    "        \"microsoft\": predictions_cnt[2],\n",
    "        \"twitter\": predictions_cnt[3]\n",
    "    }\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test\n",
      "Iter: 0/338\n",
      "Iter: 100/338\n",
      "Iter: 200/338\n",
      "Iter: 300/338\n",
      "Accuracy 0.27218934911242604\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test\")\n",
    "\n",
    "correct = 0\n",
    "predictions_cnt = [0, 0, 0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (*args, target) in enumerate(dataloader_test):\n",
    "        args = [arg.to(device) for arg in args]\n",
    "        target = target.to(device)\n",
    "\n",
    "        prediction = model(*args)\n",
    "        prediction = F.softmax(prediction, dim=0)\n",
    "\n",
    "        if torch.argmax(prediction) == torch.argmax(target):\n",
    "            correct += 1\n",
    "\n",
    "        predictions_cnt[torch.argmax(prediction)] += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}/{len(dataloader_test)}\")\n",
    "\n",
    "print(f\"Accuracy {correct / len(dataloader_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}